[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Geospatial Data Science with Julia",
    "section": "",
    "text": "Welcome\nGeospatial Data Science with Julia presents a fresh approach to data science with geospatial data and the  programming language. It contains best practices for writing clean, readable and performant code in geoscientific applications involving sophisticated representations of the (sub)surface of the Earth such as unstructured meshes made of 2D and 3D geometries.\nBy reading this book, you will:\nMost importantly, you will learn a set of geospatial features that is much richer than the simple features implemented in traditional geographic information systems (GIS).\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#how-to-contribute",
    "href": "index.html#how-to-contribute",
    "title": "Geospatial Data Science with Julia",
    "section": "How to contribute?",
    "text": "How to contribute?\nFirst off, thank you for considering contributing to this book. It’s people like you that make this project so much fun. Below are a few suggestions to facilitate the review process:\n\nPlease be polite, we are here to help and learn from each other\nTry to explain your contribution with simple language\nReferences to textbooks and papers are always welcome\nFollow the code style in the examples as much as possible\n\nThis book is open source and fully reproducible thanks to the amazing Quarto project. You can edit the pages directly on GitHub and submit a pull request for review. If you are not familiar with this process, consider reading the first contributions guide.\nAlternatively, you can render the book locally with the Quarto VS Code Extension, which is the recommended method for reviewing more elaborate changes.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#getting-involved",
    "href": "index.html#getting-involved",
    "title": "Geospatial Data Science with Julia",
    "section": "Getting involved",
    "text": "Getting involved\nIf you would like to get involved with the project, you can start by\n\nJoining our community channel: \nStarring or sponsoring our book and software on GitHub: \nSharing the book on social media (LinkedIn, Twitter, …)\nAsking questions and making suggestions\nOrganizing training courses and workshops\nCiting the work in publications:\n@book{Hoffimann2023,\n  title = {Geospatial Data Science with {{Julia}}},\n  author = {Hoffimann, Júlio},\n  year = {2023},\n  doi = {10.5281/zenodo.10150870},\n  url = {https://juliaearth.github.io/geospatial-data-science-with-julia}\n}",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "foreword.html",
    "href": "foreword.html",
    "title": "Foreword",
    "section": "",
    "text": "I’ve always felt that something was off with existing approaches to geospatial data science in other programming languages. I remember sitting in the beautiful Green library at Stanford after a short introductory course on GIS with R, and wondering why it had to be so “computer sciency”:\n\nWhat on Earth is a “LineString”? Isn’t a “Line” a geometric object with infinite length?\nWhy do I need to learn this low-level distinction between “raster” and “vector” data?\nAnd many other questions…\n\nAfter years of my PhD, I finally envisioned a more general approach, through the continuous design and development of the  framework for the  programming language. This book is the first attempt to share this vision with the broader scientific community.\nThere is a long journey until the technology reaches its full potential, but it is getting there! I hope that the book will enlighten you on some of those issues and that you can benefit from the open source software we built over the years.",
    "crumbs": [
      "Foreword"
    ]
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "Preface",
    "section": "",
    "text": "Who this book is for\nAnyone interested in geospatial data science will benefit from reading this book. If you are a student with basic-to-intermediate programming experience, you will learn a valuable set of tools for your career. If you are an experienced data scientist, you may still be surprised by the generality of the framework presented here.\nThis is not a book on geostatistics. Although some chapters and examples will cover concepts from geostatistical theory, that is only to illustrate what is possible after you master geospatial data science with the  programming language.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#why-julia",
    "href": "preface.html#why-julia",
    "title": "Preface",
    "section": "Why Julia?",
    "text": "Why Julia?\nAn effective implementation of the framework presented in this book requires a language that can:\n\nGenerate high-performance code\nSpecialize on multiple arguments\nEvaluate code interactively\nExploit parallel hardware\n\nThis list of requirements eliminates Python, R and other mainstream languages used for data science.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#how-to-read-this-book",
    "href": "preface.html#how-to-read-this-book",
    "title": "Preface",
    "section": "How to read this book",
    "text": "How to read this book\nIf this is your first encounter with  or with programming in general, consider reading the open source book Think Julia: How to Think Like a Computer Scientist by Lauwens and Downey (2018). It introduces the language to first-time programmers and explains basic concepts that you will need to know to master the material here.\nIf you are an experienced programmer who just wants to quickly learn the syntax of the language, consider checking the Learn Julia in Y minutes website. If you are seeking more detailed information, consider reading the official documentation.\nAssuming that you learned the basics of the language, you can proceed and read this book. It is organized in five parts as follows:\n\n\n\n\n\nflowchart LR\n  preread[\"Julia basics ✅\"] --&gt; partI\n  subgraph partI[\"Part I: Foundations\"]\n    chapter1[\"(1) What is geospatial data?\"]\n    chapter2[\"(2) Scientific visualization\"]\n    chapter3[\"(3) Interfacing with GIS\"]\n    chapter4[\"(4) Geometric processing\"]\n    chapter1 --&gt; chapter2\n    chapter2 --&gt; chapter3\n    chapter3 --&gt; chapter4\n  end\n  subgraph partII[\"Part II: Transforms\"]\n    chapter5[\"(5) What are transforms?\"]\n    chapter6[\"(6) Map projections\"]\n    chapter7[\"(7) Building pipelines\"]\n    chapter5 --&gt; chapter6\n    chapter6 --&gt; chapter7\n  end\n  subgraph partIII[\"Part III: Queries\"]\n    chapter8[\"(8) Split-apply-combine\"]\n    chapter9[\"(9) Geospatial joins\"]\n    chapter8 --&gt; chapter9\n  end\n  subgraph partIV[\"Part IV: Interpolation\"]\n    chapter10[\"(10) Geospatial correlation\"]\n    chapter11[\"(11) Simple interpolation\"]\n    chapter10 --&gt; chapter11\n  end\n  subgraph partV[\"Part V: Applications\"]\n    chapter12[\"(12) Mineral deposits\"]\n    chapter13[\"(13) Agricultural fields\"]\n    chapter14[\"(14) Petroleum reservoirs\"]\n    chapter12 --&gt; chapter13\n    chapter13 --&gt; chapter14\n  end\n  partI --&gt; partII\n  partI --&gt; partIII\n  partI --&gt; partIV\n  partII --&gt; partV\n  partIII --&gt; partV\n  partIV --&gt; partV\n\n\n\n\n\n\nThe chapters were written to be read in sequence, but there is some flexibility on how to read the parts. I recommend reading Part I first to understand the framework and vision. After that, you will have the necessary background to follow the code examples in Part II, Part III and Part IV. Finally, you can explore the applications in Part V to solidify the concepts.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#software-installation",
    "href": "preface.html#software-installation",
    "title": "Preface",
    "section": "Software installation",
    "text": "Software installation\nIf you want to reproduce the examples in the book, copy and paste the code below in the Julia REPL:\nusing Pkg\n\n# assert Julia version\n@assert VERSION ≥ v\"1.11\" \"requires Julia v1.11 or later\"\n\n# create fresh environment\npkg\"activate @GDSJL\"\n\n# install framework\npkg\"add GeoStats@0.73.4\"\n\n# install IO module\npkg\"add GeoIO@1.19.10\"\n\n# install viz modules\npkg\"add CairoMakie@0.13.1\"\npkg\"add PairPlots@3.0.1\"\n\n# install other modules\npkg\"add DataFrames@1.7.0\"\nIf you need to reproduce the exact same environment with fixed versions of indirect dependencies, please download the Project.toml and Manifest.toml files that are stored on GitHub.\nSome examples require data files that are also stored on GitHub at this link.\nClick on any file of interest and press the download button.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#acknowledgements",
    "href": "preface.html#acknowledgements",
    "title": "Preface",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nI would like to acknowledge all the contributors of the  framework. You are the reason this book exists!  The implementation of the framework is only possible thanks to the amazing programming language advances by Bezanson et al. (2017).\nA special thanks to Elias Carvalho for his outstanding contributions to the software stack, to Prof. Douglas Mazzinghy (UFMG), Prof. Leandro Martínez (UNICAMP) and Prof. Fernando Moraes (UENF) for organizing the first training courses at universities, to Prof. Francisco Heron (UFC) for his contributions on high-performance computing, to Dr. João Pinelo (AIRCentre) for organizing the JuliaEO workshop, and to colleagues in industry who support this work through research and development projects, including Patrice Mazzoni, Keila Gonçalves, Fabio Duarte, Mariana Menezes, Givago Azevedo, Fernando Villanova, Luis Gomide.\nThanks to all the reviewers of the first draft, including Maciel Zortea, Max de Bayser, Bogumił Kamiński, Ronan Arraes, Erick Chacón Montalván, Kyle Beggs.\n\n\n\n\nBezanson, Jeff, Alan Edelman, Stefan Karpinski, and Viral B Shah. 2017. “Julia: A Fresh Approach to Numerical Computing.” SIAM Review 59 (1): 65–98. https://doi.org/10.1137/141000671.\n\n\nLauwens, Ben, and Allen Downey. 2018. Think Julia: How to Think Like a Computer Scientist. https://benlauwens.github.io/ThinkJulia.jl/latest/book.html.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "01-geodata.html",
    "href": "01-geodata.html",
    "title": "1  What is geospatial data?",
    "section": "",
    "text": "1.1 Definition\nWelcome to Part I of the book. Before we can start our journey in geospatial data science, we need to introduce important concepts, which will be the foundations of Part II, Part III and Part IV.\nIn this chapter, we define geospatial data and introduce a universal representation for it which is ideal for geostatistical analysis. Unlike other representations in the literature (e.g., “raster”, “vector” data), the proposed representation is suitable for encoding geospatial data over 3D unstructured meshes, 2D images embedded in 3D space, and other types of complex geospatial domains.\nThe definition depends on two other definitions that we clarify next.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is geospatial data?</span>"
    ]
  },
  {
    "objectID": "01-geodata.html#definition",
    "href": "01-geodata.html#definition",
    "title": "1  What is geospatial data?",
    "section": "",
    "text": "Definition\n\n\n\n(Discrete) geospatial data is the combination of a table of attributes (or features) with a discretization of a geospatial domain. Each row (or measurement) in the table corresponds to an element (or geometry) in the discretization of the geospatial domain.\n\n\n\n\n1.1.1 Table\nIn data science the most natural data structure for working with data is the table. Generally speaking, a table is any object that can be structured into rows containing measurements and columns representing variables. For example, Table 1.1 has 5 measurements of 4 variables:\n\n\n\nTable 1.1: Example of table\n\n\n\n\n\nNAME\nAGE\nHEIGHT\nGENDER\n\n\n\n\nJohn\n34\n1.78m\nmale\n\n\nMary\n12\n1.56m\nfemale\n\n\nPaul\n23\n1.70m\nmale\n\n\nAnne\n39\n1.80m\nfemale\n\n\nKate\n28\n1.72m\nfemale\n\n\n\n\n\n\nIn Julia, the concept of table is formalized in Tables.jl by Quinn et al. (2023). The definition is independent of the machine representation, and various representations can co-exist in the language.\n\n\n1.1.2 Domain\nThe second definition that we need is that of a geospatial domain. In geosciences, questions are often formulated within a physical region of interest. This physical region can cover a small area of the surface of the Earth, the entire Earth surface, or any region of finite measure that can be discretized into smaller geometries (a.k.a. elements):\n\n\n\n\n\n\n\n\n\n\n\n(a) Coast line in Islay Province, Peru. View on Google Maps\n\n\n\n\n\n\n\n\n\n\n\n(b) Synthetic carbonate reservoir model by Correia et al. (2015). See UNISIM-II for more details\n\n\n\n\n\n\n\nFigure 1.1: Example of geospatial domains\n\n\n\nFigure 1.1 illustrates two very different examples of geospatial domains. The domain in Figure 1.1 (a) is widely studied in GIS books. It is a 2D domain that contemplates a small area near Islay Province, Peru. The domain in Figure 1.1 (b) on the other hand is not considered in traditional GIS literature. It is a 3D domain that has been discretized into hexahedron geometries.\nThe concept of geospatial domain is formalized in Meshes.jl by Hoffimann et al. (2021).\n\n\n1.1.3 Remarks\n\nImages like the one depicted in Figure 1.1 (a) are often implemented in terms of the array data structure. GIS books call it “raster data”, but we will avoid this term in our framework in order to obtain a more general set of tools.\nAccording to our definition of geospatial data, “raster data” is simply a table with colors as variables (e.g., RGB values) combined with a grid of quadrangle geometries. We illustrate this concept in Figure 1.2 by zooming in a satellite image of the Lena delta:\n\n\n\n\n\n\n\n\n\n\n\n(a) “Raster data” of Lena delta\n\n\n\n\n\n\n\n\n\n\n\n(b) Zoom reveals quadrangle geometries\n\n\n\n\n\n\n\nFigure 1.2: Quadrangle geometries in “raster data”\n\n\n\nThere are no constraints on the geometries used in the discretization of the geospatial domain. In Figure 1.3, Brazil is discretized into complex polygonal geometries that represent country states:\n\n\n\n\n\n\nFigure 1.3: Brazil’s states represented with complex polygonal geometries. View on Google Maps.\n\n\n\nGIS books call it “vector data” because the geometries are stored as vectors of coordinates in memory. We will also avoid this term in our framework given that it only highlights an implementation detail.\n\nBefore we start discussing machine representation with actual Julia code, let’s make a final (pedantic) distinction between the words geospatial and spatial. These words mean different things in different communities:\n\nIn geosciences, an object is geospatial if it lives in physical space.\nIn statistics, a model is spatial if it exploits the vicinity of samples in the sample space.\n\nGiven that geospatial data science deals with both concepts, we must use these words carefully.\n\n\n\n\n\n\nNote\n\n\n\nIn Geostatistical Learning, models can exploit both spaces to improve prediction performance, but that is out of the scope for this book.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is geospatial data?</span>"
    ]
  },
  {
    "objectID": "01-geodata.html#representation",
    "href": "01-geodata.html#representation",
    "title": "1  What is geospatial data?",
    "section": "1.2 Representation",
    "text": "1.2 Representation\nBased on the definition of geospatial data given in the previous section, we are now ready to proceed and discuss an efficient machine representation for it with actual Julia code.\n\n1.2.1 Table\nThe Julia language comes with two built-in table representations:\n\nNamed tuple of vectors\nVector of named tuples\n\nThe first representation focuses on the columns of the table:\n\ncoltable = (\n  NAME=[\"John\", \"Mary\", \"Paul\", \"Anne\", \"Kate\"],\n  AGE=[34, 12, 23, 39, 28],\n  HEIGHT=[1.78, 1.56, 1.70, 1.80, 1.72],\n  GENDER=[\"male\", \"female\", \"male\", \"female\", \"female\"]\n)\n\n(NAME = [\"John\", \"Mary\", \"Paul\", \"Anne\", \"Kate\"], AGE = [34, 12, 23, 39, 28], HEIGHT = [1.78, 1.56, 1.7, 1.8, 1.72], GENDER = [\"male\", \"female\", \"male\", \"female\", \"female\"])\n\n\nGiven that data science is often performed with entire columns, this column-major representation of a table is very convenient. The second representation focuses on the rows of the table:\n\nrowtable = [\n  (NAME=\"John\", AGE=34, HEIGHT=1.78, GENDER=\"male\"),\n  (NAME=\"Mary\", AGE=12, HEIGHT=1.56, GENDER=\"female\"),\n  (NAME=\"Paul\", AGE=23, HEIGHT=1.70, GENDER=\"male\"),\n  (NAME=\"Anne\", AGE=39, HEIGHT=1.80, GENDER=\"female\"),\n  (NAME=\"Kate\", AGE=28, HEIGHT=1.72, GENDER=\"female\")\n]\n\n5-element Vector{@NamedTuple{NAME::String, AGE::Int64, HEIGHT::Float64, GENDER::String}}:\n (NAME = \"John\", AGE = 34, HEIGHT = 1.78, GENDER = \"male\")\n (NAME = \"Mary\", AGE = 12, HEIGHT = 1.56, GENDER = \"female\")\n (NAME = \"Paul\", AGE = 23, HEIGHT = 1.7, GENDER = \"male\")\n (NAME = \"Anne\", AGE = 39, HEIGHT = 1.8, GENDER = \"female\")\n (NAME = \"Kate\", AGE = 28, HEIGHT = 1.72, GENDER = \"female\")\n\n\nThe row-major representation can be useful to process data that is potentially larger than the available computer memory, or infinite streams of data.\nAlthough these two representations come built-in with Julia, they lack basic functionality for data science. The most widely used table representation for data science in Julia is available in DataFrames.jl by Bouchet-Valat and Kamiński (2023).\n\nusing DataFrames\n\ndf = DataFrame(\n  NAME=[\"John\", \"Mary\", \"Paul\", \"Anne\", \"Kate\"],\n  AGE=[34, 12, 23, 39, 28],\n  HEIGHT=[1.78, 1.56, 1.70, 1.80, 1.72],\n  GENDER=[\"male\", \"female\", \"male\", \"female\", \"female\"]\n)\n\nThis representation provides additional syntax for accessing rows and columns of the table:\n\ndf[1,:]\n\n\ndf[:,\"NAME\"]\n\n5-element Vector{String}:\n \"John\"\n \"Mary\"\n \"Paul\"\n \"Anne\"\n \"Kate\"\n\n\n\ndf[1:3,[\"NAME\",\"AGE\"]]\n\n\ndf.HEIGHT\n\n5-element Vector{Float64}:\n 1.78\n 1.56\n 1.7\n 1.8\n 1.72\n\n\n\ndf.\"HEIGHT\"\n\n5-element Vector{Float64}:\n 1.78\n 1.56\n 1.7\n 1.8\n 1.72\n\n\n\n\n\n\n\n\nNote\n\n\n\nUnlike other languages, Julia makes a distinction between the the symbol :HEIGHT and the string \"HEIGHT\". The DataFrame representation supports both types for column names, but that is not always the case with other table representations.\n\n\nOther popular table representations in Julia are associated with specific file formats:\n\nCSV.File from CSV.jl\nXLSX.Worksheet from XLSX.jl\nDatabases from JuliaDatabases\n\nThe choice of table representation is a function of the application.\n\n\n1.2.2 Domain\nAll available domain representations come from the Meshes.jl module.\nLet’s start with a simple list of disconnected geometries:\n\nusing GeoStats\n\np = Point(1, 2)\ns = Segment((0, 2), (1, 3))\nt = Triangle((0, 0), (1, 0), (1, 1))\nb = Ball((2, 2), 1)\n\ngeoms = [p, s, t, b]\n\n4-element Vector{Geometry{𝔼{2}, Cartesian2D{NoDatum, Quantity{Float64, 𝐋, Unitful.FreeUnits{(m,), 𝐋, nothing}}}}}:\n Point(x: 1.0 m, y: 2.0 m)\n Segment((x: 0.0 m, y: 2.0 m), (x: 1.0 m, y: 3.0 m))\n Triangle((x: 0.0 m, y: 0.0 m), (x: 1.0 m, y: 0.0 m), (x: 1.0 m, y: 1.0 m))\n Ball(center: (x: 2.0 m, y: 2.0 m), radius: 1.0 m)\n\n\nBecause these geometries are unaware of each other, we place them into a GeometrySet, informally known in computational geometry as the “soup of geometries” data structure:\n\ngset = GeometrySet(geoms)\n\n4 GeometrySet\n├─ Point(x: 1.0 m, y: 2.0 m)\n├─ Segment((x: 0.0 m, y: 2.0 m), (x: 1.0 m, y: 3.0 m))\n├─ Triangle((x: 0.0 m, y: 0.0 m), (x: 1.0 m, y: 0.0 m), (x: 1.0 m, y: 1.0 m))\n└─ Ball(center: (x: 2.0 m, y: 2.0 m), radius: 1.0 m)\n\n\nNo advanced knowledge is required to start working with these geometries. For example, we can compute the length of the Segment, the area of the Triangle and the area of the Ball with:\n\nlength(s), area(t), area(b)\n\n(1.4142135623730951 m, 0.5 m^2, 3.141592653589793 m^2)\n\n\nMore generally, we can compute the measure of the geometries in the domain:\n\n[measure(g) for g in gset]\n\n4-element Vector{Quantity{Float64}}:\n 0.0 m\n 1.4142135623730951 m\n 0.5 m^2\n 3.141592653589793 m^2\n\n\nIn the example above, we iterated over the domain to apply the function of interest, but we could have used Julia’s dot syntax for broadcasting the function over the geometries:\n\nmeasure.(gset)\n\n4-element Vector{Quantity{Float64}}:\n 0.0 m\n 1.4142135623730951 m\n 0.5 m^2\n 3.141592653589793 m^2\n\n\nThe list of supported geometries is very comprehensive. It encompasses all geometries from the simple features standard and more. We will see more examples in the following chapters.\nOne of the main limitations of GIS software today is the lack of explicit representation of topology. A GeometrySet does not provide efficient topological relations (Floriani and Hui 2007), yet advanced geospatial data science requires the definition of geospatial domains where geometries are aware of their neighbors. Let’s illustrate this concept with the CartesianGrid domain:\n\ngrid = CartesianGrid(10, 10)\n\n10×10 CartesianGrid\n├─ minimum: Point(x: 0.0 m, y: 0.0 m)\n├─ maximum: Point(x: 10.0 m, y: 10.0 m)\n└─ spacing: (1.0 m, 1.0 m)\n\n\nWe can access the individual geometries of the domain as before:\n\ngrid[1]\n\nQuadrangle\n├─ Point(x: 0.0 m, y: 0.0 m)\n├─ Point(x: 1.0 m, y: 0.0 m)\n├─ Point(x: 1.0 m, y: 1.0 m)\n└─ Point(x: 0.0 m, y: 1.0 m)\n\n\nAnd even though we can manipulate this domain as if it was a “soup of geometries”, the major advantage in this abstraction is the underlying topology:\n\ntopo = topology(grid)\n\n10×10 GridTopology(aperiodic, aperiodic)\n\n\nThis data structure can be used by advanced users who wish to design algorithms with neighborhood information. We will cover this topic in a separate chapter. For now, keep in mind that working with the entire domain as opposed to with a vector or “soup of geometries” has major benefits.\n\n\n\n\n\n\nNote\n\n\n\nThe CartesianGrid domain is lazy, meaning it only stores the start and end points of the grid together with the spacing between the elements. Therefore, we can easily create large 3D grids of Hexahedron geometries without consuming all available memory:\n\ngrid = CartesianGrid(10000, 10000, 10000)\n\n10000×10000×10000 CartesianGrid\n├─ minimum: Point(x: 0.0 m, y: 0.0 m, z: 0.0 m)\n├─ maximum: Point(x: 10000.0 m, y: 10000.0 m, z: 10000.0 m)\n└─ spacing: (1.0 m, 1.0 m, 1.0 m)\n\n\n\ngrid[1]\n\nHexahedron\n├─ Point(x: 0.0 m, y: 0.0 m, z: 0.0 m)\n├─ Point(x: 1.0 m, y: 0.0 m, z: 0.0 m)\n├─ Point(x: 1.0 m, y: 1.0 m, z: 0.0 m)\n├─ Point(x: 0.0 m, y: 1.0 m, z: 0.0 m)\n├─ Point(x: 0.0 m, y: 0.0 m, z: 1.0 m)\n├─ Point(x: 1.0 m, y: 0.0 m, z: 1.0 m)\n├─ Point(x: 1.0 m, y: 1.0 m, z: 1.0 m)\n└─ Point(x: 0.0 m, y: 1.0 m, z: 1.0 m)\n\n\n\n\nIn computational geometry, a CartesianGrid is a specific type of mesh. It can only represent “flat” domains sampled regularly along each dimension (e.g., images). To represent domains with curvature such as terrain elevation models or complex 3D domains like the one in Figure 1.1 (b), we can use the SimpleMesh domain:\n\n# global vector of 2D points\npoints = [(0.0, 0.0), (1.0, 0.0), (0.0, 1.0), (1.0, 1.0), (0.25, 0.5), (0.75, 0.5)]\n\n# connect the points into N-gons\nconnec = connect.([(1, 2, 6, 5), (2, 4, 6), (4, 3, 5, 6), (3, 1, 5)])\n\n# 2D mesh made of N-gon elements\nmesh = SimpleMesh(points, connec)\n\n4 SimpleMesh\n  6 vertices\n  ├─ Point(x: 0.0 m, y: 0.0 m)\n  ├─ Point(x: 1.0 m, y: 0.0 m)\n  ├─ Point(x: 0.0 m, y: 1.0 m)\n  ├─ Point(x: 1.0 m, y: 1.0 m)\n  ├─ Point(x: 0.25 m, y: 0.5 m)\n  └─ Point(x: 0.75 m, y: 0.5 m)\n  4 elements\n  ├─ Quadrangle(1, 2, 6, 5)\n  ├─ Triangle(2, 4, 6)\n  ├─ Quadrangle(4, 3, 5, 6)\n  └─ Triangle(3, 1, 5)\n\n\nThe connect function takes a tuple of indices and a geometry type, and produces a connectivity object. The geometry type can be omitted, in which case it is assumed to be a Ngon, i.e., a polygon with N sides:\n\nc = connect((1, 2, 3))\n\nTriangle(1, 2, 3)\n\n\nThis connectivity object can be materialized into an actual geometry with a vector of points:\n\nmaterialize(c, [Point(0, 0), Point(1, 0), Point(1, 1)])\n\nTriangle\n├─ Point(x: 0.0 m, y: 0.0 m)\n├─ Point(x: 1.0 m, y: 0.0 m)\n└─ Point(x: 1.0 m, y: 1.0 m)\n\n\nThe SimpleMesh uses the materialize function above to construct geometries on the fly, similar to what we have seen with the CartesianGrid:\n\nmesh[1]\n\nQuadrangle\n├─ Point(x: 0.0 m, y: 0.0 m)\n├─ Point(x: 1.0 m, y: 0.0 m)\n├─ Point(x: 0.75 m, y: 0.5 m)\n└─ Point(x: 0.25 m, y: 0.5 m)\n\n\nDon’t worry if you feel overwhelmed by these concepts. We are only sharing them here to give you an idea of how complex 3D domains are represented in the framework. You can do geospatial data science without ever having to operate with these concepts explicitly.\nLet’s make a few important remarks:\n\nFlexibility comes with a price. To construct a SimpleMesh of connected geometries we need to explicitly create a vector of vertices, and connect these vertices into geometries using their indices in the vector.\nGeometries in a SimpleMesh can be of different type. In the example, we have both Triangle and Quadrangle geometries in the domain. This is similar to what we had with GeometrySet, but now the geometries are connected.\nSimpleMesh are rarely constructed by hand. They are often the result of a sophisticated geometric processing pipeline that is already stored in a file on disk.\n\nThe last missing piece of the puzzle is the combination of tables with domains into geospatial data, which we discuss next.\n\n\n1.2.3 Data\nWouldn’t it be nice if we had a representation of geospatial data that behaved like a table as discussed in the Tables section, but preserved topological information as discussed in the Domains section? In the GeoStats.jl framework, this is precisely what we get with the georef function:\n\nusing GeoStats\n\ndf = DataFrame(\n  NAME=[\"John\", \"Mary\", \"Paul\", \"Anne\"],\n  AGE=[34.0, 12.0, 23.0, 39.0]u\"yr\",\n  HEIGHT=[1.78, 1.56, 1.70, 1.80]u\"m\",\n  GENDER=[\"male\", \"female\", \"male\", \"female\"]\n)\n\ngrid = CartesianGrid(2, 2)\n\ngeotable = georef(df, grid)\n\n\n4×5 GeoTable over 2×2 CartesianGrid\n\n\nNAME\nAGE\nHEIGHT\nGENDER\ngeometry\n\n\nCategorical\nContinuous\nContinuous\nCategorical\nQuadrangle\n\n\n[NoUnits]\n[yr]\n[m]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\nJohn\n34.0 yr\n1.78 m\nmale\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\nMary\n12.0 yr\n1.56 m\nfemale\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\nPaul\n23.0 yr\n1.7 m\nmale\nQuadrangle((x: 0.0 m, y: 1.0 m), ..., (x: 0.0 m, y: 2.0 m))\n\n\nAnne\n39.0 yr\n1.8 m\nfemale\nQuadrangle((x: 1.0 m, y: 1.0 m), ..., (x: 1.0 m, y: 2.0 m))\n\n\n\n\n\n\n\n\n\n\n\nTip for all users\n\n\n\nThe framework is integrated with the Unitful.jl module. To add the unit “meter” to the numeric value 1.0, we can write 1.0u\"m\". Similarly, we can add units to vectors of values:\n\n[1.0, 2.0, 3.0]u\"m\"\n\n3-element Vector{Quantity{Float64, 𝐋, Unitful.FreeUnits{(m,), 𝐋, nothing}}}:\n 1.0 m\n 2.0 m\n 3.0 m\n\n\nIt is also possible to load units explicitly to avoid the “u” prefix:\nusing Unitful: m, ft\n\n1.0m + 2.0ft\n\n\nThe function combines any table with any domain into a geospatial data representation that adheres to the Tables.jl interface. We call this representation a GeoTable to distinguish it from a standard table. Besides the original columns, the GeoTable has a special geometry column with the underlying domain:\n\nnames(geotable)\n\n5-element Vector{String}:\n \"NAME\"\n \"AGE\"\n \"HEIGHT\"\n \"GENDER\"\n \"geometry\"\n\n\nUnlike a standard table, the GeoTable creates geometries on the fly depending on the data access pattern. For example, we can request the first measurement of the GeoTable and it will automatically construct the corresponding Quadrangle:\n\ngeotable[1,:]\n\n(NAME = \"John\", AGE = 34.0 yr, HEIGHT = 1.78 m, GENDER = \"male\", geometry = Quadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m)))\n\n\nIf we request a subset of measurements, the GeoTable will avoid unnecessary creation of geometries, and will instead return a view into the original data:\n\ngeotable[1:3,[\"NAME\",\"AGE\"]]\n\n\n3×3 GeoTable over 3 view(::CartesianGrid, 1:3)\n\n\nNAME\nAGE\ngeometry\n\n\nCategorical\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[yr]\n🖈 Cartesian{NoDatum}\n\n\n\n\nJohn\n34.0 yr\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\nMary\n12.0 yr\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\nPaul\n23.0 yr\nQuadrangle((x: 0.0 m, y: 1.0 m), ..., (x: 0.0 m, y: 2.0 m))\n\n\n\n\n\nFinally, if we request the entire geometry column, we get back the original domain:\n\ngeotable[:,\"geometry\"]\n\n2×2 CartesianGrid\n├─ minimum: Point(x: 0.0 m, y: 0.0 m)\n├─ maximum: Point(x: 2.0 m, y: 2.0 m)\n└─ spacing: (1.0 m, 1.0 m)\n\n\nBesides the data access patterns of the DataFrame, the GeoTable also provides an advanced method for retrieving all rows that intersect with a given geometry:\n\ngeotable[Segment((0, 0), (2, 0)), :]\n\n\n2×5 GeoTable over 2 view(::CartesianGrid, [1, 2])\n\n\nNAME\nAGE\nHEIGHT\nGENDER\ngeometry\n\n\nCategorical\nContinuous\nContinuous\nCategorical\nQuadrangle\n\n\n[NoUnits]\n[yr]\n[m]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\nJohn\n34.0 yr\n1.78 m\nmale\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\nMary\n12.0 yr\n1.56 m\nfemale\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\n\n\n\nThis method is very useful to narrow the region of interest and quickly discard all measurements that are outside of it. For instance, it is common to discard all “pixels” outside of a polygon before exporting the geotable to a file on disk.\nNotice that the GeoTable representation is general enough to accommodate both “raster data” and “vector data” in traditional GIS. We can create very large rasters because the CartesianGrid is lazy:\n\ngeoref(\n  (\n    R=rand(1000000),\n    G=rand(1000000),\n    B=rand(1000000)\n  ),\n  CartesianGrid(1000, 1000)\n)\n\n\n1000000×4 GeoTable over 1000×1000 CartesianGrid\n\n\nR\nG\nB\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n0.33195\n0.681245\n0.0306698\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\n0.0646401\n0.771028\n0.777815\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\n0.720224\n0.768791\n0.70103\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 1.0 m))\n\n\n0.222993\n0.656516\n0.529195\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 1.0 m))\n\n\n0.501018\n0.668166\n0.0142756\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 1.0 m))\n\n\n0.8528\n0.768712\n0.581367\nQuadrangle((x: 5.0 m, y: 0.0 m), ..., (x: 5.0 m, y: 1.0 m))\n\n\n0.653225\n0.386806\n0.690323\nQuadrangle((x: 6.0 m, y: 0.0 m), ..., (x: 6.0 m, y: 1.0 m))\n\n\n0.259549\n0.548992\n0.951362\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 1.0 m))\n\n\n0.865173\n0.625383\n0.81126\nQuadrangle((x: 8.0 m, y: 0.0 m), ..., (x: 8.0 m, y: 1.0 m))\n\n\n0.518125\n0.00463774\n0.0806121\nQuadrangle((x: 9.0 m, y: 0.0 m), ..., (x: 9.0 m, y: 1.0 m))\n\n\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nAnd can load vector geometries from files that store simple features using the GeoIO.jl module:\n\nusing GeoIO\n\nGeoIO.load(\"data/countries.geojson\")\n\n\n177×3 GeoTable over 177 GeometrySet\n\n\nCOUNTRY\nREGION\ngeometry\n\n\nCategorical\nCategorical\nMultiPolygon\n\n\n[NoUnits]\n[NoUnits]\n🖈 GeodeticLatLon{WGS84Latest}\n\n\n\n\nFiji\nMelanesia\nMulti(3×PolyArea)\n\n\nTanzania\nEastern Africa\nMulti(1×PolyArea)\n\n\nW. Sahara\nNorthern Africa\nMulti(1×PolyArea)\n\n\nCanada\nNorthern America\nMulti(30×PolyArea)\n\n\nUnited States of America\nNorthern America\nMulti(10×PolyArea)\n\n\nKazakhstan\nCentral Asia\nMulti(1×PolyArea)\n\n\nUzbekistan\nCentral Asia\nMulti(1×PolyArea)\n\n\nPapua New Guinea\nMelanesia\nMulti(4×PolyArea)\n\n\nIndonesia\nSouth-Eastern Asia\nMulti(13×PolyArea)\n\n\nArgentina\nSouth America\nMulti(2×PolyArea)\n\n\n⋮\n⋮\n⋮\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe “data” folder is stored on GitHub. Check the Preface for download instructions.\n\n\nWe will see more examples of “vector data” in the chapter Interfacing with GIS, and will explain why file formats like Shapefile.jl and GeoJSON.jl are not enough for advanced geospatial data science.\n\n\n\n\n\n\nTip for all users\n\n\n\nThe GeoStats.jl module reexports the full stack of modules for geospatial data science in Julia. There is no need to import modules like Meshes.jl explicitly. You are all set if you start your script with\nusing GeoStats\n\n\n\n\n\n\n\n\nTip for advanced users\n\n\n\nIn Julia, a function is type-stable if the return type is known at compile time. Since the GeoTable has columns from the original table (e.g., numbers) and an additional special geometry column, the access to the data with the DataFrame syntax is not type stable. If you need to write type-stable code, use the functions values and domain instead:\n\nvalues(geotable)\n\n4×4 DataFrame\n\n\n\nRow\nNAME\nAGE\nHEIGHT\nGENDER\n\n\n\nString\nQuantity…\nQuantity…\nString\n\n\n\n\n1\nJohn\n34.0 yr\n1.78 m\nmale\n\n\n2\nMary\n12.0 yr\n1.56 m\nfemale\n\n\n3\nPaul\n23.0 yr\n1.7 m\nmale\n\n\n4\nAnne\n39.0 yr\n1.8 m\nfemale\n\n\n\n\n\n\n\ndomain(geotable)\n\n2×2 CartesianGrid\n├─ minimum: Point(x: 0.0 m, y: 0.0 m)\n├─ maximum: Point(x: 2.0 m, y: 2.0 m)\n└─ spacing: (1.0 m, 1.0 m)",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is geospatial data?</span>"
    ]
  },
  {
    "objectID": "01-geodata.html#remarks-1",
    "href": "01-geodata.html#remarks-1",
    "title": "1  What is geospatial data?",
    "section": "1.3 Remarks",
    "text": "1.3 Remarks\nWhat did we learn in this chapter?\n\nGeospatial data can be efficiently represented as a GeoTable. This representation is universal, meaning it combines the “raster” and “vector” representations found in traditional GIS.\nA GeoTable provides all the data access patterns of a DataFrame. In particular, it supports the syntax geotable[rows,cols] without expensive copies of geometries.\nWorking with geospatial domains as opposed to working with vectors of disconnected geometries has major benefits. In particular, it preserves topological information.\n\nIt is very convenient to manipulate a GeoTable as if it was a DataFrame. Nevertheless, we will learn that advanced geospatial data science requires higher-level constructs to preserve geospatial information. We will cover these constructs in Part II and Part III of the book.\n\n\n\n\nBouchet-Valat, Milan, and Bogumił Kamiński. 2023. “DataFrames.jl: Flexible and Fast Tabular Data in Julia.” Journal of Statistical Software 107 (4): 1–32. https://doi.org/10.18637/jss.v107.i04.\n\n\nCorreia, M.., J.. Hohendorff, A. T. Gaspar, and D.. Schiozer. 2015. UNISIM-II-D: Benchmark Case Proposal Based on a Carbonate Reservoir. Vol. Day 3 Fri, November 20, 2015. SPE Latin America and Caribbean Petroleum Engineering Conference. https://doi.org/10.2118/177140-MS.\n\n\nFloriani, L. De, and A. Hui. 2007. “Shape Representations Based on Simplicial and Cell Complexes.” In Eurographics 2007 - State of the Art Reports, edited by Dieter Schmalstieg and Jiri Bittner. The Eurographics Association. https://doi.org/10.2312/egst.20071055.\n\n\nHoffimann, Júlio, Maciel Zortea, Breno de Carvalho, and Bianca Zadrozny. 2021. “Geostatistical Learning: Challenges and Opportunities.” Frontiers in Applied Mathematics and Statistics 7. https://doi.org/10.3389/fams.2021.689393.\n\n\nQuinn, Jacob, Bogumił Kamiński, David Anthoff, Milan Bouchet-Valat, Tamas K. Papp, Takafumi Arakaki, Rafael Schouten, et al. 2023. “JuliaData/Tables.jl: V1.10.1.” Zenodo. https://doi.org/10.5281/zenodo.7730968.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is geospatial data?</span>"
    ]
  },
  {
    "objectID": "02-geoviz.html",
    "href": "02-geoviz.html",
    "title": "2  Scientific visualization",
    "section": "",
    "text": "2.1 viz/viz!\nThe visualization ecosystem in Julia is evolving very quickly. Among the various visualization projects, Makie.jl by Danisch and Krumbiegel (2021) is the most advanced for scientific visualization.\nMakie.jl is currently organized in backend modules:\nIn this book, we use CairoMakie.jl:\nMakie.jl provides a plot recipe system developed after Plots.jl by Breloff (2023), which enables automatic visualization of custom Julia types. The GeoStats.jl framework is integrated with this system, and provides powerful visualization functions for geospatial data.\nJulia will automatically trigger the compilation of these visualization functions whenever GeoStats.jl and Makie.jl are loaded in the same session:\nThe main visualization function that the framework provides is the viz/viz! function. The viz function creates a scene and displays geometries within a geospatial domain. On the other hand, the viz! function adds more geometries to an existing scene.\nLet’s create a small geotable over a Cartesian grid for illustration purposes:\nimg = georef((A=rand(10, 10), B=rand(10, 10)))\n\n\n100×3 GeoTable over 10×10 CartesianGrid\n\n\nA\nB\ngeometry\n\n\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n0.734697\n0.514796\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\n0.762102\n0.377287\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\n0.156078\n0.307941\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 1.0 m))\n\n\n0.798288\n0.297411\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 1.0 m))\n\n\n0.730699\n0.547037\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 1.0 m))\n\n\n0.270911\n0.473235\nQuadrangle((x: 5.0 m, y: 0.0 m), ..., (x: 5.0 m, y: 1.0 m))\n\n\n0.822762\n0.656424\nQuadrangle((x: 6.0 m, y: 0.0 m), ..., (x: 6.0 m, y: 1.0 m))\n\n\n0.391484\n0.735967\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 1.0 m))\n\n\n0.64697\n0.411879\nQuadrangle((x: 8.0 m, y: 0.0 m), ..., (x: 8.0 m, y: 1.0 m))\n\n\n0.24524\n0.181046\nQuadrangle((x: 9.0 m, y: 0.0 m), ..., (x: 9.0 m, y: 1.0 m))\n\n\n⋮\n⋮\n⋮\nBy default, all geometries are displayed with a single color:\nviz(img.geometry)\nWe can pass any vector of Colors.jl or numbers (automatically converted to colors) to the function via the color option. It is common to pass colors from another column of the geotable:\nviz(img.geometry, color = img.A)\nbut any vector with the same length can be passed:\nviz(img.geometry, color = 1:length(img.A))\nThe alpha option can be used to control the transparency of each geometry in the domain:\nviz(img.geometry, color = img.B, alpha = rand(length(img.B)))\nOther aesthetic options are available in the official documentation.\nAs another example, consider the visualization of data over a GeometrySet:\ngset = GeometrySet([\n  Triangle((12, 12), (15, 15), (12, 15)),\n  Quadrangle((5, 12), (10, 15), (10, 18), (5, 15))\n])\n\ngis = georef((A=[0.1, 0.2], B=[0.3, 0.4]), gset)\n\nviz(gis.geometry, color = gis.A)\nWe can create a scene with the geometries from the first geotable (“raster data”), and then add the geometries from the second geotable (“vector data”):\nviz(img.geometry)\nviz!(gis.geometry)\n\n# display current figure\nMke.current_figure()\nLet’s add an additional set of points and line segments to conclude the example:\nviz!([Point(-20, -10), Point(-20, 0), Point(-40, 10)])\nviz!([Segment((-40, -10), (0, 0)), Segment((-40, 0), (-20, 10))])\n\nMke.current_figure()\nThe viz and viz! functions are aware of coordinate reference systems, which is a quite unique feature of the framework, explored in the chapter Map projections.\nBelow is a preview of this feature in action:\nusing GeoIO\n\nworld = GeoIO.load(\"data/countries.geojson\")\n\nviz(world.geometry, color = 1:nrow(world))",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Scientific visualization</span>"
    ]
  },
  {
    "objectID": "02-geoviz.html#vizviz",
    "href": "02-geoviz.html#vizviz",
    "title": "2  Scientific visualization",
    "section": "",
    "text": "Note\n\n\n\nThe georef function creates a CartesianGrid starting at the origin whenever the domain is omitted. The size of the grid is taken as the size of the first array in the named tuple:\n\nimg.geometry\n\n10×10 CartesianGrid\n├─ minimum: Point(x: 0.0 m, y: 0.0 m)\n├─ maximum: Point(x: 10.0 m, y: 10.0 m)\n└─ spacing: (1.0 m, 1.0 m)\n\n\n\n\n\n\n\n\n\n\nTip for all users\n\n\n\nTo create a named tuple with a single key in Julia, we need an extra comma after the key/value pair:\n\n(A=rand(10, 10),)\n\n(A = [0.5581043672716959 0.5054665531019492 … 0.4513733139201258 0.41543615383561316; 0.2823662642837468 0.6715229331137479 … 0.33963557638926944 0.9153053157287051; … ; 0.8945476199275371 0.8124145441202367 … 0.05209127250025514 0.5914233240365571; 0.8943218831047535 0.2660840035165557 … 0.9251544739707117 0.8783936614646527],)\n\n\nor a semicolon before the key/value pair:\n\n(; A=rand(10, 10))\n\n(A = [0.38900864620439823 0.9824373975194511 … 0.27234437589709115 0.8295852176954704; 0.12190964236620339 0.43286872081109184 … 0.1286719017955107 0.6819544387274471; … ; 0.4398231084520121 0.8644222380480219 … 0.7403103402535874 0.009539218145921069; 0.6561054851997129 0.46526296361899444 … 0.5327476386369338 0.34987866436037707],)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip for all users\n\n\n\nMakie.jl can set the aspect ratio of the axis after the visualization is created. The following code can be used to adjust the aspect ratio for the data in the scene:\n\nax = Mke.current_axis()\nax.aspect = Mke.DataAspect()\nMke.current_figure()\n\n\n\n\nAlternatively, it is possible to set the aspect ratio in the viz/viz! call directly:\n\nviz(CartesianGrid(20, 10), color = 1:200, axis = (; aspect = Mke.DataAspect()))\n\n\n\n\n\n\n\n\n\n\n\n\nTip for advanced users\n\n\n\nMakie.jl dispatches the viz and viz! functions whenever it encounters a geospatial domain, a vector of geometries or a single geometry from Meshes.jl. This means that you can replace viz with Mke.plot and viz! with Mke.plot! in scripts and the result will be the same.\n\n\n\n\n\n\n\n\nTip for advanced users\n\n\n\nIn the case of Mesh domains, it is also possible to specify a color for each vertex of the mesh. In this case, the viz and viz! functions fill in the domain with using the interpolation routine from the graphics library:\n\ngrid = CartesianGrid(10, 10)\n\nfig = Mke.Figure()\nviz(fig[1,1], grid, color = 1:nelements(grid))\nviz(fig[1,2], grid, color = 1:nvertices(grid))\nfig",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Scientific visualization</span>"
    ]
  },
  {
    "objectID": "02-geoviz.html#viewer",
    "href": "02-geoviz.html#viewer",
    "title": "2  Scientific visualization",
    "section": "2.2 viewer",
    "text": "2.2 viewer\nAs geospatial data scientists we are often interested in quick inspection of intermediate results from multivariate geostatistical analysis. Visualizing all the variables manually with viz/viz! can be very time consuming. To address this issue, the framework provides a basic viewer that displays all variables stored in a geotable:\n\ngeotable = georef((A=rand(1000), B=rand(1000)), rand(Point, 1000))\n\nviewer(geotable)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe rand(Point, 1000) function call creates 1000 random Points in 3D space.\n\n\nIt adds interactive elements to the scene, including a menu to select the variable used as color, and a color bar that automatically updates upon menu selection. The viewer will be particularly useful when we start to work with geospatial transforms in Part II of the book. The pipe operator (|&gt;) in Julia will be preferred for reasons that will become clear later:\n\ngeotable = georef((A=rand(1000), B=rand(1000)), CartesianGrid(10, 10, 10))\n\ngeotable |&gt; viewer\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe viz/viz! and the viewer automatically select color schemes for variables based on data science traits from the DataScienceTraits.jl module. Additionally, the viewer recognizes units from the Unitful.jl module:\n\ngeotable = georef((; A=[1,2,3,4]u\"m\"), CartesianGrid(2, 2))\n\ngeotable |&gt; viewer",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Scientific visualization</span>"
    ]
  },
  {
    "objectID": "02-geoviz.html#cbar",
    "href": "02-geoviz.html#cbar",
    "title": "2  Scientific visualization",
    "section": "2.3 cbar",
    "text": "2.3 cbar\nAny vector of Julia objects implementing the getcolors function from the Colorfy.jl module can be passed to the color option of viz/viz!. The final vector of colors will be a function of the colormap and colorrange options.\nTo reproduce this behavior in the colorbar, the framework provides the cbar function. It is similar to Makie’s colorbar, but addresses various practical challenges with missing values, units, etc.\n\ngrid = CartesianGrid(2, 2)\nvals = [1, missing, 3, 4]\ncmap = \"cividis\"\n\nfig = Mke.Figure()\nviz(fig[1,1], grid, color = vals, colormap = cmap)\ncbar(fig[1,2], vals, colormap = cmap)\nfig\n\n\n\n\nWe are now equipped with a set of visualization functions that can really improve the speed at which we explore and analyze geospatial data. These functions provide a consistent set of aesthetic options that we will cover in more detail with future examples.\nBefore we start learning the advanced features of the framework, we would like to say a few words about integration with existing GIS technology.\n\n\n\n\nBreloff, Tom. 2023. “Plots.jl.” Zenodo. https://doi.org/10.5281/zenodo.8183938.\n\n\nDanisch, Simon, and Julius Krumbiegel. 2021. “Makie.jl: Flexible High-Performance Data Visualization for Julia.” Journal of Open Source Software 6 (65): 3349. https://doi.org/10.21105/joss.03349.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Scientific visualization</span>"
    ]
  },
  {
    "objectID": "03-geoio.html",
    "href": "03-geoio.html",
    "title": "3  Interfacing with GIS",
    "section": "",
    "text": "3.1 GeoIO.jl\nIn order to disrupt existing practices and really develop something new in Julia, we had to make some hard decisions along the way. One of these decisions relates to how we are willing to interface our framework with existing GIS standards and workflows.\nOn the one hand, we could have followed the path that was followed by other communities such as Python and R, and focus our energy interfacing with well-tested GIS libraries written in C/C++ (e.g., GDAL, GEOS). This is precisely what the JuliaGeo organization has been doing over the years, and it is an important agenda to bring people from other languages that are used to the OGC standards.\nOn the other hand, we have young geoscientists and first-time programmers who have never studied GIS before, and who really struggle learning the technology as it is today. The widespread emphasis on machine representation and software engineering has created a gap between the developers and the users of GIS software. A typical gap the Julia programming language helps to close.\nWe decided to limit our interface with existing GIS technology to input and output (IO) of files while it matures. This gives users of the framework the chance to\nIt creates an ecosystem where users can become contributors and maintainers of the framework, without any knowledge of a second programming language.\nThe GeoIO.jl module can load and save geospatial data on disk in a variety of formats, including the most popular formats in GIS (e.g., .shp, .geojson, .kml, .parquet) thanks to various backend packages spread across various Julia organizations. It is designed for users who just want to get their data ready for geospatial data science.\nTo load a file from disk, we use GeoIO.load:\nThe function automatically selects the backend based on the file extension, converts the simple features into a geospatial domain, and returns a GeoTable.\nTo save the GeoTable to disk, possibly in a different format, we use GeoIO.save:\nThe module fixes inconsistencies between formats whenever possible. For example, the GeoJSON format writes Date columns as String because the JSON format has no date types. The Shapefile format has its own limitations, etc.\nOver time, we expect to improve the ecosystem as a whole by highlighting various issues with available standards and backend implementations.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Interfacing with GIS</span>"
    ]
  },
  {
    "objectID": "03-geoio.html#geoio.jl",
    "href": "03-geoio.html#geoio.jl",
    "title": "3  Interfacing with GIS",
    "section": "",
    "text": "using GeoIO\n\ngeotable = GeoIO.load(\"file.shp\")\n\n\nGeoIO.save(\"file.geojson\", geotable)",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Interfacing with GIS</span>"
    ]
  },
  {
    "objectID": "03-geoio.html#file-formats",
    "href": "03-geoio.html#file-formats",
    "title": "3  Interfacing with GIS",
    "section": "3.2 File formats",
    "text": "3.2 File formats\nMost GIS file formats do not preserve topological information. This means that neighborhood information is lost as soon as geometries are saved to disk. To illustrate this issue, we consider a geotable over a grid:\n\nusing GeoIO\n\nearth = GeoIO.load(\"data/earth.tif\")\n\n\n656100×2 GeoTable over 810×810 TransformedGrid\n\n\ncolor\ngeometry\n\n\nColorful\nQuadrangle\n\n\n[NoUnits]\n🖈 GeodeticLatLon{WGS84Latest}\n\n\n\n\nRGB{N0f8}(0.525, 0.71, 0.824)\nQuadrangle((lat: 90.0°, lon: -180.0°), ..., (lat: 89.7778°, lon: -180.0°))\n\n\nRGB{N0f8}(0.525, 0.71, 0.831)\nQuadrangle((lat: 90.0°, lon: -179.556°), ..., (lat: 89.7778°, lon: -179.556°))\n\n\nRGB{N0f8}(0.525, 0.71, 0.827)\nQuadrangle((lat: 90.0°, lon: -179.111°), ..., (lat: 89.7778°, lon: -179.111°))\n\n\nRGB{N0f8}(0.525, 0.71, 0.824)\nQuadrangle((lat: 90.0°, lon: -178.667°), ..., (lat: 89.7778°, lon: -178.667°))\n\n\nRGB{N0f8}(0.525, 0.71, 0.824)\nQuadrangle((lat: 90.0°, lon: -178.222°), ..., (lat: 89.7778°, lon: -178.222°))\n\n\nRGB{N0f8}(0.522, 0.71, 0.831)\nQuadrangle((lat: 90.0°, lon: -177.778°), ..., (lat: 89.7778°, lon: -177.778°))\n\n\nRGB{N0f8}(0.525, 0.71, 0.824)\nQuadrangle((lat: 90.0°, lon: -177.333°), ..., (lat: 89.7778°, lon: -177.333°))\n\n\nRGB{N0f8}(0.525, 0.71, 0.831)\nQuadrangle((lat: 90.0°, lon: -176.889°), ..., (lat: 89.7778°, lon: -176.889°))\n\n\nRGB{N0f8}(0.525, 0.71, 0.824)\nQuadrangle((lat: 90.0°, lon: -176.444°), ..., (lat: 89.7778°, lon: -176.444°))\n\n\nRGB{N0f8}(0.522, 0.71, 0.824)\nQuadrangle((lat: 90.0°, lon: -176.0°), ..., (lat: 89.7778°, lon: -176.0°))\n\n\n⋮\n⋮\n\n\n\n\n\nIf we save the geotable to a .geojson file on disk, and then load it back, we observe that the grid gets replaced by a geometry set:\n\nfname = tempname() * \".geojson\"\n\nGeoIO.save(fname, earth)\n\nGeoIO.load(fname)\n\n\n656100×2 GeoTable over 656100 GeometrySet\n\n\ncolor\ngeometry\n\n\nUnknown\nPolyArea\n\n\n[NoUnits]\n🖈 GeodeticLatLon{WGS84Latest}\n\n\n\n\nDict{String, Any}(\"g\"=&gt;0.709804, \"b\"=&gt;0.823529, \"r\"=&gt;0.52549)\nPolyArea((lat: 90.0°, lon: -180.0°), ..., (lat: 90.0°, lon: -179.556°))\n\n\nDict{String, Any}(\"g\"=&gt;0.709804, \"b\"=&gt;0.831373, \"r\"=&gt;0.52549)\nPolyArea((lat: 90.0°, lon: -179.556°), ..., (lat: 90.0°, lon: -179.111°))\n\n\nDict{String, Any}(\"g\"=&gt;0.709804, \"b\"=&gt;0.827451, \"r\"=&gt;0.52549)\nPolyArea((lat: 90.0°, lon: -179.111°), ..., (lat: 90.0°, lon: -178.667°))\n\n\nDict{String, Any}(\"g\"=&gt;0.709804, \"b\"=&gt;0.823529, \"r\"=&gt;0.52549)\nPolyArea((lat: 90.0°, lon: -178.667°), ..., (lat: 90.0°, lon: -178.222°))\n\n\nDict{String, Any}(\"g\"=&gt;0.709804, \"b\"=&gt;0.823529, \"r\"=&gt;0.52549)\nPolyArea((lat: 90.0°, lon: -178.222°), ..., (lat: 90.0°, lon: -177.778°))\n\n\nDict{String, Any}(\"g\"=&gt;0.709804, \"b\"=&gt;0.831373, \"r\"=&gt;0.521569)\nPolyArea((lat: 90.0°, lon: -177.778°), ..., (lat: 90.0°, lon: -177.333°))\n\n\nDict{String, Any}(\"g\"=&gt;0.709804, \"b\"=&gt;0.823529, \"r\"=&gt;0.52549)\nPolyArea((lat: 90.0°, lon: -177.333°), ..., (lat: 90.0°, lon: -176.889°))\n\n\nDict{String, Any}(\"g\"=&gt;0.709804, \"b\"=&gt;0.831373, \"r\"=&gt;0.52549)\nPolyArea((lat: 90.0°, lon: -176.889°), ..., (lat: 90.0°, lon: -176.444°))\n\n\nDict{String, Any}(\"g\"=&gt;0.709804, \"b\"=&gt;0.823529, \"r\"=&gt;0.52549)\nPolyArea((lat: 90.0°, lon: -176.444°), ..., (lat: 90.0°, lon: -176.0°))\n\n\nDict{String, Any}(\"g\"=&gt;0.709804, \"b\"=&gt;0.823529, \"r\"=&gt;0.521569)\nPolyArea((lat: 90.0°, lon: -176.0°), ..., (lat: 90.0°, lon: -175.556°))\n\n\n⋮\n⋮\n\n\n\n\n\nOther file formats such as .ply and .msh are widely used in computer graphics to save geospatial data over meshes, and preserve topological information:\n\nbeethoven = GeoIO.load(\"data/beethoven.ply\")\n\nviz(beethoven.geometry)",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Interfacing with GIS</span>"
    ]
  },
  {
    "objectID": "03-geoio.html#rationale",
    "href": "03-geoio.html#rationale",
    "title": "3  Interfacing with GIS",
    "section": "3.3 Rationale",
    "text": "3.3 Rationale\nNow that we have set expectations for our interface with GIS, let’s address an important question that many readers might have coming from other communities:\n\nDo we gain anything by not adhering to programming interfaces?\n\nThe answer is an emphatic YES! It means that we have total freedom to innovate and improve the representation of various geometries and geospatial domains with Julia’s amazing type system. To give a simple example, let’s take a look at the Triangle geometry:\n\nt = Triangle((0, 0), (1, 0), (1, 1))\n\nTriangle\n├─ Point(x: 0.0 m, y: 0.0 m)\n├─ Point(x: 1.0 m, y: 0.0 m)\n└─ Point(x: 1.0 m, y: 1.0 m)\n\n\nIf we treated this geometry as a generic polygon represented by a vector of vertices in memory, like it is done in GeoInterface.jl for example, we wouldn’t be able to dispatch optimized code that is only valid for a triangle:\n\n@code_llvm isconvex(t)\n\n; Function Signature: isconvex(Meshes.Ngon{3, Meshes.𝔼{2}, CoordRefSystems.Cartesian{CoordRefSystems.NoDatum, 2, Unitful.Quantity{Float64, Unitful.Dimensions{(Unitful.Dimension{:Length}(power=Base.Rational{Int64}(num=1, den=1)),)}(), Unitful.FreeUnits{(Unitful.Unit{:Meter, Unitful.Dimensions{(Unitful.Dimension{:Length}(power=Base.Rational{Int64}(num=1, den=1)),)}()}(tens=0, power=Base.Rational{Int64}(num=1, den=1)),), Unitful.Dimensions{(Unitful.Dimension{:Length}(power=Base.Rational{Int64}(num=1, den=1)),)}(), nothing}}}})\n;  @ /home/runner/.julia/packages/Meshes/BqsZk/src/predicates/isconvex.jl:57 within `isconvex`\ndefine i8 @julia_isconvex_28416(ptr nocapture readonly %0) #0 {\ntop:\n  ret i8 1\n}\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn Julia, the macro @code_llvm shows the underlying code sent to the LLVM compiler. In this case, the code is the single line ret i8 1, which is the instruction to return the constant integer 1.\n\n\nNotice how the isconvex function is compiled away to the constant 1 (i.e. true) when called on the triangle. The code for a generic polygon is much more complicated and requires runtime checks that are too expensive to afford, especially in 3D.\nAnother reason to not adhere to a generic interface is that we can store information in the geometry types themselves (e.g., coordinate reference system) that is relevant to design advanced scientific visualization features illustrated in the previous chapter, and to dispatch specialized algorithms from geodesic geometry.\nHaving cleared that up, we will now proceed to the last foundational chapter of the book, which covers the advanced geometric processing features of the framework.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Interfacing with GIS</span>"
    ]
  },
  {
    "objectID": "04-geoproc.html",
    "href": "04-geoproc.html",
    "title": "4  Geometric processing",
    "section": "",
    "text": "4.1 Geometries\nIn this chapter we give an overview of some of the advanced geometric processing features of the framework, highlighting the ones that will be most useful in future chapters.\nFrom now on, we will assume that the main module of the framework is loaded in all code examples:\nWe will also assume that the Makie.jl backend is loaded:\nWe provide a vast list of geometries, which are organized into two main classes, Primitive and Polytope geometries. A geometry is a Primitive if it can be represented efficiently without discretization. For example, we can represent a Box with two corner points or a Ball with center and radius:\nbox = Box((0, 0, 0), (1, 1, 1))\nball = Ball((0, 0, 2), 0.5)\n\nviz([box, ball], color = [\"teal\", \"slategray3\"])\nOther examples include the Cylinder:\ncyl = Cylinder(1.0)\n\nviz(cyl)\nAnd the Torus:\ntorus = Torus((1, 1, 0), (-1, -1, 0), (1, -1, 0), 0.5)\n\nviz(torus)\nThe full list can be obtained with Julia’s subtypes function:\nsubtypes(Primitive)\n\n20-element Vector{Any}:\n Ball\n BezierCurve\n Box\n Circle\n Cone\n ConeSurface\n Cylinder\n CylinderSurface\n Disk\n Ellipsoid\n Frustum\n FrustumSurface\n Line\n ParaboloidSurface\n ParametrizedCurve\n Plane\n Point\n Ray\n Sphere\n Torus\nA geometry is a Polytope if it can be represented as a combination of “flat sides”, which are also Polytope themselves. A 3D Polytope is called a Polyhedron, a 2D Polytope is called a Polygon and a 1D Polytope is called a polygonal Chain. All these geometries are represented internally with a list of vertices.\nFirst, let’s take a look into the Polyhedron geometries:\nsubtypes(Polyhedron)\n\n4-element Vector{Any}:\n Hexahedron\n Pyramid\n Tetrahedron\n Wedge\nThe Hexahedron is a generalization of a 3D Box in the sense that it doesn’t need to be aligned with the coordinate system:\nhex = Hexahedron((0, 0, 0), (1, 0, 0), (1, 1, 0), (0, 1, 0),\n                 (0, 0, 1), (1, 0, 1), (1, 1, 1), (0, 1, 1))\n\nviz(hex)\nIn this case, we need to store all the 8 vertices instead of just the corner points. Other examples of Polyhedron include the Tetrahedron and the Pyramid.\nNow, let’s move to the Polygon geometries:\nsubtypes(Polygon)\n\n2-element Vector{Any}:\n Ngon\n PolyArea\nWe provide two types of Polygon that meet different application requirements.\nThe Ngon is a polygon without holes. Its vertices are stored in static memory, and they are mostly used for discretization of other geometries and geospatial domains. We provide type aliases to construct Ngon with a specific number N of vertices:\nTriangle, Quadrangle, Pentagon, …, Decagon\nThe Quadrangle is a generalization of the 2D Box in the sense that it doesn’t need to be aligned with the coordinate system:\nt = Triangle((0, 0), (1, 0), (1, 1))\nq = Quadrangle((1, 1), (2, 1), (2, 2), (1, 2))\n\nviz([t, q], color = [\"teal\", \"slategray3\"])\nThe PolyArea is a polygon with or without holes. Its vertices are stored in dynamic memory, and they are mostly used for representation of polygonal areas in GIS:\nouter = [(0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 1.0)]\nhole1 = [(0.2, 0.2), (0.2, 0.4), (0.4, 0.4), (0.4, 0.2)]\nhole2 = [(0.6, 0.2), (0.6, 0.4), (0.8, 0.4), (0.8, 0.2)]\npoly  = PolyArea([outer, hole1, hole2])\n\nviz(poly)\nIn the example above, the first list of vertices represents the external boundary of the PolyArea, also known as the outer Ring. The other two lists represent the two internal boundaries, or inner rings. A single list of vertices can be used, in which case the PolyArea doesn’t have holes.\nFinally, let’s take a look into the polygonal Chain:\nsubtypes(Chain)\n\n3-element Vector{Any}:\n Ring\n Rope\n Segment\nThese are 1-dimensional polytopes connecting Points in sequence. We have seen the Rings in the PolyArea and Ngon geometries:\nviz(r)\nA Ring is closed meaning that its first and last Points are connected with a Segment. A Rope is an open Ring without the closing Segment:\nviz(open.(r))\nWe can obtain the list of segments of a Chain with the segments function:\ncollect(segments(first(r)))\n\n4-element Vector{Segment{𝔼{2}, Cartesian2D{NoDatum, Quantity{Float64, 𝐋, Unitful.FreeUnits{(m,), 𝐋, nothing}}}}}:\n Segment((x: 0.0 m, y: 0.0 m), (x: 1.0 m, y: 0.0 m))\n Segment((x: 1.0 m, y: 0.0 m), (x: 1.0 m, y: 1.0 m))\n Segment((x: 1.0 m, y: 1.0 m), (x: 0.0 m, y: 1.0 m))\n Segment((x: 0.0 m, y: 1.0 m), (x: 0.0 m, y: 0.0 m))\nThe Segment geometry is a Chain with just 2 vertices:\nviz(Segment((0, 0), (1, 1)))\nFinally, there is the Multi-geometry, which is a set of geometries seen as a single geometry. This is very common in GIS to represent disconnected areas on a geographic map that are related to each other (e.g., political areas):\nMulti([Point(1, 2), Point(2, 3)])\n\nMultiPoint\n├─ Point(x: 1.0 m, y: 2.0 m)\n└─ Point(x: 2.0 m, y: 3.0 m)\nMulti(r)\n\nMultiRing\n├─ Ring((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n├─ Ring((x: 0.2 m, y: 0.2 m), ..., (x: 0.4 m, y: 0.2 m))\n└─ Ring((x: 0.6 m, y: 0.2 m), ..., (x: 0.8 m, y: 0.2 m))\nMulti([t, q])\n\nMultiNgon\n├─ Triangle((x: 0.0 m, y: 0.0 m), (x: 1.0 m, y: 0.0 m), (x: 1.0 m, y: 1.0 m))\n└─ Quadrangle((x: 1.0 m, y: 1.0 m), ..., (x: 1.0 m, y: 2.0 m))",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Geometric processing</span>"
    ]
  },
  {
    "objectID": "04-geoproc.html#geometries",
    "href": "04-geoproc.html#geometries",
    "title": "4  Geometric processing",
    "section": "",
    "text": "Note\n\n\n\nGeometries have their own documentation. For example, to learn more about the Cylinder geometry, its parameters and defaults, we can type the following in the Julia REPL:\n?Cylinder\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe topology of a 2D Polygon is defined by the orientation of its rings. Most geometric processing algorithms expect counter clockwise (CCW) orientation for the outer ring, and clockwise (CW) orientation for the inner rings:\n\nr = rings(poly)\n\norientation.(r)\n\n3-element Vector{OrientationType}:\n CCW::OrientationType = 1\n CW::OrientationType = 0\n CW::OrientationType = 0\n\n\n\n\n\n\n\n\n\n\nTip for all users\n\n\n\nThe Repair transform covered in the next chapter can be used to repair the orientations of rings in polygons.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Geometric processing</span>"
    ]
  },
  {
    "objectID": "04-geoproc.html#predicates",
    "href": "04-geoproc.html#predicates",
    "title": "4  Geometric processing",
    "section": "4.2 Predicates",
    "text": "4.2 Predicates\nJulia provides support for unicode characters in variable and function names. We leverage this feature to define commonly used geometric predicates with intuitive mathematical notation:\n\np = Point(0.0, 0.0)\nb = Ball((0.5, 0.5), 1.0)\n\nviz([p, b], color = [\"teal\", \"slategray3\"])\n\n\n\n\n\np ∈ b\n\ntrue\n\n\n\nb1 = Box((0, 0), (1, 1))\nb2 = Box((0.5, 0.5), (2, 2))\n\nviz([b1, b2], color = [\"teal\", \"slategray3\"])\n\n\n\n\n\nb1 ⊆ b2\n\nfalse\n\n\n\n\n\n\n\n\nTip for all users\n\n\n\nThe symbol ∈ is obtained in Julia by typing \\in and pressing the TAB key on the keyboard. We could have used the syntax p in b or in(p, b) as well. Similarly, the symbol ⊆ is obtained by typing \\subseteq. We could have used the syntax issubseteq(b1, b2) as well.\nIf you don’t know the \\(\\LaTeX\\) name of a symbol, you can copy/paste it in the Julia REPL in help mode:\n?∈\n\n\nSome predicates don’t have well-established mathematical notation. For example, a polygon issimple if it doesn’t have holes nor self-intersections:\n\nq = Quadrangle((0, 0), (1, 0), (1, 1), (0.6, 0.4))\n\nviz(q)\n\n\n\n\n\nissimple(q)\n\ntrue\n\n\nIt isconvex if all line segments connecting two points of the polygon are inside the polygon:\n\nisconvex(q)\n\nfalse\n\n\nA very useful predicate is intersects (with a “s” at the end):\n\nouter = [(0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 1.0)]\nhole1 = [(0.2, 0.2), (0.2, 0.4), (0.4, 0.4), (0.4, 0.2)]\nhole2 = [(0.6, 0.2), (0.6, 0.4), (0.8, 0.4), (0.8, 0.2)]\npoly  = PolyArea([outer, hole1, hole2])\nball1 = Ball((0.5, 0.5), 0.05)\nball2 = Ball((0.3, 0.3), 0.05)\n\nviz([poly, ball1, ball2], color = [\"slategray3\", \"teal\", \"brown\"])\n\n\n\n\n\nintersects(poly, ball1)\n\ntrue\n\n\n\nintersects(poly, ball2)\n\nfalse\n\n\nIt tells whether or not the geometries intersect, without actually computing the intersection. The intersection itself is considered a geometric operation as discussed in the next section.\nPlease consult the official documentation for the full list of predicates.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Geometric processing</span>"
    ]
  },
  {
    "objectID": "04-geoproc.html#operations",
    "href": "04-geoproc.html#operations",
    "title": "4  Geometric processing",
    "section": "4.3 Operations",
    "text": "4.3 Operations\nGeometric operations transform a geometry or a set of geometries into a new geometry or number. For example, the intersection of two segments can be a Point, a Segment or nothing:\n\ns1 = Segment((0.0, 0.0), (1.0, 0.0))\ns2 = Segment((0.5, 0.0), (2.0, 0.0))\n\ns1 ∩ s2\n\nSegment\n├─ Point(x: 0.5 m, y: 0.0 m)\n└─ Point(x: 1.0 m, y: 0.0 m)\n\n\n\n\n\n\n\n\nTip for advanced users\n\n\n\nFor performance-sensitive applications, it is wise to replace the ∩ operation by its the 3-argument version named intersection:\n\nintersection(s1, s2) do I\n  if I == Crossing\n    return 1\n  else\n    return 0\n  end\nend\n\n0\n\n\nThe example above uses Julia’s do-syntax to define a function in place. The function takes the intersection type I and creates branches that return the same type (Int in this case) for type stability. The more we reduce the number of branches and types, the more the Julia compiler will be able to infer the output type.\n\n\nLikewise, the intersection of two 2D geometries can be obtained with:\n\npoly1 = Ngon((0, 1), (1, 0), (2, 1), (3, 0), (4, 1), (2, 2))\npoly2 = Ngon((1.0, 0.5), (3.5, 0.0), (3.5, 1.5), (1.0, 1.5))\n\npoly  = poly1 ∩ poly2\n\nviz(poly1)\nviz!(poly2, color = \"teal\", alpha = 0.2)\nviz!(boundary(poly), color = \"red\")\nMke.current_figure()\n\n\n\n\nThe previous example makes use of the boundary of a geometry, which is very useful to know:\n\nboundary(poly)\n\nRing\n├─ Point(x: 1.0 m, y: 0.5 m)\n├─ Point(x: 1.4166666666666667 m, y: 0.4166666666666667 m)\n├─ Point(x: 2.0 m, y: 1.0 m)\n├─ Point(x: 2.875 m, y: 0.125 m)\n├─ Point(x: 3.0833333333333335 m, y: 0.08333333333333333 m)\n├─ Point(x: 3.5 m, y: 0.4999999999999999 m)\n├─ Point(x: 3.5 m, y: 1.25 m)\n├─ Point(x: 3.0 m, y: 1.5 m)\n└─ Point(x: 1.0 m, y: 1.5 m)\n\n\nSome operations like measure (length, area or volume) produce numbers instead of geometries. For example, the area of the polygon above is:\n\narea(poly)\n\n2.4479166666666665 m^2\n\n\nThe measure of the boundary is known as the perimeter of the geometry:\n\nperimeter(poly)\n\n7.598044863023599 m\n\n\nAll Polytope geometries have vertices:\n\nvertices(poly)\n\n9-element Vector{Point{𝔼{2}, Cartesian2D{NoDatum, Quantity{Float64, 𝐋, Unitful.FreeUnits{(m,), 𝐋, nothing}}}}}:\n Point(x: 1.0 m, y: 0.5 m)\n Point(x: 1.4166666666666667 m, y: 0.4166666666666667 m)\n Point(x: 2.0 m, y: 1.0 m)\n Point(x: 2.875 m, y: 0.125 m)\n Point(x: 3.0833333333333335 m, y: 0.08333333333333333 m)\n Point(x: 3.5 m, y: 0.4999999999999999 m)\n Point(x: 3.5 m, y: 1.25 m)\n Point(x: 3.0 m, y: 1.5 m)\n Point(x: 1.0 m, y: 1.5 m)\n\n\nPlease consult the official documentation for the full list of operations.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Geometric processing</span>"
    ]
  },
  {
    "objectID": "04-geoproc.html#algorithms",
    "href": "04-geoproc.html#algorithms",
    "title": "4  Geometric processing",
    "section": "4.4 Algorithms",
    "text": "4.4 Algorithms\nAny other function that is not a predicate nor an operation is called a geometric processing “algorithm” in the framework. We provide a list of advanced algorithms for discretization, simplification, refinement, convex hull, etc.\nBelow we illustrate some of these algorithms, which will be useful in future examples:\n\npoints = rand(Point, 100, crs=Cartesian2D)\n\n100-element Vector{Point{𝔼{2}, Cartesian2D{NoDatum, Quantity{Float64, 𝐋, Unitful.FreeUnits{(m,), 𝐋, nothing}}}}}:\n Point(x: 0.5110993229517505 m, y: 0.0645578549111705 m)\n Point(x: 0.42162037668360874 m, y: 0.8048804259161714 m)\n Point(x: 0.4669289420220072 m, y: 0.4060339124549379 m)\n Point(x: 0.7892852209996265 m, y: 0.2036146156048695 m)\n Point(x: 0.8222621214121207 m, y: 0.32679268352278634 m)\n Point(x: 0.9978224729011219 m, y: 0.41862182501669887 m)\n Point(x: 0.694458502446782 m, y: 0.7799359139617988 m)\n Point(x: 0.33050025282600026 m, y: 0.7402758551866256 m)\n Point(x: 0.6646127219747411 m, y: 0.34603305720634325 m)\n Point(x: 0.9280868485345222 m, y: 0.7156011830119267 m)\n ⋮\n Point(x: 0.6066567001728888 m, y: 0.97388705721347 m)\n Point(x: 0.6276941212162067 m, y: 0.21310475029587106 m)\n Point(x: 0.1270944115101127 m, y: 0.33147873972530895 m)\n Point(x: 0.6117249700081856 m, y: 0.14123500524219146 m)\n Point(x: 0.3934939122040938 m, y: 0.9565356288076979 m)\n Point(x: 0.8340188088425481 m, y: 0.6954926999999846 m)\n Point(x: 0.4369018312346018 m, y: 0.3599905510250546 m)\n Point(x: 0.6985529390467947 m, y: 0.317396236122662 m)\n Point(x: 0.7343663202465578 m, y: 0.13075436011478392 m)\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe crs option specifies the Coordinate Reference System (CRS) of the points. It will be explored in the chapter Map projections. By default, the rand function generates geometries with Cartesian3D CRS:\n\nrand(Triangle, 3)\n\n3-element Vector{Triangle{𝔼{3}, Cartesian3D{NoDatum, Quantity{Float64, 𝐋, Unitful.FreeUnits{(m,), 𝐋, nothing}}}}}:\n Triangle((x: 0.591771 m, y: 0.0413222 m, z: 0.239796 m), (x: 0.290448 m, y: 0.539784 m, z: 0.357264 m), (x: 0.827333 m, y: 0.52164 m, z: 0.718546 m))\n Triangle((x: 0.518482 m, y: 0.718737 m, z: 0.65054 m), (x: 0.68305 m, y: 0.952617 m, z: 0.764429 m), (x: 0.834857 m, y: 0.0758875 m, z: 0.591104 m))\n Triangle((x: 0.709745 m, y: 0.193304 m, z: 0.54513 m), (x: 0.628329 m, y: 0.294001 m, z: 0.208133 m), (x: 0.506675 m, y: 0.0939179 m, z: 0.722551 m))\n\n\n\n\n\nviz(boundingbox(points))\nviz!(points, color = \"black\")\nMke.current_figure()\n\n\n\n\n\nviz(convexhull(points))\nviz!(points, color = \"black\")\nMke.current_figure()\n\n\n\n\nGeometries can be discretized into geospatial domains (i.e., collections of geometries). We have seen some of these domains in previous chapters, including the GeometrySet and the CartesianGrid. Here, we will focus on the Mesh subtypes:\n\nsubtypes(Mesh)\n\n5-element Vector{Any}:\n RectilinearGrid\n RegularGrid\n SimpleMesh\n StructuredGrid\n TransformedMesh\n\n\n\nsubtypes(Grid)\n\n5-element Vector{Any}:\n RectilinearGrid\n RegularGrid\n SimpleMesh{M, C, V, GridTopology{Dim}} where {M&lt;:Meshes.Manifold, C&lt;:CRS, V&lt;:AbstractArray{Point{M, C}, 1}, Dim}\n StructuredGrid\n TransformedMesh{M, C, GridTopology{Dim}} where {M&lt;:Meshes.Manifold, C&lt;:CRS, Dim}\n\n\nThere are two main functions to perform discretization: discretize and simplexify. The discretize function takes a geometry and a discretization algorithm as input, and produces a Mesh. For example, we can discretize a 2D ball with regular spacing along each parametric dimension (i.e., polar coordinates):\n\nball = Ball((0, 0), 1)\n\nmesh = discretize(ball, RegularDiscretization(20, 50))\n\n1050 SimpleMesh\n  1051 vertices\n  ├─ Point(x: 0.047619047619047616 m, y: 0.0 m)\n  ├─ Point(x: 0.09523809523809523 m, y: 0.0 m)\n  ├─ Point(x: 0.14285714285714285 m, y: 0.0 m)\n  ├─ Point(x: 0.19047619047619047 m, y: 0.0 m)\n  ├─ Point(x: 0.23809523809523808 m, y: 0.0 m)\n  ⋮\n  ├─ Point(x: 0.8503840296981238 m, y: -0.10742848591226112 m)\n  ├─ Point(x: 0.8976275869035751 m, y: -0.11339673512960896 m)\n  ├─ Point(x: 0.9448711441090264 m, y: -0.1193649843469568 m)\n  ├─ Point(x: 0.9921147013144778 m, y: -0.12533323356430465 m)\n  └─ Point(x: 0.0 m, y: 0.0 m)\n  1050 elements\n  ├─ Quadrangle(1, 2, 23, 22)\n  ├─ Quadrangle(2, 3, 24, 23)\n  ├─ Quadrangle(3, 4, 25, 24)\n  ├─ Quadrangle(4, 5, 26, 25)\n  ├─ Quadrangle(5, 6, 27, 26)\n  ⋮\n  ├─ Triangle(1051, 946, 967)\n  ├─ Triangle(1051, 967, 988)\n  ├─ Triangle(1051, 988, 1009)\n  ├─ Triangle(1051, 1009, 1030)\n  └─ Triangle(1051, 1030, 1)\n\n\nWe can visualize the elements of the mesh with the showsegments option:\n\nviz(mesh, showsegments = true)\n\n\n\n\nThe meshes produced by the discretize function can have mixed element types. In this case, the mesh is made of Quadrangle and Triangle geometries. The function simplexify is preferred if the application requires a mesh of simplices (i.e., triangles or tetrahedra):\n\ntmesh = simplexify(ball)\n\n5050 SimpleMesh\n  2551 vertices\n  ├─ Point(x: 0.0196078431372549 m, y: 0.0 m)\n  ├─ Point(x: 0.0392156862745098 m, y: 0.0 m)\n  ├─ Point(x: 0.058823529411764705 m, y: 0.0 m)\n  ├─ Point(x: 0.0784313725490196 m, y: 0.0 m)\n  ├─ Point(x: 0.09803921568627451 m, y: 0.0 m)\n  ⋮\n  ├─ Point(x: 0.9337550130018614 m, y: -0.1179606904134632 m)\n  ├─ Point(x: 0.9532082424394003 m, y: -0.12041820479707702 m)\n  ├─ Point(x: 0.972661471876939 m, y: -0.12287571918069083 m)\n  ├─ Point(x: 0.9921147013144778 m, y: -0.12533323356430465 m)\n  └─ Point(x: 0.0 m, y: 0.0 m)\n  5050 elements\n  ├─ Triangle(53, 52, 1)\n  ├─ Triangle(1, 2, 53)\n  ├─ Triangle(54, 53, 2)\n  ├─ Triangle(2, 3, 54)\n  ├─ Triangle(55, 54, 3)\n  ⋮\n  ├─ Triangle(2551, 2296, 2347)\n  ├─ Triangle(2551, 2347, 2398)\n  ├─ Triangle(2551, 2398, 2449)\n  ├─ Triangle(2551, 2449, 2500)\n  └─ Triangle(2551, 2500, 1)\n\n\n\nviz(tmesh, showsegments = true)\n\n\n\n\nVarious triangulation algorithms are provided such as DehnTriangulation (Devadoss and O’Rourke 2011), DelaunayTriangulation (Cheng, Dey, and Shewchuk 2012) and HeldTriangulation (Held 2001). After the mesh is created, it is possible to refine the elements:\n\nmesh = discretize(Box((0, 0), (1, 1)))\n\n2 SimpleMesh\n  4 vertices\n  ├─ Point(x: 0.0 m, y: 0.0 m)\n  ├─ Point(x: 1.0 m, y: 0.0 m)\n  ├─ Point(x: 1.0 m, y: 1.0 m)\n  └─ Point(x: 0.0 m, y: 1.0 m)\n  2 elements\n  ├─ Triangle(1, 2, 3)\n  └─ Triangle(1, 3, 4)\n\n\n\ntmesh = refine(mesh, TriRefinement())\n\nviz(tmesh, showsegments = true)\n\n\n\n\n\nqmesh = refine(mesh, QuadRefinement())\n\nviz(qmesh, showsegments = true)\n\n\n\n\nWe will have the chance to see more algorithms in action as we advance in the chapters of the book.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Geometric processing</span>"
    ]
  },
  {
    "objectID": "04-geoproc.html#domains",
    "href": "04-geoproc.html#domains",
    "title": "4  Geometric processing",
    "section": "4.5 Domains",
    "text": "4.5 Domains\nFor most purposes, domains can be manipulated as if they were Julia vectors of geometries. As an example, we can compute the centroid of each geometry in the domain by broadcasting the function:\n\ngrid = CartesianGrid(2, 3)\n\ncentroid.(grid)\n\n6-element Vector{Point{𝔼{2}, Cartesian2D{NoDatum, Quantity{Float64, 𝐋, Unitful.FreeUnits{(m,), 𝐋, nothing}}}}}:\n Point(x: 0.5 m, y: 0.5 m)\n Point(x: 1.5 m, y: 0.5 m)\n Point(x: 0.5 m, y: 1.5 m)\n Point(x: 1.5 m, y: 1.5 m)\n Point(x: 0.5 m, y: 2.5 m)\n Point(x: 1.5 m, y: 2.5 m)\n\n\nIn some cases, however, it is important to know which geometries are adjacent to a given geometry; or which geometries make up the boundary of a given geometry. This is where the topology is useful:\n\ntopo = topology(grid)\n\n2×3 GridTopology(aperiodic, aperiodic)\n\n\nWe can create an Adjacency topological relation to find which quadrangles are adjacent to quadrangle 1 in the domain:\n\nA = Adjacency{2}(topo)\n\nA(1)\n\n(2, 3)\n\n\nThe number 2 that appears in the Adjacency relation is known as the parametric dimension. In this case, we are interested in the adjacency of 2D geometries. The quadrangle 1 is the first quadrangle in the bottom-left corner of the grid, and it is adjacent to quadrangles 2 and 3. As another example, the quadrangle 3 is adjacent to quadrangles 4, 1 and 5:\n\nA(3)\n\n(4, 1, 5)\n\n\nIn order to query the adjacency of vertices, we create a relation with parametric dimension 0:\n\nA = Adjacency{0}(topo)\n\nA(1)\n\n(2, 4)\n\n\nWe can also query the vertices that are on the boundary of a given quadrangle with the Boundary topological relation. In this case, we specify the parametric dimension of the input and output geometries:\n\nB = Boundary{2,0}(topo)\n\nB(1)\n\n(1, 2, 5, 4)\n\n\nTopological relations are an advanced feature of the framework. They are mostly used by developers of geostatistical algorithms, or in geospatial queries that will be covered in Part III of the book.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Geometric processing</span>"
    ]
  },
  {
    "objectID": "04-geoproc.html#congratulations",
    "href": "04-geoproc.html#congratulations",
    "title": "4  Geometric processing",
    "section": "4.6 Congratulations!",
    "text": "4.6 Congratulations!\nCongratulations on finishing Part I of the book. Let’s quickly review what we learned so far:\n\nThe main concept in geospatial data science is the concept of geospatial data, represented in the GeoStats.jl framework as geotables over geospatial domains.\nThe geotable representation generalizes traditional GIS representations (“raster” vs. “vector”), and enables an unified approach to visualization and manipulation of geospatial data.\nIt is still possible to interface with existing GIS technology via input and output of files using the GeoIO.jl module. A typical workflow will load GIS data at the beginning of a script, and save the result of the analysis at the end of the script.\nGeometric processing doesn’t need to be complicated. It should be fun and read like math. If it feels “computer sciency”, that is a limitation of the software and programming language.\n\nWe are finally ready to learn the advanced features of the framework. Let’s get it started.\n\n\n\n\nCheng, Siu-Wing, Tamal K. Dey, and Jonathan Shewchuk. 2012. Delaunay Mesh Generation. Chapman; Hall/CRC. https://people.eecs.berkeley.edu/~jrs/meshbook.html.\n\n\nDevadoss, Satyan L, and Joseph O’Rourke. 2011. Discrete and Computational Geometry. Princeton, NJ: Princeton University Press.\n\n\nHeld, M. 2001. “FIST: Fast Industrial-Strength Triangulation of Polygons.” Algorithmica 30 (4): 563–96. https://doi.org/10.1007/s00453-001-0028-4.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Geometric processing</span>"
    ]
  },
  {
    "objectID": "05-transforms.html",
    "href": "05-transforms.html",
    "title": "5  What are transforms?",
    "section": "",
    "text": "5.1 Motivation\nIn Part I of the book, we learned that our GeoTable representation of geospatial data provides the data access pattern of the DataFrame, a feature that is very convenient for data science. To recap, let’s consider the following geotable with four random variables:\nN = 10000\na = [2randn(N÷2) .+ 6; randn(N÷2)]\nb = [3randn(N÷2); 2randn(N÷2)]\nc = randn(N)\nd = c .+ 0.6randn(N)\n\ntable = (; a, b, c, d)\n\ngtb = georef(table, CartesianGrid(100, 100))\n\n\n10000×5 GeoTable over 100×100 CartesianGrid\n\n\na\nb\nc\nd\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n4.88581\n0.207721\n-0.439557\n0.371569\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\n3.02362\n-1.62966\n-0.0442461\n1.26995\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\n3.55495\n-3.81017\n2.03573\n2.24289\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 1.0 m))\n\n\n9.36882\n0.878005\n0.810664\n0.441809\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 1.0 m))\n\n\n4.53893\n3.17166\n-0.420006\n0.21676\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 1.0 m))\n\n\n6.79182\n-4.93775\n1.4784\n1.9384\nQuadrangle((x: 5.0 m, y: 0.0 m), ..., (x: 5.0 m, y: 1.0 m))\n\n\n9.36777\n-7.63681\n0.705221\n-0.422692\nQuadrangle((x: 6.0 m, y: 0.0 m), ..., (x: 6.0 m, y: 1.0 m))\n\n\n7.50485\n-5.18151\n-0.0588877\n0.519115\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 1.0 m))\n\n\n11.2884\n1.1928\n0.469971\n0.818511\nQuadrangle((x: 8.0 m, y: 0.0 m), ..., (x: 8.0 m, y: 1.0 m))\n\n\n5.84379\n-2.40664\n-0.852607\n-1.57794\nQuadrangle((x: 9.0 m, y: 0.0 m), ..., (x: 9.0 m, y: 1.0 m))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\nWe can easily retrieve the “a” column of the geotable as a vector, and plot its histogram:\nMke.hist(gtb.a, color = \"gray80\")\nWe can compute the cross-correlation between columns “a” and “b”:\ncor(gtb.a, gtb.b)\n\n-0.0012974472772385513\nAnd inspect bivariate distributions of the values of the geotable with PairPlots.jl by Thompson (2023):\nusing PairPlots\n\npairplot(values(gtb))\nThis pattern is useful to answer geoscientific questions via marginal analysis (i.e. entire columns treated as measurements of a single random variable). However, the answers to many questions in geosciences depend on where the measurements were made.\nAttempting to answer geoscientific questions with basic access to rows and columns can be very frustrating. In particular, this approach is prone to unintentional removal of geospatial information:\ngtb.a\n\n10000-element Vector{Float64}:\n  4.885812782101949\n  3.0236173407588334\n  3.5549470152053524\n  9.368817744193239\n  4.538927468511029\n  6.791815752557896\n  9.367765851308516\n  7.504850399957872\n 11.288376337077615\n  5.843792427204422\n  ⋮\n -0.6961346767351666\n -0.09082398255772903\n  0.8197606010569192\n  0.6996260981302798\n  0.5270925066299955\n -1.433735555047421\n  0.5007162416235108\n  0.7913282706001916\n  1.2380148868389969\nWe propose a new approach to geospatial data science with the concept of transforms, which we introduce in three classes with practical examples:",
    "crumbs": [
      "Part II: Transforms",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What are transforms?</span>"
    ]
  },
  {
    "objectID": "05-transforms.html#motivation",
    "href": "05-transforms.html#motivation",
    "title": "5  What are transforms?",
    "section": "",
    "text": "Note\n\n\n\nAny script that is written in terms of direct column access has the potential to discard the special geometry column, and become unreadable very quickly with the use of auxiliary indices for rows.\n\n\n\n\nFeature transforms\nGeometric transforms\nGeospatial transforms",
    "crumbs": [
      "Part II: Transforms",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What are transforms?</span>"
    ]
  },
  {
    "objectID": "05-transforms.html#feature-transforms",
    "href": "05-transforms.html#feature-transforms",
    "title": "5  What are transforms?",
    "section": "5.2 Feature transforms",
    "text": "5.2 Feature transforms\nA feature transform is a function that takes the values of the geotable and produces a new set of values over the same geospatial domain. The framework provides over 30 such transforms, ranging from basic selection of columns, to data cleaning, to advanced multivariate statistical transforms.\n\n5.2.1 Basic\nLet’s start with two basic and important transforms, Select and Reject. The Select transform can be used to select columns of interest from a geotable:\n\ngtb |&gt; Select(\"a\", \"b\") # select columns \"a\" and \"b\"\n\n\n10000×3 GeoTable over 100×100 CartesianGrid\n\n\na\nb\ngeometry\n\n\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n4.88581\n0.207721\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\n3.02362\n-1.62966\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\n3.55495\n-3.81017\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 1.0 m))\n\n\n9.36882\n0.878005\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 1.0 m))\n\n\n4.53893\n3.17166\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 1.0 m))\n\n\n6.79182\n-4.93775\nQuadrangle((x: 5.0 m, y: 0.0 m), ..., (x: 5.0 m, y: 1.0 m))\n\n\n9.36777\n-7.63681\nQuadrangle((x: 6.0 m, y: 0.0 m), ..., (x: 6.0 m, y: 1.0 m))\n\n\n7.50485\n-5.18151\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 1.0 m))\n\n\n11.2884\n1.1928\nQuadrangle((x: 8.0 m, y: 0.0 m), ..., (x: 8.0 m, y: 1.0 m))\n\n\n5.84379\n-2.40664\nQuadrangle((x: 9.0 m, y: 0.0 m), ..., (x: 9.0 m, y: 1.0 m))\n\n\n⋮\n⋮\n⋮\n\n\n\n\n\nIn the example above, we selected the columns “a” and “b” explicitly, but Select has various methods for more flexible column selection:\n\ngtb |&gt; Select(1:3) # select columns 1 to 3\n\n\n10000×4 GeoTable over 100×100 CartesianGrid\n\n\na\nb\nc\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n4.88581\n0.207721\n-0.439557\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\n3.02362\n-1.62966\n-0.0442461\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\n3.55495\n-3.81017\n2.03573\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 1.0 m))\n\n\n9.36882\n0.878005\n0.810664\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 1.0 m))\n\n\n4.53893\n3.17166\n-0.420006\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 1.0 m))\n\n\n6.79182\n-4.93775\n1.4784\nQuadrangle((x: 5.0 m, y: 0.0 m), ..., (x: 5.0 m, y: 1.0 m))\n\n\n9.36777\n-7.63681\n0.705221\nQuadrangle((x: 6.0 m, y: 0.0 m), ..., (x: 6.0 m, y: 1.0 m))\n\n\n7.50485\n-5.18151\n-0.0588877\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 1.0 m))\n\n\n11.2884\n1.1928\n0.469971\nQuadrangle((x: 8.0 m, y: 0.0 m), ..., (x: 8.0 m, y: 1.0 m))\n\n\n5.84379\n-2.40664\n-0.852607\nQuadrangle((x: 9.0 m, y: 0.0 m), ..., (x: 9.0 m, y: 1.0 m))\n\n\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\n\ngtb |&gt; Select(r\"[bcd]\") # columns matching regular expression\n\n\n10000×4 GeoTable over 100×100 CartesianGrid\n\n\nb\nc\nd\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n0.207721\n-0.439557\n0.371569\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\n-1.62966\n-0.0442461\n1.26995\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\n-3.81017\n2.03573\n2.24289\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 1.0 m))\n\n\n0.878005\n0.810664\n0.441809\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 1.0 m))\n\n\n3.17166\n-0.420006\n0.21676\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 1.0 m))\n\n\n-4.93775\n1.4784\n1.9384\nQuadrangle((x: 5.0 m, y: 0.0 m), ..., (x: 5.0 m, y: 1.0 m))\n\n\n-7.63681\n0.705221\n-0.422692\nQuadrangle((x: 6.0 m, y: 0.0 m), ..., (x: 6.0 m, y: 1.0 m))\n\n\n-5.18151\n-0.0588877\n0.519115\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 1.0 m))\n\n\n1.1928\n0.469971\n0.818511\nQuadrangle((x: 8.0 m, y: 0.0 m), ..., (x: 8.0 m, y: 1.0 m))\n\n\n-2.40664\n-0.852607\n-1.57794\nQuadrangle((x: 9.0 m, y: 0.0 m), ..., (x: 9.0 m, y: 1.0 m))\n\n\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nA convenient method is also provided to select and rename columns:\n\ngtb |&gt; Select(\"a\" =&gt; \"A\", \"b\" =&gt; \"B\")\n\n\n10000×3 GeoTable over 100×100 CartesianGrid\n\n\nA\nB\ngeometry\n\n\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n4.88581\n0.207721\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\n3.02362\n-1.62966\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\n3.55495\n-3.81017\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 1.0 m))\n\n\n9.36882\n0.878005\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 1.0 m))\n\n\n4.53893\n3.17166\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 1.0 m))\n\n\n6.79182\n-4.93775\nQuadrangle((x: 5.0 m, y: 0.0 m), ..., (x: 5.0 m, y: 1.0 m))\n\n\n9.36777\n-7.63681\nQuadrangle((x: 6.0 m, y: 0.0 m), ..., (x: 6.0 m, y: 1.0 m))\n\n\n7.50485\n-5.18151\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 1.0 m))\n\n\n11.2884\n1.1928\nQuadrangle((x: 8.0 m, y: 0.0 m), ..., (x: 8.0 m, y: 1.0 m))\n\n\n5.84379\n-2.40664\nQuadrangle((x: 9.0 m, y: 0.0 m), ..., (x: 9.0 m, y: 1.0 m))\n\n\n⋮\n⋮\n⋮\n\n\n\n\n\nThe Reject transform can be used to reject columns from a geotable that are not relevant for a given analysis. It supports the same column specification of Select:\n\ngtb |&gt; Reject(\"b\") # reject column \"b\"\n\n\n10000×4 GeoTable over 100×100 CartesianGrid\n\n\na\nc\nd\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n4.88581\n-0.439557\n0.371569\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\n3.02362\n-0.0442461\n1.26995\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\n3.55495\n2.03573\n2.24289\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 1.0 m))\n\n\n9.36882\n0.810664\n0.441809\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 1.0 m))\n\n\n4.53893\n-0.420006\n0.21676\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 1.0 m))\n\n\n6.79182\n1.4784\n1.9384\nQuadrangle((x: 5.0 m, y: 0.0 m), ..., (x: 5.0 m, y: 1.0 m))\n\n\n9.36777\n0.705221\n-0.422692\nQuadrangle((x: 6.0 m, y: 0.0 m), ..., (x: 6.0 m, y: 1.0 m))\n\n\n7.50485\n-0.0588877\n0.519115\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 1.0 m))\n\n\n11.2884\n0.469971\n0.818511\nQuadrangle((x: 8.0 m, y: 0.0 m), ..., (x: 8.0 m, y: 1.0 m))\n\n\n5.84379\n-0.852607\n-1.57794\nQuadrangle((x: 9.0 m, y: 0.0 m), ..., (x: 9.0 m, y: 1.0 m))\n\n\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nUnlike direct column access, the Select and Reject transforms preserve geospatial information.\n\n\n\n\n\n\n\n\nTip for all users\n\n\n\nThe Select transform can be used in conjunction with the viewer to quickly visualize a specific variable:\n\ngtb |&gt; Select(\"a\") |&gt; viewer\n\n\n\n\n\n\nThe Rename transform can be used to rename specific columns of a geotable. It preserves all other columns that are not part of the column specification:\n\ngtb |&gt; Rename(\"a\" =&gt; \"A\", \"b\" =&gt; \"B\")\n\n\n10000×5 GeoTable over 100×100 CartesianGrid\n\n\nA\nB\nc\nd\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n4.88581\n0.207721\n-0.439557\n0.371569\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\n3.02362\n-1.62966\n-0.0442461\n1.26995\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\n3.55495\n-3.81017\n2.03573\n2.24289\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 1.0 m))\n\n\n9.36882\n0.878005\n0.810664\n0.441809\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 1.0 m))\n\n\n4.53893\n3.17166\n-0.420006\n0.21676\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 1.0 m))\n\n\n6.79182\n-4.93775\n1.4784\n1.9384\nQuadrangle((x: 5.0 m, y: 0.0 m), ..., (x: 5.0 m, y: 1.0 m))\n\n\n9.36777\n-7.63681\n0.705221\n-0.422692\nQuadrangle((x: 6.0 m, y: 0.0 m), ..., (x: 6.0 m, y: 1.0 m))\n\n\n7.50485\n-5.18151\n-0.0588877\n0.519115\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 1.0 m))\n\n\n11.2884\n1.1928\n0.469971\n0.818511\nQuadrangle((x: 8.0 m, y: 0.0 m), ..., (x: 8.0 m, y: 1.0 m))\n\n\n5.84379\n-2.40664\n-0.852607\n-1.57794\nQuadrangle((x: 9.0 m, y: 0.0 m), ..., (x: 9.0 m, y: 1.0 m))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nThe Identity transform can be used as a placeholder to forward the geotable without modifications to the next transform:\n\ngtb |&gt; Identity()\n\n\n10000×5 GeoTable over 100×100 CartesianGrid\n\n\na\nb\nc\nd\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n4.88581\n0.207721\n-0.439557\n0.371569\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\n3.02362\n-1.62966\n-0.0442461\n1.26995\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\n3.55495\n-3.81017\n2.03573\n2.24289\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 1.0 m))\n\n\n9.36882\n0.878005\n0.810664\n0.441809\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 1.0 m))\n\n\n4.53893\n3.17166\n-0.420006\n0.21676\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 1.0 m))\n\n\n6.79182\n-4.93775\n1.4784\n1.9384\nQuadrangle((x: 5.0 m, y: 0.0 m), ..., (x: 5.0 m, y: 1.0 m))\n\n\n9.36777\n-7.63681\n0.705221\n-0.422692\nQuadrangle((x: 6.0 m, y: 0.0 m), ..., (x: 6.0 m, y: 1.0 m))\n\n\n7.50485\n-5.18151\n-0.0588877\n0.519115\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 1.0 m))\n\n\n11.2884\n1.1928\n0.469971\n0.818511\nQuadrangle((x: 8.0 m, y: 0.0 m), ..., (x: 8.0 m, y: 1.0 m))\n\n\n5.84379\n-2.40664\n-0.852607\n-1.57794\nQuadrangle((x: 9.0 m, y: 0.0 m), ..., (x: 9.0 m, y: 1.0 m))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nThe RowTable and ColTable transforms change the underlying table representation of the values of the geotable as discussed in the first chapter of the book:\n\nrtb = gtb |&gt; RowTable()\n\n\n10000×5 GeoTable over 100×100 CartesianGrid\n\n\na\nb\nc\nd\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n4.88581\n0.207721\n-0.439557\n0.371569\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\n3.02362\n-1.62966\n-0.0442461\n1.26995\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\n3.55495\n-3.81017\n2.03573\n2.24289\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 1.0 m))\n\n\n9.36882\n0.878005\n0.810664\n0.441809\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 1.0 m))\n\n\n4.53893\n3.17166\n-0.420006\n0.21676\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 1.0 m))\n\n\n6.79182\n-4.93775\n1.4784\n1.9384\nQuadrangle((x: 5.0 m, y: 0.0 m), ..., (x: 5.0 m, y: 1.0 m))\n\n\n9.36777\n-7.63681\n0.705221\n-0.422692\nQuadrangle((x: 6.0 m, y: 0.0 m), ..., (x: 6.0 m, y: 1.0 m))\n\n\n7.50485\n-5.18151\n-0.0588877\n0.519115\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 1.0 m))\n\n\n11.2884\n1.1928\n0.469971\n0.818511\nQuadrangle((x: 8.0 m, y: 0.0 m), ..., (x: 8.0 m, y: 1.0 m))\n\n\n5.84379\n-2.40664\n-0.852607\n-1.57794\nQuadrangle((x: 9.0 m, y: 0.0 m), ..., (x: 9.0 m, y: 1.0 m))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\n\nrtb |&gt; values |&gt; typeof\n\nVector{@NamedTuple{a::Float64, b::Float64, c::Float64, d::Float64}} (alias for Array{@NamedTuple{a::Float64, b::Float64, c::Float64, d::Float64}, 1})\n\n\nThe Functional transform can be used to apply a function to columns of a geotable in place:\n\ngtb |&gt; Functional(cos) |&gt; values |&gt; pairplot\n\n\n\n\n\ngtb |&gt; Functional(\"a\" =&gt; cos, \"b\" =&gt; sin) |&gt; values |&gt; pairplot\n\n\n\n\nThe Map transform can be used to create new columns from existing columns in the geotable. It takes a column specification, calls a function on the selected columns row-by-row, and returns the result as a new column:\n\ngtb |&gt; Map(\"a\" =&gt; sin, \"b\" =&gt; cos =&gt; \"cos(b)\")\n\n\n10000×7 GeoTable over 100×100 CartesianGrid\n\n\na\nb\nc\nd\nsin_a\ncos(b)\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n4.88581\n0.207721\n-0.439557\n0.371569\n-0.985\n0.978503\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\n3.02362\n-1.62966\n-0.0442461\n1.26995\n0.117702\n-0.0588311\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\n3.55495\n-3.81017\n2.03573\n2.24289\n-0.401683\n-0.784702\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 1.0 m))\n\n\n9.36882\n0.878005\n0.810664\n0.441809\n0.055931\n0.638688\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 1.0 m))\n\n\n4.53893\n3.17166\n-0.420006\n0.21676\n-0.984993\n-0.999548\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 1.0 m))\n\n\n6.79182\n-4.93775\n1.4784\n1.9384\n0.486982\n0.223457\nQuadrangle((x: 5.0 m, y: 0.0 m), ..., (x: 5.0 m, y: 1.0 m))\n\n\n9.36777\n-7.63681\n0.705221\n-0.422692\n0.0569812\n0.215472\nQuadrangle((x: 6.0 m, y: 0.0 m), ..., (x: 6.0 m, y: 1.0 m))\n\n\n7.50485\n-5.18151\n-0.0588877\n0.519115\n0.93967\n0.452101\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 1.0 m))\n\n\n11.2884\n1.1928\n0.469971\n0.818511\n-0.957439\n0.369059\nQuadrangle((x: 8.0 m, y: 0.0 m), ..., (x: 8.0 m, y: 1.0 m))\n\n\n5.84379\n-2.40664\n-0.852607\n-1.57794\n-0.42539\n-0.741864\nQuadrangle((x: 9.0 m, y: 0.0 m), ..., (x: 9.0 m, y: 1.0 m))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\n\ngtb |&gt; Map([2, 3] =&gt; ((b, c) -&gt; 2b + c) =&gt; \"f(b, c)\")\n\n\n10000×6 GeoTable over 100×100 CartesianGrid\n\n\na\nb\nc\nd\nf(b, c)\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n4.88581\n0.207721\n-0.439557\n0.371569\n-0.0241145\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\n3.02362\n-1.62966\n-0.0442461\n1.26995\n-3.30357\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\n3.55495\n-3.81017\n2.03573\n2.24289\n-5.58462\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 1.0 m))\n\n\n9.36882\n0.878005\n0.810664\n0.441809\n2.56667\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 1.0 m))\n\n\n4.53893\n3.17166\n-0.420006\n0.21676\n5.92331\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 1.0 m))\n\n\n6.79182\n-4.93775\n1.4784\n1.9384\n-8.39709\nQuadrangle((x: 5.0 m, y: 0.0 m), ..., (x: 5.0 m, y: 1.0 m))\n\n\n9.36777\n-7.63681\n0.705221\n-0.422692\n-14.5684\nQuadrangle((x: 6.0 m, y: 0.0 m), ..., (x: 6.0 m, y: 1.0 m))\n\n\n7.50485\n-5.18151\n-0.0588877\n0.519115\n-10.4219\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 1.0 m))\n\n\n11.2884\n1.1928\n0.469971\n0.818511\n2.85557\nQuadrangle((x: 8.0 m, y: 0.0 m), ..., (x: 8.0 m, y: 1.0 m))\n\n\n5.84379\n-2.40664\n-0.852607\n-1.57794\n-5.66589\nQuadrangle((x: 9.0 m, y: 0.0 m), ..., (x: 9.0 m, y: 1.0 m))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nThe name of the resulting column can be provided or omitted. If the name is omitted like in the example above with the column “a”, it is created by concatenation of column and function names.\n\n\n\n\n\n\nNote\n\n\n\nThe Map transform mimics the behavior of the transform function in DataFrames.jl, except that it always broadcasts the functions to the rows of the selected columns and always produces a single column for each function.\n\n\nTo filter rows in the geotable based on a given predicate (i.e., a function that returns true or false), we can use the Filter transform:\n\ngtb |&gt; Filter(row -&gt; row.a &lt; 0 && row.b &gt; 0)\n\n\n1224×5 GeoTable over 1224 view(::CartesianGrid, [2115, 3284, 4234, 4842, ..., 9987, 9990, 9992, 9993])\n\n\na\nb\nc\nd\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n-1.0681\n0.92068\n0.575923\n0.0307886\nQuadrangle((x: 14.0 m, y: 21.0 m), ..., (x: 14.0 m, y: 22.0 m))\n\n\n-0.0606301\n4.20857\n-0.482224\n-0.654621\nQuadrangle((x: 83.0 m, y: 32.0 m), ..., (x: 83.0 m, y: 33.0 m))\n\n\n-2.11883\n3.13768\n-1.12075\n-1.06169\nQuadrangle((x: 33.0 m, y: 42.0 m), ..., (x: 33.0 m, y: 43.0 m))\n\n\n-0.211718\n3.39355\n0.21455\n-0.340991\nQuadrangle((x: 41.0 m, y: 48.0 m), ..., (x: 41.0 m, y: 49.0 m))\n\n\n-0.532241\n1.47989\n0.449097\n-0.0638539\nQuadrangle((x: 9.0 m, y: 50.0 m), ..., (x: 9.0 m, y: 51.0 m))\n\n\n-0.160618\n0.459294\n-1.4688\n-1.95531\nQuadrangle((x: 15.0 m, y: 50.0 m), ..., (x: 15.0 m, y: 51.0 m))\n\n\n-1.80722\n0.243561\n2.74684\n3.06823\nQuadrangle((x: 17.0 m, y: 50.0 m), ..., (x: 17.0 m, y: 51.0 m))\n\n\n-0.760937\n1.25193\n0.314519\n0.735841\nQuadrangle((x: 22.0 m, y: 50.0 m), ..., (x: 22.0 m, y: 51.0 m))\n\n\n-1.05618\n0.507739\n-1.71917\n-1.32851\nQuadrangle((x: 31.0 m, y: 50.0 m), ..., (x: 31.0 m, y: 51.0 m))\n\n\n-0.969577\n1.68612\n1.13332\n1.82473\nQuadrangle((x: 35.0 m, y: 50.0 m), ..., (x: 35.0 m, y: 51.0 m))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nTo sort rows based on specific columns we can use the Sort transform:\n\ngtb |&gt; Sort(\"a\", \"b\")\n\n\n10000×5 GeoTable over 10000 view(::CartesianGrid, [8720, 8978, 9069, 5893, ..., 2421, 213, 3055, 1935])\n\n\na\nb\nc\nd\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n-4.46696\n-0.501248\n-0.197697\n-0.750288\nQuadrangle((x: 19.0 m, y: 87.0 m), ..., (x: 19.0 m, y: 88.0 m))\n\n\n-3.4798\n0.834567\n-0.382879\n-0.344992\nQuadrangle((x: 77.0 m, y: 89.0 m), ..., (x: 77.0 m, y: 90.0 m))\n\n\n-3.43583\n-2.61584\n-1.41209\n-1.6437\nQuadrangle((x: 68.0 m, y: 90.0 m), ..., (x: 68.0 m, y: 91.0 m))\n\n\n-3.34896\n-0.172724\n-0.217586\n0.221013\nQuadrangle((x: 92.0 m, y: 58.0 m), ..., (x: 92.0 m, y: 59.0 m))\n\n\n-3.33737\n-1.40386\n-0.900319\n-0.878592\nQuadrangle((x: 28.0 m, y: 61.0 m), ..., (x: 28.0 m, y: 62.0 m))\n\n\n-3.27739\n0.0632477\n1.62699\n1.32595\nQuadrangle((x: 39.0 m, y: 91.0 m), ..., (x: 39.0 m, y: 92.0 m))\n\n\n-3.20164\n2.37187\n-0.131753\n-1.02223\nQuadrangle((x: 31.0 m, y: 51.0 m), ..., (x: 31.0 m, y: 52.0 m))\n\n\n-3.19985\n-0.218046\n-0.0797351\n-0.171346\nQuadrangle((x: 42.0 m, y: 62.0 m), ..., (x: 42.0 m, y: 63.0 m))\n\n\n-3.14424\n-1.74011\n-1.48969\n-1.24232\nQuadrangle((x: 85.0 m, y: 77.0 m), ..., (x: 85.0 m, y: 78.0 m))\n\n\n-3.07836\n-0.409344\n-0.243\n-0.954631\nQuadrangle((x: 49.0 m, y: 66.0 m), ..., (x: 49.0 m, y: 67.0 m))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nThis transform accepts all options of the sortperm function in Julia, including the option to sort in reverse order:\n\ngtb |&gt; Sort(\"a\", \"b\", rev=true)\n\n\n10000×5 GeoTable over 10000 view(::CartesianGrid, [1935, 3055, 213, 2421, ..., 5893, 9069, 8978, 8720])\n\n\na\nb\nc\nd\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n13.9461\n3.13306\n-0.0996197\n-0.639118\nQuadrangle((x: 34.0 m, y: 19.0 m), ..., (x: 34.0 m, y: 20.0 m))\n\n\n12.7548\n-6.36199\n-0.524636\n-0.872273\nQuadrangle((x: 54.0 m, y: 30.0 m), ..., (x: 54.0 m, y: 31.0 m))\n\n\n12.7067\n-1.40113\n-1.43142\n-1.43792\nQuadrangle((x: 12.0 m, y: 2.0 m), ..., (x: 12.0 m, y: 3.0 m))\n\n\n12.6533\n-1.28572\n-1.15148\n-0.659433\nQuadrangle((x: 20.0 m, y: 24.0 m), ..., (x: 20.0 m, y: 25.0 m))\n\n\n12.642\n0.87357\n0.358397\n0.0550992\nQuadrangle((x: 51.0 m, y: 33.0 m), ..., (x: 51.0 m, y: 34.0 m))\n\n\n12.195\n6.00488\n0.55493\n0.874542\nQuadrangle((x: 41.0 m, y: 38.0 m), ..., (x: 41.0 m, y: 39.0 m))\n\n\n12.0192\n0.415044\n-0.291777\n-0.230245\nQuadrangle((x: 52.0 m, y: 46.0 m), ..., (x: 52.0 m, y: 47.0 m))\n\n\n11.9928\n0.664262\n0.131775\n0.171159\nQuadrangle((x: 64.0 m, y: 13.0 m), ..., (x: 64.0 m, y: 14.0 m))\n\n\n11.8668\n-3.43547\n0.236611\n0.669791\nQuadrangle((x: 14.0 m, y: 11.0 m), ..., (x: 14.0 m, y: 12.0 m))\n\n\n11.8606\n3.07282\n0.1224\n0.286362\nQuadrangle((x: 63.0 m, y: 44.0 m), ..., (x: 63.0 m, y: 45.0 m))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\n\n\n5.2.2 Cleaning\nSome feature transforms are used to clean the data before geostatistical analysis. For example, the StdNames transform can be used to standardize variable names that are not very readable due to file format limitations. To illustrate this transform, let’s create a geotable with unreadable variable names:\n\nutb = gtb |&gt; Select(\"a\" =&gt; \"aBc De-F\", \"b\" =&gt; \"b_2 (1)\")\n\n\n10000×3 GeoTable over 100×100 CartesianGrid\n\n\naBc De-F\nb_2 (1)\ngeometry\n\n\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n4.88581\n0.207721\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\n3.02362\n-1.62966\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\n3.55495\n-3.81017\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 1.0 m))\n\n\n9.36882\n0.878005\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 1.0 m))\n\n\n4.53893\n3.17166\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 1.0 m))\n\n\n6.79182\n-4.93775\nQuadrangle((x: 5.0 m, y: 0.0 m), ..., (x: 5.0 m, y: 1.0 m))\n\n\n9.36777\n-7.63681\nQuadrangle((x: 6.0 m, y: 0.0 m), ..., (x: 6.0 m, y: 1.0 m))\n\n\n7.50485\n-5.18151\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 1.0 m))\n\n\n11.2884\n1.1928\nQuadrangle((x: 8.0 m, y: 0.0 m), ..., (x: 8.0 m, y: 1.0 m))\n\n\n5.84379\n-2.40664\nQuadrangle((x: 9.0 m, y: 0.0 m), ..., (x: 9.0 m, y: 1.0 m))\n\n\n⋮\n⋮\n⋮\n\n\n\n\n\nWe can standardize the names with:\n\nutb |&gt; StdNames()\n\n\n10000×3 GeoTable over 100×100 CartesianGrid\n\n\nABC_DE_F\nB_2_1\ngeometry\n\n\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n4.88581\n0.207721\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\n3.02362\n-1.62966\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\n3.55495\n-3.81017\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 1.0 m))\n\n\n9.36882\n0.878005\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 1.0 m))\n\n\n4.53893\n3.17166\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 1.0 m))\n\n\n6.79182\n-4.93775\nQuadrangle((x: 5.0 m, y: 0.0 m), ..., (x: 5.0 m, y: 1.0 m))\n\n\n9.36777\n-7.63681\nQuadrangle((x: 6.0 m, y: 0.0 m), ..., (x: 6.0 m, y: 1.0 m))\n\n\n7.50485\n-5.18151\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 1.0 m))\n\n\n11.2884\n1.1928\nQuadrangle((x: 8.0 m, y: 0.0 m), ..., (x: 8.0 m, y: 1.0 m))\n\n\n5.84379\n-2.40664\nQuadrangle((x: 9.0 m, y: 0.0 m), ..., (x: 9.0 m, y: 1.0 m))\n\n\n⋮\n⋮\n⋮\n\n\n\n\n\nBy default the transform, uses the :uppersnake naming convention. Other conventions can be specified depending on personal preference:\n\nutb |&gt; StdNames(:uppercamel)\n\n\n10000×3 GeoTable over 100×100 CartesianGrid\n\n\nAbcDeF\nB21\ngeometry\n\n\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n4.88581\n0.207721\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\n3.02362\n-1.62966\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\n3.55495\n-3.81017\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 1.0 m))\n\n\n9.36882\n0.878005\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 1.0 m))\n\n\n4.53893\n3.17166\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 1.0 m))\n\n\n6.79182\n-4.93775\nQuadrangle((x: 5.0 m, y: 0.0 m), ..., (x: 5.0 m, y: 1.0 m))\n\n\n9.36777\n-7.63681\nQuadrangle((x: 6.0 m, y: 0.0 m), ..., (x: 6.0 m, y: 1.0 m))\n\n\n7.50485\n-5.18151\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 1.0 m))\n\n\n11.2884\n1.1928\nQuadrangle((x: 8.0 m, y: 0.0 m), ..., (x: 8.0 m, y: 1.0 m))\n\n\n5.84379\n-2.40664\nQuadrangle((x: 9.0 m, y: 0.0 m), ..., (x: 9.0 m, y: 1.0 m))\n\n\n⋮\n⋮\n⋮\n\n\n\n\n\n\nutb |&gt; StdNames(:upperflat)\n\n\n10000×3 GeoTable over 100×100 CartesianGrid\n\n\nABCDEF\nB21\ngeometry\n\n\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n4.88581\n0.207721\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\n3.02362\n-1.62966\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\n3.55495\n-3.81017\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 1.0 m))\n\n\n9.36882\n0.878005\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 1.0 m))\n\n\n4.53893\n3.17166\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 1.0 m))\n\n\n6.79182\n-4.93775\nQuadrangle((x: 5.0 m, y: 0.0 m), ..., (x: 5.0 m, y: 1.0 m))\n\n\n9.36777\n-7.63681\nQuadrangle((x: 6.0 m, y: 0.0 m), ..., (x: 6.0 m, y: 1.0 m))\n\n\n7.50485\n-5.18151\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 1.0 m))\n\n\n11.2884\n1.1928\nQuadrangle((x: 8.0 m, y: 0.0 m), ..., (x: 8.0 m, y: 1.0 m))\n\n\n5.84379\n-2.40664\nQuadrangle((x: 9.0 m, y: 0.0 m), ..., (x: 9.0 m, y: 1.0 m))\n\n\n⋮\n⋮\n⋮\n\n\n\n\n\nThe Replace transform can be used to replace specific values in the geotable by new values that are meaningful to the analysis. For example, we can replace the values -999 and NaN that are used to represent missing values in some file formats:\n\nrtb = georef((a=[1,-999,3], b=[NaN,5,6]))\n\n\n3×3 GeoTable over 3 CartesianGrid\n\n\na\nb\ngeometry\n\n\nCategorical\nContinuous\nSegment\n\n\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n1\nNaN\nSegment((x: 0.0 m), (x: 1.0 m))\n\n\n-999\n5.0\nSegment((x: 1.0 m), (x: 2.0 m))\n\n\n3\n6.0\nSegment((x: 2.0 m), (x: 3.0 m))\n\n\n\n\n\n\nrtb |&gt; Replace(-999 =&gt; missing, NaN =&gt; missing)\n\n\n3×3 GeoTable over 3 CartesianGrid\n\n\na\nb\ngeometry\n\n\nCategorical\nContinuous\nSegment\n\n\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n1\nmissing\nSegment((x: 0.0 m), (x: 1.0 m))\n\n\nmissing\n5.0\nSegment((x: 1.0 m), (x: 2.0 m))\n\n\n3\n6.0\nSegment((x: 2.0 m), (x: 3.0 m))\n\n\n\n\n\nor replace all negative values using a predicate function:\n\nrtb |&gt; Replace(&lt;(0) =&gt; missing)\n\n\n3×3 GeoTable over 3 CartesianGrid\n\n\na\nb\ngeometry\n\n\nCategorical\nContinuous\nSegment\n\n\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n1\nNaN\nSegment((x: 0.0 m), (x: 1.0 m))\n\n\nmissing\n5.0\nSegment((x: 1.0 m), (x: 2.0 m))\n\n\n3\n6.0\nSegment((x: 2.0 m), (x: 3.0 m))\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn Julia, the expression &lt;(0) is equivalent to the predicate function x -&gt; x &lt; 0.\n\n\nAlthough Replace could be used to replace missing values by new values, there is a specific transform for this purpose named Coalesce:\n\nctb = georef((a=[1,missing,3], b=[4,5,6])) |&gt; Coalesce(value=2)\n\n\n3×3 GeoTable over 3 CartesianGrid\n\n\na\nb\ngeometry\n\n\nCategorical\nCategorical\nSegment\n\n\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n1\n4\nSegment((x: 0.0 m), (x: 1.0 m))\n\n\n2\n5\nSegment((x: 1.0 m), (x: 2.0 m))\n\n\n3\n6\nSegment((x: 2.0 m), (x: 3.0 m))\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nUnlike Replace, the Coalesce transform also changes the column type to make sure that no missing values can be stored in the future:\n\ntypeof(ctb.a)\n\nVector{Int64} (alias for Array{Int64, 1})\n\n\n\n\nIn many applications, it is enough to simply drop all rows for which the selected column values are missing. This is the purpose of the DropMissing transform:\n\ngeoref((a=[1,missing,3], b=[4,5,6])) |&gt; DropMissing()\n\n\n2×3 GeoTable over 2 view(::CartesianGrid, [1, 3])\n\n\na\nb\ngeometry\n\n\nCategorical\nCategorical\nSegment\n\n\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n1\n4\nSegment((x: 0.0 m), (x: 1.0 m))\n\n\n3\n6\nSegment((x: 2.0 m), (x: 3.0 m))\n\n\n\n\n\nThe DropNaN is an alternative to drop all rows for which the selected column values are NaN.\n\n\n5.2.3 Statistical\nThe framework provides various feature transforms for statistical analysis. We will cover some of these transforms in more detail in Part V of the book with real data. In the following examples we illustrate the most basic statistical transforms with synthetic data.\nThe Sample transform can be used to sample rows of the geotable at random, with or without replacement depending on the replace option. Other options are available such as rng to set the random number generator and ordered to preserve the order of rows in the original geotable:\n\ngtb |&gt; Sample(1000, replace=false) |&gt; viewer\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSimilar to Filter and Sort, the Sample transform is lazy. It simply stores the indices of sampled rows for future construction of the new geotable.\n\n\nThe Center and Scale transforms can be used to standardize the range of values in a geotable. Aliases are provided for specific types of Scale such as MinMax and Interquartile. We can use the describe function to visualize basic statistics before and after the transforms:\n\ngtb |&gt; describe\n\nTable with 6 columns and 4 rows:\n     variable  mean         minimum   median       maximum  nmissing\n   ┌────────────────────────────────────────────────────────────────\n 1 │ a         2.99482      -4.46696  2.00896      13.9461  0\n 2 │ b         -0.0493557   -10.3206  -0.0926622   11.0995  0\n 3 │ c         0.00438327   -3.43734  0.000758373  3.64675  0\n 4 │ d         -0.00302919  -4.3051   0.00263167   4.37251  0\n\n\n\ngtb |&gt; Center(\"a\") |&gt; describe\n\nTable with 6 columns and 4 rows:\n     variable  mean          minimum   median       maximum  nmissing\n   ┌─────────────────────────────────────────────────────────────────\n 1 │ a         -3.63798e-16  -7.46177  -0.985852    10.9513  0\n 2 │ b         -0.0493557    -10.3206  -0.0926622   11.0995  0\n 3 │ c         0.00438327    -3.43734  0.000758373  3.64675  0\n 4 │ d         -0.00302919   -4.3051   0.00263167   4.37251  0\n\n\n\ngtb |&gt; MinMax() |&gt; describe\n\nTable with 6 columns and 4 rows:\n     variable  mean      minimum  median    maximum  nmissing\n   ┌─────────────────────────────────────────────────────────\n 1 │ a         0.405243  0.0      0.351702  1.0      0\n 2 │ b         0.479515  0.0      0.477493  1.0      0\n 3 │ c         0.485838  0.0      0.485326  1.0      0\n 4 │ d         0.495767  0.0      0.496419  1.0      0\n\n\nThe ZScore transform is similar to the Scale transform, but it uses the mean and the standard deviation to standardize the range:\n\ngtb |&gt; ZScore() |&gt; describe\n\nTable with 6 columns and 4 rows:\n     variable  mean          minimum   median       maximum  nmissing\n   ┌─────────────────────────────────────────────────────────────────\n 1 │ a         0.0           -2.19797  -0.290397    3.22587  0\n 2 │ b         1.81188e-17   -3.98958  -0.0168212   4.33046  0\n 3 │ c         6.03961e-18   -3.44044  -0.00362355  3.64101  0\n 4 │ d         -3.41061e-17  -3.69106  0.00485687   3.75409  0\n\n\nAnother important univariate transform is the Quantile transform, which can be used to convert empirical distribution in a column of the geotable to any given distribution from Distributions.jl by Lin et al. (2023). Selected columns are converted to a Normal distribution by default, but more than 60 distributions are available:\n\ngtb |&gt; Quantile() |&gt; values |&gt; pairplot\n\n\n\n\nIn data science, scientific traits are used to link data types to adequate statistical algorithms. The most popular scientific traits encountered in geoscientific applications are the Continuous and the Categorical scientific traits. To convert (or coerce) the scientific traits of columns in a geotable, we can use the Coerce transform:\n\nstb = georef((a=[1,2,2,2,3,3], b=[1,2,3,4,5,6])) |&gt; Coerce(\"b\" =&gt; Continuous)\n\n\n6×3 GeoTable over 6 CartesianGrid\n\n\na\nb\ngeometry\n\n\nCategorical\nContinuous\nSegment\n\n\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n1\n1.0\nSegment((x: 0.0 m), (x: 1.0 m))\n\n\n2\n2.0\nSegment((x: 1.0 m), (x: 2.0 m))\n\n\n2\n3.0\nSegment((x: 2.0 m), (x: 3.0 m))\n\n\n2\n4.0\nSegment((x: 3.0 m), (x: 4.0 m))\n\n\n3\n5.0\nSegment((x: 4.0 m), (x: 5.0 m))\n\n\n3\n6.0\nSegment((x: 5.0 m), (x: 6.0 m))\n\n\n\n\n\n\neltype(stb.b)\n\nFloat64\n\n\n\n\n\n\n\n\nNote\n\n\n\nAll scientific traits are documented in the DataScienceTraits.jl module, and can be used to select variables:\n\nstb |&gt; Only(Continuous)\n\n\n6×2 GeoTable over 6 CartesianGrid\n\n\nb\ngeometry\n\n\nContinuous\nSegment\n\n\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n1.0\nSegment((x: 0.0 m), (x: 1.0 m))\n\n\n2.0\nSegment((x: 1.0 m), (x: 2.0 m))\n\n\n3.0\nSegment((x: 2.0 m), (x: 3.0 m))\n\n\n4.0\nSegment((x: 3.0 m), (x: 4.0 m))\n\n\n5.0\nSegment((x: 4.0 m), (x: 5.0 m))\n\n\n6.0\nSegment((x: 5.0 m), (x: 6.0 m))\n\n\n\n\n\n\n\nThe Levels transform can be used to adjust the categories (or levels) of Categorical columns in case the sampling process does not include all possible values:\n\nstb = stb |&gt; Levels(\"a\" =&gt; [1,2,3,4])\n\n\n6×3 GeoTable over 6 CartesianGrid\n\n\na\nb\ngeometry\n\n\nCategorical\nContinuous\nSegment\n\n\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n1\n1.0\nSegment((x: 0.0 m), (x: 1.0 m))\n\n\n2\n2.0\nSegment((x: 1.0 m), (x: 2.0 m))\n\n\n2\n3.0\nSegment((x: 2.0 m), (x: 3.0 m))\n\n\n2\n4.0\nSegment((x: 3.0 m), (x: 4.0 m))\n\n\n3\n5.0\nSegment((x: 4.0 m), (x: 5.0 m))\n\n\n3\n6.0\nSegment((x: 5.0 m), (x: 6.0 m))\n\n\n\n\n\n\nlevels(stb.a)\n\n4-element Vector{Int64}:\n 1\n 2\n 3\n 4\n\n\nAnother popular transform in statistical learning is the OneHot transform. It converts a Categorical column into multiple columns of true/false values, one column for each level:\n\nstb |&gt; OneHot(\"a\")\n\n\n6×6 GeoTable over 6 CartesianGrid\n\n\na_1\na_2\na_3\na_4\nb\ngeometry\n\n\nCategorical\nCategorical\nCategorical\nCategorical\nContinuous\nSegment\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\ntrue\nfalse\nfalse\nfalse\n1.0\nSegment((x: 0.0 m), (x: 1.0 m))\n\n\nfalse\ntrue\nfalse\nfalse\n2.0\nSegment((x: 1.0 m), (x: 2.0 m))\n\n\nfalse\ntrue\nfalse\nfalse\n3.0\nSegment((x: 2.0 m), (x: 3.0 m))\n\n\nfalse\ntrue\nfalse\nfalse\n4.0\nSegment((x: 3.0 m), (x: 4.0 m))\n\n\nfalse\nfalse\ntrue\nfalse\n5.0\nSegment((x: 4.0 m), (x: 5.0 m))\n\n\nfalse\nfalse\ntrue\nfalse\n6.0\nSegment((x: 5.0 m), (x: 6.0 m))\n\n\n\n\n\nA similar transform for Continuous columns is the Indicator transform. It converts the column into multiple columns based on threshold values on the support of the data. By default, the threshold values are computed on a quantile scale:\n\nstb |&gt; Indicator(\"b\", k=3, scale=:quantile)\n\n\n6×5 GeoTable over 6 CartesianGrid\n\n\na\nb_1\nb_2\nb_3\ngeometry\n\n\nCategorical\nCategorical\nCategorical\nCategorical\nSegment\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n1\ntrue\ntrue\ntrue\nSegment((x: 0.0 m), (x: 1.0 m))\n\n\n2\ntrue\ntrue\ntrue\nSegment((x: 1.0 m), (x: 2.0 m))\n\n\n2\nfalse\ntrue\ntrue\nSegment((x: 2.0 m), (x: 3.0 m))\n\n\n2\nfalse\ntrue\ntrue\nSegment((x: 3.0 m), (x: 4.0 m))\n\n\n3\nfalse\nfalse\ntrue\nSegment((x: 4.0 m), (x: 5.0 m))\n\n\n3\nfalse\nfalse\ntrue\nSegment((x: 5.0 m), (x: 6.0 m))\n\n\n\n\n\nMore advanced statistical transforms such as EigenAnalysis, PCA, DRS, SDS, ProjectionPursuit for multivariate data analysis and Remainder, Closure, LogRatio, ALR, CLR, ILR for compositional data analysis will be covered in future chapters.",
    "crumbs": [
      "Part II: Transforms",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What are transforms?</span>"
    ]
  },
  {
    "objectID": "05-transforms.html#geometric-transforms",
    "href": "05-transforms.html#geometric-transforms",
    "title": "5  What are transforms?",
    "section": "5.3 Geometric transforms",
    "text": "5.3 Geometric transforms\nWhile feature transforms operate on the values of the geotable, geometric transforms operate on the geospatial domain. The framework provides various geometric transforms for 2D and 3D space.\n\n5.3.1 Coordinate\nA coordinate transform is a geometric transform that modifies the coordinates of all points in the domain without any advanced topological modification (i.e., connectivities are preserved). The most prominent examples of coordinate transforms are Translate, Rotate and Scale.\nLet’s load an additional geotable to see these transforms in action:\n\nusing GeoIO\n\nbtb = GeoIO.load(\"data/beethoven.ply\")\n\nviz(btb.geometry)\n\n\n\n\nThe Beethoven domain has been saved in the .ply file in a position that is not ideal for visualization. We can rotate this domain with any active rotation specification from Rotations.jl by Koolen et al. (2023) to improve the visualization. For example, we can specify that we want to rotate all points in the mesh by analogy with a rotation between coordinates (0, 1, 0) and coordinates (0, 0, 1):\n\nrtb = btb |&gt; Rotate((0, 1, 0), (0, 0, 1))\n\nviz(rtb.geometry)\n\n\n\n\nBeethoven is now standing up, but still facing the wall. Let’s rotate it once again by analogy between coordinates (1, 0, 0) and (-1, 1, 0):\n\nrtb = rtb |&gt; Rotate((1, 0, 0), (-1, 1, 0))\n\nviz(rtb.geometry)\n\n\n\n\nRotation specifications are also available in 2D space. As an example, we can rotate the 2D grid of our synthetic geotable by the counter clockwise angle π/4:\n\ngtb |&gt; Rotate(Angle2d(π/4)) |&gt; viewer\n\n\n\n\nIn GIS, this new geotable would be called a rotated “raster”. As another example, let’s translate the geotable to the origin of the coordinate system with the Translate transform:\n\nc = centroid(gtb.geometry)\n\ngtb |&gt; Translate(-to(c)...) |&gt; viewer\n\n\n\n\nand scale it with a positive factor for each dimension:\n\ngtb |&gt; Scale(0.1, 0.2) |&gt; viewer\n\n\n\n\nThe StdCoords transform combines Translate and Scale to standardize the coordinates of the domain to the interval [-0.5, 0.5]:\n\ngtb |&gt; StdCoords() |&gt; viewer\n\n\n\n\nIn GIS, another very important coordinate transform is the Proj transform. We will cover this transform in the next chapter because it depends on the concept of map projection, which deserves more attention.\n\n\n\n\n\n\nNote\n\n\n\nIn our framework, the Proj transform is just another coordinate transform. It is implemented with the same code optimizations, and can be used in conjunction with many other transforms that are not available elsewhere.\n\n\n\n\n5.3.2 Advanced\nAdvanced geometric transforms are provided that change the topology of the domain besides the coordinates of points. Some of these transforms can be useful to repair problematic geometries acquired from sensors in the real world.\nThe Repair transform is parameterized by an integer K that identifies the repair to be performed. For example, Repair{0}() is a transform that removes duplicated vertices and faces in a domain represented by a mesh. The Repair{9}() on the other hand fixes the orientation of rings in polygonal areas so that the external boundary is oriented counter clockwise and the inner boundaries are oriented clockwise. The list of available repairs will continue to grow with the implementation of new geometric algorithms in the framework.\nTo understand why geometric transforms are more general than coordinate transforms, let’s consider the following polygonal area with holes:\n\nouter = [(0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 1.0)]\nhole1 = [(0.2, 0.2), (0.2, 0.4), (0.4, 0.4), (0.4, 0.2)]\nhole2 = [(0.6, 0.2), (0.6, 0.4), (0.8, 0.4), (0.8, 0.2)]\npoly  = PolyArea([outer, hole1, hole2])\n\nviz(poly)\n\n\n\n\nWe can connect the holes with the external boundary (or ring) using the Bridge transform:\n\npoly |&gt; Bridge(0.01) |&gt; viz\n\n\n\n\nBy looking at the visualization, we observe that the number of vertices changed to accommodate the so called “bridges” between the rings. The topology also changed as there are no holes in the resulting geometry.\nAs a final example of advanced geometric transform, we illustrate the TaubinSmoothing transform, which gradually removes sharp boundaries of a manifold mesh:\n\nstb = btb |&gt; TaubinSmoothing(30)\n\nfig = Mke.Figure()\nviz(fig[1,1], btb.geometry)\nviz(fig[1,2], stb.geometry)\nfig\n\n\n\n\nFor more advanced geometric transforms, please consult the official documentation.",
    "crumbs": [
      "Part II: Transforms",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What are transforms?</span>"
    ]
  },
  {
    "objectID": "05-transforms.html#geospatial-transforms",
    "href": "05-transforms.html#geospatial-transforms",
    "title": "5  What are transforms?",
    "section": "5.4 Geospatial transforms",
    "text": "5.4 Geospatial transforms\nGeospatial transforms are those transforms that operate on both the values and the domain of the geotable. They are common in geostatistical workflows that need to remove geospatial “trends” or workflows that need to extract geometries from domains.\nAs an example, let’s consider the following geotable with a variable z that made of a trend component μ and a noise component ϵ:\n\n# quadratic + noise\nr = range(-1, stop=1, length=100)\nμ = [x^2 + y^2 for x in r, y in r]\nϵ = 0.1rand(100, 100)\nt = georef((z=μ+ϵ,))\n\nviewer(t)\n\n\n\n\nWe can use the Detrend transform to remove a trend of polynomial degree 2:\n\nt |&gt; Detrend(degree=2) |&gt; viewer\n\n\n\n\nThe remaining component can then be modeled with geostatistical models of geospatial correlation, which will be covered in Part IV of the book.\nModels of geospatial correlation such as variograms (Hoffimann and Zadrozny 2019) require unique coordinates in the geotable and that is the purpose of the UniqueCoords transform. It removes duplicate points in the geotable and aggregates the values with custom aggregation functions.\nLet’s consider the following geotable stored in a .png file to illustrate another geospatial transform:\n\nletters = GeoIO.load(\"data/letters.png\")\n\n\n44255×2 GeoTable over 265×167 TransformedGrid\n\n\ncolor\ngeometry\n\n\nColorful\nQuadrangle\n\n\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\nGray{N0f8}(1.0)\nQuadrangle((x: -1.62266e-14 m, y: 265.0 m), ..., (x: 1.0 m, y: 265.0 m))\n\n\nGray{N0f8}(1.0)\nQuadrangle((x: -1.61653e-14 m, y: 264.0 m), ..., (x: 1.0 m, y: 264.0 m))\n\n\nGray{N0f8}(1.0)\nQuadrangle((x: -1.61041e-14 m, y: 263.0 m), ..., (x: 1.0 m, y: 263.0 m))\n\n\nGray{N0f8}(1.0)\nQuadrangle((x: -1.60429e-14 m, y: 262.0 m), ..., (x: 1.0 m, y: 262.0 m))\n\n\nGray{N0f8}(1.0)\nQuadrangle((x: -1.59816e-14 m, y: 261.0 m), ..., (x: 1.0 m, y: 261.0 m))\n\n\nGray{N0f8}(1.0)\nQuadrangle((x: -1.59204e-14 m, y: 260.0 m), ..., (x: 1.0 m, y: 260.0 m))\n\n\nGray{N0f8}(1.0)\nQuadrangle((x: -1.58592e-14 m, y: 259.0 m), ..., (x: 1.0 m, y: 259.0 m))\n\n\nGray{N0f8}(1.0)\nQuadrangle((x: -1.57979e-14 m, y: 258.0 m), ..., (x: 1.0 m, y: 258.0 m))\n\n\nGray{N0f8}(1.0)\nQuadrangle((x: -1.57367e-14 m, y: 257.0 m), ..., (x: 1.0 m, y: 257.0 m))\n\n\nGray{N0f8}(1.0)\nQuadrangle((x: -1.56755e-14 m, y: 256.0 m), ..., (x: 1.0 m, y: 256.0 m))\n\n\n⋮\n⋮\n\n\n\n\n\nThe Potrace transform can be used to extract complex geometries from a geotable over a 2D Grid. It transforms the Grid domain into a GeometrySet based on any column that contains a discrete set of marker values. In this example, we use the color as the column with markers:\n\nAb = letters |&gt; Potrace(\"color\", ϵ=0.8)\n\n\n2×2 GeoTable over 2 GeometrySet\n\n\ncolor\ngeometry\n\n\nColorful\nMultiPolygon\n\n\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\nGray{N0f8}(1.0)\nMulti(4×PolyArea)\n\n\nGray{N0f8}(0.0)\nMulti(2×PolyArea)\n\n\n\n\n\nThe option ϵ controls the deviation tolerance used to simplify the boundaries of the geometries. The higher is the tolerance, the less is the number of segments in the boundary:\n\nviz(Ab.geometry[2], color = \"black\")\n\n\n\n\nIn the reverse direction, we have the Rasterize transform, which takes a geotable over a GeometrySet and assigns the geometries to a Grid. In this transform, we can either provide an external grid for the the assignments, or request a grid size to discretize the boundingbox of all geometries:\n\nA = [1, 2, 3, 4, 5]\nB = [1.1, 2.2, 3.3, 4.4, 5.5]\np1 = Triangle((2, 0), (6, 2), (2, 2))\np2 = Triangle((0, 6), (3, 8), (0, 10))\np3 = Quadrangle((3, 6), (9, 6), (9, 9), (6, 9))\np4 = Quadrangle((7, 0), (10, 0), (10, 4), (7, 4))\np5 = Pentagon((1, 3), (5, 3), (6, 6), (3, 8), (0, 6))\ngtb = georef((; A, B), [p1, p2, p3, p4, p5])\n\n\n5×3 GeoTable over 5 GeometrySet\n\n\nA\nB\ngeometry\n\n\nCategorical\nContinuous\nNgon\n\n\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n1\n1.1\nTriangle((x: 2.0 m, y: 0.0 m), (x: 6.0 m, y: 2.0 m), (x: 2.0 m, y: 2.0 m))\n\n\n2\n2.2\nTriangle((x: 0.0 m, y: 6.0 m), (x: 3.0 m, y: 8.0 m), (x: 0.0 m, y: 10.0 m))\n\n\n3\n3.3\nQuadrangle((x: 3.0 m, y: 6.0 m), ..., (x: 6.0 m, y: 9.0 m))\n\n\n4\n4.4\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 4.0 m))\n\n\n5\n5.5\nPentagon((x: 1.0 m, y: 3.0 m), ..., (x: 0.0 m, y: 6.0 m))\n\n\n\n\n\n\ngtb |&gt; viewer\n\n\n\n\n\nntb = gtb |&gt; Rasterize(20, 20)\n\n\n400×3 GeoTable over 20×20 CartesianGrid\n\n\nA\nB\ngeometry\n\n\nCategorical\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\nmissing\nmissing\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 0.5 m))\n\n\nmissing\nmissing\nQuadrangle((x: 0.5 m, y: 0.0 m), ..., (x: 0.5 m, y: 0.5 m))\n\n\nmissing\nmissing\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 0.5 m))\n\n\n1\n1.1\nQuadrangle((x: 1.5 m, y: 0.0 m), ..., (x: 1.5 m, y: 0.5 m))\n\n\n1\n1.1\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 0.5 m))\n\n\nmissing\nmissing\nQuadrangle((x: 2.5 m, y: 0.0 m), ..., (x: 2.5 m, y: 0.5 m))\n\n\nmissing\nmissing\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 0.5 m))\n\n\nmissing\nmissing\nQuadrangle((x: 3.5 m, y: 0.0 m), ..., (x: 3.5 m, y: 0.5 m))\n\n\nmissing\nmissing\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 0.5 m))\n\n\nmissing\nmissing\nQuadrangle((x: 4.5 m, y: 0.0 m), ..., (x: 4.5 m, y: 0.5 m))\n\n\n⋮\n⋮\n⋮\n\n\n\n\n\n\nntb |&gt; viewer\n\n\n\n\nThe values of the variables are aggregated at geometric intersections using a default aggregation function, which can be overwritten with an option. Once the geotable is defined over a Grid, it is possible to refine or coarsen the grid with the Downscale and Upscale transforms.\nThe Transfer of values to a new geospatial domain is another very useful geospatial transform. The Aggregate transform is related, but aggregates the values with given aggregation functions.",
    "crumbs": [
      "Part II: Transforms",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What are transforms?</span>"
    ]
  },
  {
    "objectID": "05-transforms.html#remarks",
    "href": "05-transforms.html#remarks",
    "title": "5  What are transforms?",
    "section": "5.5 Remarks",
    "text": "5.5 Remarks\nIn this chapter we learned the important concept of transforms, and saw examples of the concept in action with synthetic data. In order to leverage the large number of transforms implemented in the framework, all we need to do is load our geospatial data as a geotable using georef or GeoIO.jl.\nSome additional remarks:\n\nOne of the major advantages of transforms compared to traditional row/column access in data science is that they preserve geospatial information. There is no need to keep track of indices in arrays to repeatedly reattach values to geometries.\nTransforms can be organized into three classes—feature, geometric and geospatial—depending on how they operate with the values and the domain of the geotable:\n\nFeature transforms operate on the values. They include column selection, data cleaning, statistical analysis and any transform designed for traditional Tables.jl.\nGeometric transforms operate on the domain. They include coordinate transforms that simply modify the coordinates of points as well as more advanced transforms that can change the topology of the domain.\nGeospatial transforms operate on both the values and domain. They include geostatistical transforms and transforms that use other columns besides the geometry column to produce new columns and geometries.\n\n\nIn the next chapters, we will review map projections with the Proj coordinate transform, and will introduce one of the greatest features of the framework known as transform pipelines.\n\n\n\n\nHoffimann, Júlio, and Bianca Zadrozny. 2019. “Efficient Variography with Partition Variograms.” Computers & Geosciences 131: 52–59. https://doi.org/https://doi.org/10.1016/j.cageo.2019.06.013.\n\n\nKoolen, Twan, Yuto Horikawa, Andy Ferris, Claire Foster, awbsmith, ryanelandt, Jan Weidner, et al. 2023. “JuliaGeometry/Rotations.jl: V1.6.0.” Zenodo. https://doi.org/10.5281/zenodo.8366010.\n\n\nLin, Dahua, David Widmann, Simon Byrne, John Myles White, Andreas Noack, Mathieu Besançon, Douglas Bates, et al. 2023. “JuliaStats/Distributions.jl: V0.25.100.” Zenodo. https://doi.org/10.5281/zenodo.8224988.\n\n\nThompson, William. 2023. “PairPlots.jl Beautiful and Flexible Visualizations of High Dimensional Data.” https://sefffal.github.io/PairPlots.jl/dev.",
    "crumbs": [
      "Part II: Transforms",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What are transforms?</span>"
    ]
  },
  {
    "objectID": "06-projections.html",
    "href": "06-projections.html",
    "title": "6  Map projections",
    "section": "",
    "text": "6.1 Basic\nIn this chapter, we detach the concept of Point from its geospatial coordinates in a given coordinate reference system (CRS). We explain how the same point in the physical world can be represented with multiple geospatial coordinates, and illustrate various types of CRS catalogued in the EPSG Dataset.\nThe framework classifies the various CRS as Basic, Geographic or Projected, all of which can depend on a geodetic datum. The following sections introduce these very important concepts in geospatial data science, as well as the Proj transform for CRS conversion.\nIn previous chapters, the construction of geometries assumed a Cartesian Coordinate Reference System, or CRS for short. In all previous examples, we constructed Points with Cartesian coordinates in m units:\npoint = Point(1, 2)\n\nPoint with Cartesian{NoDatum} coordinates\n├─ x: 1.0 m\n└─ y: 2.0 m\nThese coordinates can be retrieved with the coords function:\ncart = coords(point)\n\nCartesian{NoDatum} coordinates\n├─ x: 1.0 m\n└─ y: 2.0 m\nTo represent the same point in a Polar CRS, in terms of a radius ρ and an angle ϕ, we can convert its coordinates and reconstruct the point:\npolar = convert(Polar, cart)\n\nPolar{NoDatum} coordinates\n├─ ρ: 2.23606797749979 m\n└─ ϕ: 1.1071487177940904 rad\nPoint(polar)\n\nPoint with Polar{NoDatum} coordinates\n├─ ρ: 2.23606797749979 m\n└─ ϕ: 1.1071487177940904 rad\nEven though this process is transparent, it would be very tedious to perform this conversion for all Points of Geometrys in a domain of a GeoTable, and reconstruct the result efficiently. That is where the Proj transform becomes useful:\nPoint(1, 2) |&gt; Proj(Polar)\n\nPoint with Polar{NoDatum} coordinates\n├─ ρ: 2.23606797749979 m\n└─ ϕ: 1.1071487177940904 rad\nThis transform takes vectors of Geometrys, Domain or GeoTable and converts the underlying coordinates to a given target CRS efficiently, exploiting lazy representations of Grids:\nCartesianGrid(100, 100, 100) |&gt; Proj(Cylindrical)\n\n100×100×100 TransformedGrid\n  1030301 vertices\n  ├─ Point(ρ: 0.0 m, ϕ: 0.0 rad, z: 0.0 m)\n  ├─ Point(ρ: 1.0 m, ϕ: 0.0 rad, z: 0.0 m)\n  ├─ Point(ρ: 2.0 m, ϕ: 0.0 rad, z: 0.0 m)\n  ├─ Point(ρ: 3.0 m, ϕ: 0.0 rad, z: 0.0 m)\n  ├─ Point(ρ: 4.0 m, ϕ: 0.0 rad, z: 0.0 m)\n  ⋮\n  ├─ Point(ρ: 138.62178760930766 m, ϕ: 0.8058034940839864 rad, z: 100.0 m)\n  ├─ Point(ρ: 139.31618714277246 m, ϕ: 0.8006254127745656 rad, z: 100.0 m)\n  ├─ Point(ρ: 140.0142849854971 m, ϕ: 0.7954988299827702 rad, z: 100.0 m)\n  ├─ Point(ρ: 140.71602609511115 m, ϕ: 0.7904232467282607 rad, z: 100.0 m)\n  └─ Point(ρ: 141.4213562373095 m, ϕ: 0.7853981633974483 rad, z: 100.0 m)\n  1000000 elements\n  ├─ Hexahedron(1, 2, 103, 102, 10202, 10203, 10304, 10303)\n  ├─ Hexahedron(2, 3, 104, 103, 10203, 10204, 10305, 10304)\n  ├─ Hexahedron(3, 4, 105, 104, 10204, 10205, 10306, 10305)\n  ├─ Hexahedron(4, 5, 106, 105, 10205, 10206, 10307, 10306)\n  ├─ Hexahedron(5, 6, 107, 106, 10206, 10207, 10308, 10307)\n  ⋮\n  ├─ Hexahedron(1019994, 1019995, 1020096, 1020095, 1030195, 1030196, 1030297, 1030296)\n  ├─ Hexahedron(1019995, 1019996, 1020097, 1020096, 1030196, 1030197, 1030298, 1030297)\n  ├─ Hexahedron(1019996, 1019997, 1020098, 1020097, 1030197, 1030198, 1030299, 1030298)\n  ├─ Hexahedron(1019997, 1019998, 1020099, 1020098, 1030198, 1030199, 1030300, 1030299)\n  └─ Hexahedron(1019998, 1019999, 1020100, 1020099, 1030199, 1030200, 1030301, 1030300)\nAlthough the conversion between Basic CRS doesn’t affect the position of points:\nPoint(cart) ≈ Point(polar)\n\ntrue\nIt can be useful to write geospatial algorithms in terms of specific coordinates of interest:\ncart.x\n\n1.0 m\ncart.y\n\n2.0 m\npolar.ρ\n\n2.23606797749979 m\npolar.ϕ\n\n1.1071487177940904 rad\nAll coordinate values in the framework have well-defined units to facilitate the development of geospatial applications with full support for different unit systems (e.g., English units).",
    "crumbs": [
      "Part II: Transforms",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Map projections</span>"
    ]
  },
  {
    "objectID": "06-projections.html#basic",
    "href": "06-projections.html#basic",
    "title": "6  Map projections",
    "section": "",
    "text": "Note\n\n\n\nOther units from Unitful.jl can be specified with the u\"...\" syntax:\n\nPoint(1u\"ft\", 2u\"cm\")\n\nPoint with Cartesian{NoDatum} coordinates\n├─ x: 0.3048 m\n└─ y: 0.02 m\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe syntax\nPoint(x, y, ...)\nis an alias to\nPoint(Cartesian(x, y, ...))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip for all users\n\n\n\nUnitful coordinate values address many pitfalls in geospatial applications. A simple comparison of coordinate values without units can lead to major engineering failures such as the roller coaster derailment at Tokyo Disneyland’s Space Mountain.\nConsider writing algorithms with units to avoid trivial issues in critical applications:\n\ncart.x &lt; 2u\"ft\"\n\nfalse\n\n\n\nustrip(cart.x) &lt; 2\n\ntrue\n\n\n\n\n\n\n\n\n\n\nTip for advanced users\n\n\n\nThe result of the coords function is not a vector, and therefore cannot be used in linear algebra. To retrieve the Vec from the origin of the CRS to the given Point, use the to function instead:\n\nto(point)\n\nVec(1.0 m, 2.0 m)\n\n\nThis utility function will always convert the CRS of the coordinates of the Point to Cartesian before returning the static vector:\n\np = Point(polar)\n\nPoint with Polar{NoDatum} coordinates\n├─ ρ: 2.23606797749979 m\n└─ ϕ: 1.1071487177940904 rad\n\n\n\nv = to(p)\n\nVec(1.0000000000000002 m, 2.0 m)",
    "crumbs": [
      "Part II: Transforms",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Map projections</span>"
    ]
  },
  {
    "objectID": "06-projections.html#geographic",
    "href": "06-projections.html#geographic",
    "title": "6  Map projections",
    "section": "6.2 Geographic",
    "text": "6.2 Geographic\nUnlike Basic CRS, which are commonly employed in engineering applications where the geospatial domain is small compared to the Earth, Geographic CRS depend on a geodetic datum:\n\n\n\n\n\n\nDefinition\n\n\n\nA geodetic datum is the combination of a ellipsoid of revolution (a.k.a., spheroid) that approximates the surface of the Earth and a reference physical point that identifies the origin of the CRS.\n\n\nTo illustrate this concept, we start with the most widely used Geographic CRS:\n\nlatlon = LatLon(0, 90)\n\nGeodeticLatLon{WGS84Latest} coordinates\n├─ lat: 0.0°\n└─ lon: 90.0°\n\n\n\n\n\n\n\n\nNote\n\n\n\nLatLon is an alias for GeodeticLatLon.\n\n\nIn the geodetic LatLon CRS, the longitude coordinate is the horizontal angle measured in degrees from the Greenwich (or prime) meridian:\n\nlatlon.lon\n\n90.0°\n\n\nThe latitude coordinate is the vertical angle measured in degrees from the Equator parallel:\n\nlatlon.lat\n\n0.0°\n\n\nThe geodetic datum of this CRS can be retrieved with the datum function:\n\ndatum(latlon)\n\nWGS84Latest (alias for WGS84{2296})\n\n\nIt contains the ellipsoid of revolution:\n\nellipsoid(datum(latlon))\n\nCoordRefSystems.WGS84🌎\n\n\nas well as other parameters used to convert from longitude and latitude angles to Cartesian coordinates in meters:\n\nconvert(Cartesian, latlon)\n\nCartesian{WGS84Latest} coordinates\n├─ x: 3.905482530786651e-10 m\n├─ y: 6.378137e6 m\n└─ z: 0.0 m\n\n\nIn this case, the WGS84Latest datum is propagated to the Cartesian CRS, which is no longer the default NoDatum of previous examples. The datum is used to display geometries with their actual shapes and sizes in the physical world:\n\nA = Point(LatLon(0, 0))\nB = Point(LatLon(0, 90))\nC = Point(LatLon(45, 90))\n\nsegments = [Segment(A, B), Segment(B, C), Segment(A, C)]\n\nviz(segments)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAll datum parameters are stored in the CRS type itself at compile time, and are statically retrieved by the Julia compiler during CRS conversion. This leads to extremely efficient code, and consequently extremely efficient Projections of large geotables.\n\n\nBelow is a more familiar example loaded with the GeoIO.jl module:\n\nusing GeoIO\n\nworld = GeoIO.load(\"data/countries.geojson\")\n\n\n177×3 GeoTable over 177 GeometrySet\n\n\nCOUNTRY\nREGION\ngeometry\n\n\nCategorical\nCategorical\nMultiPolygon\n\n\n[NoUnits]\n[NoUnits]\n🖈 GeodeticLatLon{WGS84Latest}\n\n\n\n\nFiji\nMelanesia\nMulti(3×PolyArea)\n\n\nTanzania\nEastern Africa\nMulti(1×PolyArea)\n\n\nW. Sahara\nNorthern Africa\nMulti(1×PolyArea)\n\n\nCanada\nNorthern America\nMulti(30×PolyArea)\n\n\nUnited States of America\nNorthern America\nMulti(10×PolyArea)\n\n\nKazakhstan\nCentral Asia\nMulti(1×PolyArea)\n\n\nUzbekistan\nCentral Asia\nMulti(1×PolyArea)\n\n\nPapua New Guinea\nMelanesia\nMulti(4×PolyArea)\n\n\nIndonesia\nSouth-Eastern Asia\nMulti(13×PolyArea)\n\n\nArgentina\nSouth America\nMulti(2×PolyArea)\n\n\n⋮\n⋮\n⋮\n\n\n\n\n\nThe GeodeticLatLon CRS is displayed in the subheader of the geometry column. It is used internally by the framework for advanced visualization and geometric processing:\n\nworld |&gt; Select(\"REGION\") |&gt; viewer\n\n\n\n\nWe can convert the GeodeticLatLon CRS to a GeocentricLatLon CRS where the latitude coordinate is measured with respect to the center of the ellipsoid:\n\nworld |&gt; Proj(GeocentricLatLon)\n\n\n177×3 GeoTable over 177 GeometrySet\n\n\nCOUNTRY\nREGION\ngeometry\n\n\nCategorical\nCategorical\nMultiPolygon\n\n\n[NoUnits]\n[NoUnits]\n🖈 GeocentricLatLon{WGS84Latest}\n\n\n\n\nFiji\nMelanesia\nMulti(3×PolyArea)\n\n\nTanzania\nEastern Africa\nMulti(1×PolyArea)\n\n\nW. Sahara\nNorthern Africa\nMulti(1×PolyArea)\n\n\nCanada\nNorthern America\nMulti(30×PolyArea)\n\n\nUnited States of America\nNorthern America\nMulti(10×PolyArea)\n\n\nKazakhstan\nCentral Asia\nMulti(1×PolyArea)\n\n\nUzbekistan\nCentral Asia\nMulti(1×PolyArea)\n\n\nPapua New Guinea\nMelanesia\nMulti(4×PolyArea)\n\n\nIndonesia\nSouth-Eastern Asia\nMulti(13×PolyArea)\n\n\nArgentina\nSouth America\nMulti(2×PolyArea)\n\n\n⋮\n⋮\n⋮\n\n\n\n\n\nor to a geodetic LatLonAlt, which also includes the altitude coordinate in meters:\n\nworld |&gt; Proj(LatLonAlt) |&gt; domain |&gt; first\n\nMultiPolyArea\n├─ PolyArea((lat: -16.0671°, lon: 180.0°, alt: 0.0 m), ..., (lat: -16.5552°, lon: 180.0°, alt: 0.0 m))\n├─ PolyArea((lat: -17.5048°, lon: 178.126°, alt: 0.0 m), ..., (lat: -17.3399°, lon: 178.374°, alt: 0.0 m))\n└─ PolyArea((lat: -16.0209°, lon: -179.793°, alt: 0.0 m), ..., (lat: -16.5018°, lon: -179.917°, alt: 0.0 m))\n\n\nThe crs function can be used to retrieve the CRS of any given Geometry, Domain, or GeoTable for use in the Proj transform:\n\ncrs(world)\n\nGeodeticLatLon{WGS84Latest, Quantity{Float64, NoDims, Unitful.FreeUnits{(°,), NoDims, nothing}}}\n\n\nAs a final example to illustrate the importance of the datum, consider the CRS conversion that preserves the definition of the coordinates, but changes the datum from WGS84Latest to ITRFLatest:\n\nPoint(LatLon(45, 45)) |&gt; Proj(LatLon{ITRFLatest})\n\nPoint with GeodeticLatLon{ITRFLatest} coordinates\n├─ lat: 45.000000000943224°\n└─ lon: 45.0°\n\n\nThese are still longitude and latitude coordinates, but measured with respect to a different ellipsoid:\n\nellipsoid(ITRFLatest)\n\nCoordRefSystems.GRS80🌎\n\n\nFrom these examples, we can see that the Proj transform accepts a CRS or a CRS{Datum} type. In the latter case, the new coordinates are expressed in terms of the specified datum:\n\nPoint(LatLon(45, 45)) |&gt; Proj(LatLonAlt{WGS84{2139}})\n\nPoint with GeodeticLatLonAlt{WGS84{2139}} coordinates\n├─ lat: 45.000000053516594°\n├─ lon: 44.999999990497585°\n└─ alt: -0.0037412531673908234 m\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe WGS84Latest datum is by far the most widely used datum in the world (e.g., GPS devices). It is often confused with the WGS84🌎 ellipsoid, which is not exported by the framework:\n\nellipsoid(WGS84Latest)\n\nCoordRefSystems.WGS84🌎",
    "crumbs": [
      "Part II: Transforms",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Map projections</span>"
    ]
  },
  {
    "objectID": "06-projections.html#projected",
    "href": "06-projections.html#projected",
    "title": "6  Map projections",
    "section": "6.3 Projected",
    "text": "6.3 Projected\nWe are finally ready to introduce Projected CRS. These are 2D coordinate reference systems obtained from longitude and latitude via specific mathematical formulae. The literature on this subject is quite dense, and it suffices to know that these formulas can be generally written as\n\\[\nx = f_x(\\lambda, \\varphi),\\quad y = f_y(\\lambda, \\varphi)\n\\]\nwhere \\(x\\) and \\(y\\) are the projected coordinates from longitude \\(\\lambda\\) and latitude \\(\\varphi\\).\nDifferent formulas \\(f_x\\) and \\(f_y\\) were proposed in the literature to preserve properties of geometries such as shape, size and angle. Since it is not possible to preserve all these properties at once, one must choose a Projected CRS carefully with the Proj transform before sending the geotable to the viewer, or before performing geometric calculations (e.g., distances).\nLet’s start with the historically famous Mercator CRS, designed to preserve angles (or bearings) for navigation. Its formulas are given by\n\\[\nx = R(\\lambda - \\lambda_o), \\quad y = R\\ln\\left(\\tan\\left(\\frac{\\pi}{4} + \\frac{\\varphi}{2}\\right)\\right)\n\\]\nwhere \\(R\\) is the major semiaxis of the ellipsoid of the datum, and \\(\\lambda_o\\) is the longitude of the origin (or central) meridian, not necessarily the Greenwich (i.e., \\(\\lambda_o=0\\)). We can viz the result of the formulas on a RegularGrid of LatLon coordinates:\n\nstart  = Point(LatLon(-80, -180))\nfinish = Point(LatLon(84, 180))\n\ngrid = RegularGrid(start, finish, dims=(20, 20))\n\n20×20 RegularGrid\n├─ minimum: Point(lat: -80.0°, lon: -180.0°)\n├─ maximum: Point(lat: 84.0°, lon: 180.0°)\n└─ spacing: (8.2°, 18.0°)\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe Mercator CRS is not well-defined at the poles \\(\\varphi = \\pm 90\\degree\\). It is common to restrict the visualization to the \\(-80\\degree \\le \\varphi \\le 84\\degree\\) latitude range.\n\n\n\npgrid = grid |&gt; Proj(Mercator)\n\n20×20 TransformedGrid\n  441 vertices\n  ├─ Point(x: -2.0037508342789244e7 m, y: -1.5496570739723716e7 m)\n  ├─ Point(x: -2.0037508342789244e7 m, y: -1.1640877666645138e7 m)\n  ├─ Point(x: -2.0037508342789244e7 m, y: -9.210594404921511e6 m)\n  ├─ Point(x: -2.0037508342789244e7 m, y: -7.404688904937668e6 m)\n  ├─ Point(x: -2.0037508342789244e7 m, y: -5.943414207077789e6 m)\n  ⋮\n  ├─ Point(x: 2.0037508342789244e7 m, y: 6.623426821665486e6 m)\n  ├─ Point(x: 2.0037508342789244e7 m, y: 8.230536506199419e6 m)\n  ├─ Point(x: 2.0037508342789244e7 m, y: 1.0289594640053453e7 m)\n  ├─ Point(x: 2.0037508342789244e7 m, y: 1.3244148388311565e7 m)\n  └─ Point(x: 2.0037508342789244e7 m, y: 1.8764656231380563e7 m)\n  400 elements\n  ├─ Quadrangle(1, 2, 23, 22)\n  ├─ Quadrangle(2, 3, 24, 23)\n  ├─ Quadrangle(3, 4, 25, 24)\n  ├─ Quadrangle(4, 5, 26, 25)\n  ├─ Quadrangle(5, 6, 27, 26)\n  ⋮\n  ├─ Quadrangle(415, 416, 437, 436)\n  ├─ Quadrangle(416, 417, 438, 437)\n  ├─ Quadrangle(417, 418, 439, 438)\n  ├─ Quadrangle(418, 419, 440, 439)\n  └─ Quadrangle(419, 420, 441, 440)\n\n\n\nfig = Mke.Figure()\nviz(fig[1,1], grid, showsegments = true)\nviz(fig[1,2], pgrid, showsegments = true)\nfig\n\n\n\n\nIt is clear from the visualization that areas are distorted away from the Equator. In other words, the Mercator CRS is not adequate for area calculations near the poles:\n\nextrema(area.(pgrid))\n\n(1.8196349467139988e12 m^2, 1.1061722196192861e13 m^2)\n\n\nIf the domain of interest is located far away from the Equator, and there is a need for area calculations, we can use other Projected CRS such as Lambert or GallPeters:\n\nfig = Mke.Figure()\nviz(fig[1,1], grid |&gt; Proj(Lambert), showsegments = true)\nviz(fig[1,2], grid |&gt; Proj(GallPeters), showsegments = true)\nfig\n\n\n\n\nThe formulas of some Projected CRS are quite evolved, and sometimes depend on tabulated values. Fortunately, this hard work has already been done in the CoordRefSystems.jl module.\n\n\n\n\n\n\nTip for advanced users\n\n\n\nCustom formulas can be quickly explored with the Morphological transform. It takes a function as input that maps one CRS into another. As an example, consider the sinusoidal projection defined by\n\\[\nx = (\\lambda - \\lambda_o) \\cos(\\varphi), \\quad y = \\varphi\n\\]\nand set \\(\\lambda_o = 0\\) for simplicity in the following Julia function:\n\nfunction sinproj(coords::LatLon)\n  λ = coords.lon\n  φ = coords.lat\n  x = ustrip(λ) * cos(φ)\n  y = ustrip(φ)\n  Cartesian(x, y)\nend\n\nsinproj (generic function with 1 method)\n\n\nWe can use this new function in the Morphological transform to convert the CRS of all points in the grid:\n\nviz(grid |&gt; Morphological(sinproj), showsegments = true)\n\n\n\n\n\n\nExamples of Projected CRS with a good compromise of shape, area and angle distortion include the Robinson and WinkelTripel:\n\nfig = Mke.Figure()\nviz(fig[1,1], grid |&gt; Proj(Robinson), showsegments = true)\nviz(fig[1,2], grid |&gt; Proj(WinkelTripel), showsegments = true)\nfig\n\n\n\n\nWe can create a more realistic map by loading the colors of the Earth stored in a GeoTIFF file:\n\nusing GeoIO\n\nearth = GeoIO.load(\"data/earth.tif\")\n\nearth |&gt; Proj(Robinson) |&gt; viewer\n\n\n\n\n\n\n\n\n\n\nTip for all users\n\n\n\nThe GeoArtifacts.jl module provides functions to (down)load such data from the web. It includes popular datasets such as NaturalEarth and GADM. The small earth.tif file was generated with the following script:\nusing GeoStats\nusing GeoArtifacts\nusing GeoIO\n\ngeotable = NaturalEarth.naturalearth1(\"water\")\n\nearth = geotable |&gt; Upscale(20, 10)\n\nGeoIO.save(\"data/earth.tif\", earth)\n\n\nPlease consult the official documentation for the full list of Projected CRS.",
    "crumbs": [
      "Part II: Transforms",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Map projections</span>"
    ]
  },
  {
    "objectID": "06-projections.html#utm",
    "href": "06-projections.html#utm",
    "title": "6  Map projections",
    "section": "6.4 UTM",
    "text": "6.4 UTM\nThe Universal Transverse Mercator (UTM) system defines a widely used collection of Projected CRS as a function of 60 zones in the northern and southern hemispheres. The utm function can be used to retrieve the TransverseMercator CRS given knowledge of the zone:\n\nutm(:north, 1)\n\nTransverseMercator{0.9996, 0.0°, WGS84Latest, CoordRefSystems.Shift{Quantity{Float64, NoDims, Unitful.FreeUnits{(°,), NoDims, nothing}}, Quantity{Float64, 𝐋, Unitful.FreeUnits{(m,), 𝐋, nothing}}}(-177.0°, 500000.0 m, 0.0 m)}\n\n\n\nutm(:south, 31)\n\nTransverseMercator{0.9996, 0.0°, WGS84Latest, CoordRefSystems.Shift{Quantity{Float64, NoDims, Unitful.FreeUnits{(°,), NoDims, nothing}}, Quantity{Float64, 𝐋, Unitful.FreeUnits{(m,), 𝐋, nothing}}}(3.0°, 500000.0 m, 1.0e7 m)}\n\n\nThese can be used in the Proj transform as usual. The zone number is a function of the longitude and latitude ranges of the domain of interest, and online resources exist to facilitate the identification of this number.\n\n\n\n\n\n\nTip for all users\n\n\n\nThe longitude and latitude ranges of a domain can be quickly found with the boundingbox:\n\nboundingbox(grid)\n\nBox\n├─ min: Point(lat: -80.0°, lon: -180.0°)\n└─ max: Point(lat: 84.0°, lon: 180.0°)\n\n\n\n\n\n\n\n\n\n\nTip for all users\n\n\n\nThe aliases utmnorth and utmsouth can be used to retrieve UTM zones from a specific hemisphere:\n\nutmnorth(1) == utm(:north, 1)\n\ntrue",
    "crumbs": [
      "Part II: Transforms",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Map projections</span>"
    ]
  },
  {
    "objectID": "06-projections.html#epsgesri",
    "href": "06-projections.html#epsgesri",
    "title": "6  Map projections",
    "section": "6.5 EPSG/ESRI",
    "text": "6.5 EPSG/ESRI\nThe EPSG Dataset was created in the mid 80s to catalogue the immense list of CRS in the literature, and their associated projection and datum parameters. It provides a unique identification code for each CRS that can be safely used across geospatial data science projects.\nThe CoordRefSystems.get function can be used to retrieve CRS from EPSG or ESRI codes:\n\nCoordRefSystems.get(EPSG{4326})\n\nGeodeticLatLon{WGS84Latest}\n\n\n\nCoordRefSystems.get(EPSG{3395})\n\nMercator{WGS84Latest}\n\n\n\nCoordRefSystems.get(ESRI{54030})\n\nRobinson{WGS84Latest}\n\n\nThese codes can be used directly in the Proj transform:\n\nPoint(LatLon(45, 45)) |&gt; Proj(EPSG{3395})\n\nPoint with Mercator{WGS84Latest} coordinates\n├─ x: 5.009377085697311e6 m\n└─ y: 5.5912959185533915e6 m\n\n\nThis feature is convenient, particularly when the CRS is complex to write.\n\n\n\n\n\n\nTip for all users\n\n\n\nThe official epsg.org website provides tools to search codes in the EPSG Dataset. Other websites such as epsg.io provide alternative tools that are more user-friendly.\n\n\nWe conclude this brief exposition of map projections with a few remarks:\n\nGetting used to the properties of various CRS takes time, however; this is an important skill to develop as a professional geospatial data scientist.\nAlthough the literature on map projections requires advanced mathematical background, the Proj transform facilitates the experimentation of various CRS in practice.",
    "crumbs": [
      "Part II: Transforms",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Map projections</span>"
    ]
  },
  {
    "objectID": "07-pipelines.html",
    "href": "07-pipelines.html",
    "title": "7  Building pipelines",
    "section": "",
    "text": "7.1 Motivation\nIn previous chapters, we learned a large number of transforms for manipulating and processing geotables. In all those code examples, we used Julia’s pipe operator |&gt; to apply the transform and send the resulting geotable to the next transform:\nIn this chapter, we will learn two new powerful operators → and ⊔ provided by the framework to combine transforms into pipelines that can be optimized and reused with different geotables.\nThe pipe operator |&gt; in Julia is very convenient for sequential application of functions. Given an input x, we can type x |&gt; f1 |&gt; f2 to apply functions f1 and f2 in sequence, in a way that is equivalent to f2(f1(x)) or, alternatively, to the function composition (f2 ∘ f1)(x). Its syntax can drastically improve code readability when the number of functions is large. However, the operator has a major limitation in the context of geospatial data science: it evaluates all intermediate results as soon as the data is inserted in the pipe. This is known in computer science as eager evaluation.\nTaking the expression above as an example, the operator will first evaluate f1(x) and store the result in a variable y. After f1 is completed, the operator evaluates f2(y) and produces the final (desired) result. If y requires a lot of computer memory as it is usually the case with large geotables, the application of the pipeline will be slow.\nAnother evaluation strategy, known as lazy evaluation, consists of building the entire pipeline without the data in it. The major advantage of this strategy is that it can analyze the functions, and potentially simplify the code before evaluation. For example, the pipeline cos → acos can be replaced by the much simpler pipeline identity for some values of the input x.",
    "crumbs": [
      "Part II: Transforms",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Building pipelines</span>"
    ]
  },
  {
    "objectID": "07-pipelines.html#operator",
    "href": "07-pipelines.html#operator",
    "title": "7  Building pipelines",
    "section": "7.2 Operator →",
    "text": "7.2 Operator →\nIn our framework, the operator → (\\to) can be used in place of the pipe operator to build lazy sequential pipelines of transforms. Consider the synthetic data from previous chapters:\n\nN = 10000\na = [2randn(N÷2) .+ 6; randn(N÷2)]\nb = [3randn(N÷2); 2randn(N÷2)]\nc = randn(N)\nd = c .+ 0.6randn(N)\n\ntable = (; a, b, c, d)\n\ngtb = georef(table, CartesianGrid(100, 100))\n\n\n10000×5 GeoTable over 100×100 CartesianGrid\n\n\na\nb\nc\nd\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n3.57728\n1.49707\n-0.604643\n-0.0807463\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\n4.93356\n-4.33672\n-1.18603\n-1.69285\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\n6.10929\n1.45729\n2.40183\n2.38922\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 1.0 m))\n\n\n9.90976\n-1.45903\n1.59394\n1.69104\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 1.0 m))\n\n\n9.61208\n-0.698047\n0.0432304\n0.607825\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 1.0 m))\n\n\n3.02813\n1.32257\n2.46016\n2.92883\nQuadrangle((x: 5.0 m, y: 0.0 m), ..., (x: 5.0 m, y: 1.0 m))\n\n\n4.65723\n-4.04275\n-0.100213\n-0.9566\nQuadrangle((x: 6.0 m, y: 0.0 m), ..., (x: 6.0 m, y: 1.0 m))\n\n\n8.74681\n0.304121\n-0.416786\n-0.158384\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 1.0 m))\n\n\n5.65619\n4.29829\n-0.315877\n-0.806317\nQuadrangle((x: 8.0 m, y: 0.0 m), ..., (x: 8.0 m, y: 1.0 m))\n\n\n7.78555\n0.529702\n-0.983216\n-1.03447\nQuadrangle((x: 9.0 m, y: 0.0 m), ..., (x: 9.0 m, y: 1.0 m))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nAnd suppose that we are interested in converting the columns “a”, “b” and “c” of the geotable with the Quantile transform. Instead of creating the intermediate geotable with the Select transform, and then sending the result to the Quantile transform, we can create the entire pipeline without reference to the data:\n\npipeline = Select(\"a\", \"b\", \"c\") → Quantile()\n\nSequentialTransform\n├─ Select(selector: [:a, :b, :c], newnames: nothing)\n└─ Quantile(selector: all, dist: Distributions.Normal{Float64}(μ=0.0, σ=1.0))\n\n\nThe operator → creates a special SequentialTransform, which can be applied like any other transform in the framework:\n\ngtb |&gt; pipeline\n\n\n10000×4 GeoTable over 100×100 CartesianGrid\n\n\na\nb\nc\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n0.144127\n0.61948\n-0.587899\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\n0.373737\n-1.68287\n-1.16357\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\n0.713397\n0.599259\n2.39106\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 1.0 m))\n\n\n2.24763\n-0.60949\n1.59729\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 1.0 m))\n\n\n2.11301\n-0.291329\n0.0468911\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 1.0 m))\n\n\n0.0818072\n0.549591\n2.46243\nQuadrangle((x: 5.0 m, y: 0.0 m), ..., (x: 5.0 m, y: 1.0 m))\n\n\n0.314949\n-1.58927\n-0.0880965\nQuadrangle((x: 6.0 m, y: 0.0 m), ..., (x: 6.0 m, y: 1.0 m))\n\n\n1.75301\n0.127683\n-0.395329\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 1.0 m))\n\n\n0.574839\n1.67466\n-0.302593\nQuadrangle((x: 8.0 m, y: 0.0 m), ..., (x: 8.0 m, y: 1.0 m))\n\n\n1.35694\n0.226259\n-0.95298\nQuadrangle((x: 9.0 m, y: 0.0 m), ..., (x: 9.0 m, y: 1.0 m))\n\n\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nIt will perform optimizations whenever possible. For instance, we know a priori that adding the Identity transform anywhere in the pipeline doesn’t have any effect:\n\npipeline → Identity()\n\nSequentialTransform\n├─ Select(selector: [:a, :b, :c], newnames: nothing)\n└─ Quantile(selector: all, dist: Distributions.Normal{Float64}(μ=0.0, σ=1.0))",
    "crumbs": [
      "Part II: Transforms",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Building pipelines</span>"
    ]
  },
  {
    "objectID": "07-pipelines.html#operator-1",
    "href": "07-pipelines.html#operator-1",
    "title": "7  Building pipelines",
    "section": "7.3 Operator ⊔",
    "text": "7.3 Operator ⊔\nThe operator ⊔ (\\sqcup) can be used to create lazy parallel transforms. There is no equivalent in Julia as this operator is very specific to tables. It combines the geotables produced by two or more pipelines into a single geotable with the disjoint union of all columns.\nLet’s illustrate this concept with two pipelines:\n\npipeline1 = Select(\"a\") → Indicator(\"a\", k=3)\n\nSequentialTransform\n├─ Select(selector: [:a], newnames: nothing)\n└─ Indicator(selector: :a, k: 3, scale: :quantile, categ: false)\n\n\n\npipeline2 = Select(\"b\", \"c\", \"d\") → PCA(maxdim=2)\n\nSequentialTransform\n├─ Select(selector: [:b, :c, :d], newnames: nothing)\n├─ ZScore(selector: all)\n└─ EigenAnalysis(proj: :V, maxdim: 2, pratio: 1.0)\n\n\nThe first pipeline creates 3 indicator variables from variable “a”:\n\ngtb |&gt; pipeline1\n\n\n10000×4 GeoTable over 100×100 CartesianGrid\n\n\na_1\na_2\na_3\ngeometry\n\n\nCategorical\nCategorical\nCategorical\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\nfalse\ntrue\ntrue\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\nfalse\ntrue\ntrue\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\nfalse\nfalse\ntrue\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 1.0 m))\n\n\nfalse\nfalse\ntrue\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 1.0 m))\n\n\nfalse\nfalse\ntrue\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 1.0 m))\n\n\nfalse\ntrue\ntrue\nQuadrangle((x: 5.0 m, y: 0.0 m), ..., (x: 5.0 m, y: 1.0 m))\n\n\nfalse\ntrue\ntrue\nQuadrangle((x: 6.0 m, y: 0.0 m), ..., (x: 6.0 m, y: 1.0 m))\n\n\nfalse\nfalse\ntrue\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 1.0 m))\n\n\nfalse\nfalse\ntrue\nQuadrangle((x: 8.0 m, y: 0.0 m), ..., (x: 8.0 m, y: 1.0 m))\n\n\nfalse\nfalse\ntrue\nQuadrangle((x: 9.0 m, y: 0.0 m), ..., (x: 9.0 m, y: 1.0 m))\n\n\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nThe second pipeline runs principal component analysis with variables “b”, “c” and “d” and produces 2 principal components:\n\ngtb |&gt; pipeline2\n\n\n10000×3 GeoTable over 100×100 CartesianGrid\n\n\nPC1\nPC2\ngeometry\n\n\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n-0.462429\n0.585356\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\n-1.84033\n-1.69827\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\n3.14675\n0.575166\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 1.0 m))\n\n\n2.15839\n-0.565761\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 1.0 m))\n\n\n0.41134\n-0.270647\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 1.0 m))\n\n\n3.51355\n0.524095\nQuadrangle((x: 5.0 m, y: 0.0 m), ..., (x: 5.0 m, y: 1.0 m))\n\n\n-0.631099\n-1.58194\nQuadrangle((x: 6.0 m, y: 0.0 m), ..., (x: 6.0 m, y: 1.0 m))\n\n\n-0.375954\n0.118924\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 1.0 m))\n\n\n-0.698901\n1.67743\nQuadrangle((x: 8.0 m, y: 0.0 m), ..., (x: 8.0 m, y: 1.0 m))\n\n\n-1.30394\n0.20483\nQuadrangle((x: 9.0 m, y: 0.0 m), ..., (x: 9.0 m, y: 1.0 m))\n\n\n⋮\n⋮\n⋮\n\n\n\n\n\nWe can combine the two pipelines into a single pipeline that executes in parallel:\n\npipeline = pipeline1 ⊔ pipeline2\n\nParallelTableTransform\n├─ SequentialTransform\n│  ├─ Select(selector: [:a], newnames: nothing)\n│  └─ Indicator(selector: :a, k: 3, scale: :quantile, categ: false)\n└─ SequentialTransform\n   ├─ Select(selector: [:b, :c, :d], newnames: nothing)\n   ├─ ZScore(selector: all)\n   └─ EigenAnalysis(proj: :V, maxdim: 2, pratio: 1.0)\n\n\n\ngtb |&gt; pipeline\n\n\n10000×6 GeoTable over 100×100 CartesianGrid\n\n\na_1\na_2\na_3\nPC1\nPC2\ngeometry\n\n\nCategorical\nCategorical\nCategorical\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\nfalse\ntrue\ntrue\n-0.462429\n0.585356\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\nfalse\ntrue\ntrue\n-1.84033\n-1.69827\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\nfalse\nfalse\ntrue\n3.14675\n0.575166\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 1.0 m))\n\n\nfalse\nfalse\ntrue\n2.15839\n-0.565761\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 1.0 m))\n\n\nfalse\nfalse\ntrue\n0.41134\n-0.270647\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 1.0 m))\n\n\nfalse\ntrue\ntrue\n3.51355\n0.524095\nQuadrangle((x: 5.0 m, y: 0.0 m), ..., (x: 5.0 m, y: 1.0 m))\n\n\nfalse\ntrue\ntrue\n-0.631099\n-1.58194\nQuadrangle((x: 6.0 m, y: 0.0 m), ..., (x: 6.0 m, y: 1.0 m))\n\n\nfalse\nfalse\ntrue\n-0.375954\n0.118924\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 1.0 m))\n\n\nfalse\nfalse\ntrue\n-0.698901\n1.67743\nQuadrangle((x: 8.0 m, y: 0.0 m), ..., (x: 8.0 m, y: 1.0 m))\n\n\nfalse\nfalse\ntrue\n-1.30394\n0.20483\nQuadrangle((x: 9.0 m, y: 0.0 m), ..., (x: 9.0 m, y: 1.0 m))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nAll 5 columns are present in the final geotable.",
    "crumbs": [
      "Part II: Transforms",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Building pipelines</span>"
    ]
  },
  {
    "objectID": "07-pipelines.html#revertibility",
    "href": "07-pipelines.html#revertibility",
    "title": "7  Building pipelines",
    "section": "7.4 Revertibility",
    "text": "7.4 Revertibility\nAn important concept related to pipelines that is very useful in geospatial data science is revertibility. The concept is useful whenever we need to answer geoscientific questions in terms of variables that have been transformed for geostatistical analysis.\nLet’s illustrate the concept with the following geotable and pipeline:\n\na = [-1.0, 4.0, 1.6, 3.4]\nb = [1.6, 3.4, -1.0, 4.0]\nc = [3.4, 2.0, 3.6, -1.0]\ntable = (; a, b, c)\n\ngtb = georef(table, [(0, 0), (1, 0), (1, 1), (0, 1)])\n\n\n4×4 GeoTable over 4 PointSet\n\n\na\nb\nc\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nPoint\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n-1.0\n1.6\n3.4\n(x: 0.0 m, y: 0.0 m)\n\n\n4.0\n3.4\n2.0\n(x: 1.0 m, y: 0.0 m)\n\n\n1.6\n-1.0\n3.6\n(x: 1.0 m, y: 1.0 m)\n\n\n3.4\n4.0\n-1.0\n(x: 0.0 m, y: 1.0 m)\n\n\n\n\n\n\npipeline = Center()\n\nCenter transform\n└─ selector: all\n\n\nWe saw that our pipelines can be evaluated with Julia’s pipe operator:\n\ngtb |&gt; pipeline\n\n\n4×4 GeoTable over 4 PointSet\n\n\na\nb\nc\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nPoint\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n-3.0\n-0.4\n1.4\n(x: 0.0 m, y: 0.0 m)\n\n\n2.0\n1.4\n0.0\n(x: 1.0 m, y: 0.0 m)\n\n\n-0.4\n-3.0\n1.6\n(x: 1.0 m, y: 1.0 m)\n\n\n1.4\n2.0\n-3.0\n(x: 0.0 m, y: 1.0 m)\n\n\n\n\n\nIn order to revert a pipeline, however; we need to save auxiliary constants that were used to transform the data (e.g., mean of selected columns). The apply function serves this purpose:\n\nnewgtb, cache = apply(pipeline, gtb)\n\nnewgtb\n\n\n4×4 GeoTable over 4 PointSet\n\n\na\nb\nc\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nPoint\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n-3.0\n-0.4\n1.4\n(x: 0.0 m, y: 0.0 m)\n\n\n2.0\n1.4\n0.0\n(x: 1.0 m, y: 0.0 m)\n\n\n-0.4\n-3.0\n1.6\n(x: 1.0 m, y: 1.0 m)\n\n\n1.4\n2.0\n-3.0\n(x: 0.0 m, y: 1.0 m)\n\n\n\n\n\nThe function produces the new geotable as usual and an additional cache with all the information needed to revert the transforms in the pipeline. We say that a pipeline isrevertible, if there is an efficient way to revert its transforms starting from any geotable that has the same schema of the geotable produced by the apply function:\n\nisrevertible(pipeline)\n\ntrue\n\n\n\nrevert(pipeline, newgtb, cache)\n\n\n4×4 GeoTable over 4 PointSet\n\n\na\nb\nc\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nPoint\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n-1.0\n1.6\n3.4\n(x: 0.0 m, y: 0.0 m)\n\n\n4.0\n3.4\n2.0\n(x: 1.0 m, y: 0.0 m)\n\n\n1.6\n-1.0\n3.6\n(x: 1.0 m, y: 1.0 m)\n\n\n3.4\n4.0\n-1.0\n(x: 0.0 m, y: 1.0 m)\n\n\n\n\n\nA very common workflow in geospatial data science consists of:\n\nTransforming the data to an appropriate sample space for geostatistical analysis\nDoing additional modeling to predict variables in new geospatial locations\nReverting the modeling results with the saved pipeline and cache\n\nWe will see examples of this workflow in Part V of the book.",
    "crumbs": [
      "Part II: Transforms",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Building pipelines</span>"
    ]
  },
  {
    "objectID": "07-pipelines.html#congratulations",
    "href": "07-pipelines.html#congratulations",
    "title": "7  Building pipelines",
    "section": "7.5 Congratulations!",
    "text": "7.5 Congratulations!\nCongratulations on finishing Part II of the book. Let’s quickly review what we learned so far:\n\nTransforms and pipelines are powerful tools to achieve reproducible geospatial data science.\nThe operators → and ⊔ can be used to build lazy pipelines. After a pipeline is built, it can be applied to different geotables, which may have different types of geospatial domain.\nLazy pipelines can always be optimized for computational performance, and the Julia language really thrives to dispatch the appropriate optimizations when they are available.\nMap projections are specific types of coordinate transforms. They can be combined with many other transforms in the framework to produce advanced geostatistical visualizations.\n\nThere is a long journey until the technology reaches its full potential. The good news is that Julia code is easy to read and modify, and you can become an active contributor after just a few weeks working with the language. We invite you to contribute new transforms and optimizations as soon as you feel comfortable with the framework.",
    "crumbs": [
      "Part II: Transforms",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Building pipelines</span>"
    ]
  },
  {
    "objectID": "08-splitcombine.html",
    "href": "08-splitcombine.html",
    "title": "8  Split-apply-combine",
    "section": "",
    "text": "8.1 Motivation\nIn Part II of the book, we introduced transform pipelines to process the values and the domain of geotables using high-level abstractions that preserve geospatial information. In this chapter, we start to introduce other tools to query geotables after they have been pre-processed by pipelines.\nIn geospatial data science, geoscientific questions are often posed in terms of both the values and the domain of a geotable. For example:\nThe word “where” is often present in these questions to indicate that answers must be georeferenced. If the variable of interest is already present in the geotable, then we can effectively answer “where” questions using the viewer and the Filter transform from previous chapters:\nIf the variable of interest is not present in the geotable, or if the “where” word is not present in the original question, then there will be some reference to “geospatial units” on which geostatistics must be computed. These questions can be answered with a geospatial version of the split-apply-combine strategy (Wickham 2011) from data science. Our framework provides the @groupby, @transform and @combine macros to split-apply-combine geotables.",
    "crumbs": [
      "Part III: Queries",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Split-apply-combine</span>"
    ]
  },
  {
    "objectID": "08-splitcombine.html#motivation",
    "href": "08-splitcombine.html#motivation",
    "title": "8  Split-apply-combine",
    "section": "",
    "text": "Where are the areas with high probability of landslide?\nWhat is the average rainfall per watershed over the last year?\nHow much lithium will be mined from each geological unit?\nWhat is the variation of log-permeability per depositional facies?\n\n\ngeotable |&gt; Filter(row -&gt; row.probability &gt; 0.9) |&gt; viewer",
    "crumbs": [
      "Part III: Queries",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Split-apply-combine</span>"
    ]
  },
  {
    "objectID": "08-splitcombine.html#bonnie-data-set",
    "href": "08-splitcombine.html#bonnie-data-set",
    "title": "8  Split-apply-combine",
    "section": "8.2 Bonnie data set",
    "text": "8.2 Bonnie data set\nWe will use the Bonnie data set to illustrate our geospatial split-apply-combine:\n\nThe Bonnie Project Example is under copyright of Transmin Metallurgical Consultants, 2019. It is issued under the Creative Commons Attribution-ShareAlike 4.0 International Public License.\n\n\nusing GeoIO\n\ngtb = GeoIO.load(\"data/bonnie.csv\", coords = (\"EAST\", \"NORTH\", \"RL\"))\n\n\n19618×9 GeoTable over 19618 PointSet\n\n\nAuppm\nAgppm\nCuppm\nAsppm\nSper\nCODE\nOX\nISBD\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nCategorical\nCategorical\nContinuous\nPoint\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n0.407\n2.335\n1311.0\n27.0\n0.01\nC1\nTR1\n2.42\n(x: 243940.0 m, y: 1.00223e6 m, z: 1855.0 m)\n\n\n0.407\n2.335\n1311.0\n27.0\n0.01\nC1\nTR1\n1.98\n(x: 243945.0 m, y: 1.00223e6 m, z: 1855.0 m)\n\n\n0.407\n2.335\n1311.0\n27.0\n0.01\nC1\nTR1\n2.068\n(x: 243950.0 m, y: 1.00226e6 m, z: 1855.0 m)\n\n\n0.385\n2.1\n572.0\n0.0\n0.0\nC1\nTR1\n2.222\n(x: 243965.0 m, y: 1.00226e6 m, z: 1855.0 m)\n\n\n0.385\n2.1\n572.0\n0.0\n0.0\nC1\nTR1\n2.156\n(x: 243970.0 m, y: 1.00226e6 m, z: 1855.0 m)\n\n\n0.385\n2.1\n572.0\n0.0\n0.0\nC1\nOX1\n2.08\n(x: 243960.0 m, y: 1.00227e6 m, z: 1855.0 m)\n\n\n0.385\n2.1\n572.0\n0.0\n0.0\nC1\nOX1\n2.06\n(x: 243965.0 m, y: 1.00227e6 m, z: 1855.0 m)\n\n\n0.385\n2.1\n572.0\n0.0\n0.0\nC1\nOX1\n1.9\n(x: 243970.0 m, y: 1.00227e6 m, z: 1855.0 m)\n\n\n0.42152\n1.422\n852.36\n22.85\n2.4078\nC1\nTR1\n2.024\n(x: 243930.0 m, y: 1.00222e6 m, z: 1860.0 m)\n\n\n0.41747\n1.429\n832.36\n21.87\n1.9388\nC1\nTR1\n2.112\n(x: 243935.0 m, y: 1.00222e6 m, z: 1860.0 m)\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nIt represents a 3D mineral deposit with grades in parts per million (ppm), sulfur contaminant in percent, and other categorical variables with geological and lithological units:\n\nnames(gtb)\n\n9-element Vector{String}:\n \"Auppm\"\n \"Agppm\"\n \"Cuppm\"\n \"Asppm\"\n \"Sper\"\n \"CODE\"\n \"OX\"\n \"ISBD\"\n \"geometry\"\n\n\nThe “EAST”, “NORTH” and “RL” coordinates used to georef the CSV file represent the centroids of the mining blocks. The sides of these blocks are provided as metadata (e.g., 5x5x5):\n\ngtb |&gt; viewer\n\n\n\n\nLet’s clean the geotable using what we learned in previous chapters. We will reject the column with sulfur, will rename the variables for greater readability, and will drop missing values. We will also add units to some of the variables using bracket notation:\n\nclean = Reject(\"Sper\") →\n        Rename(\"Agppm\" =&gt; \"Ag [ppm]\",\n               \"Auppm\" =&gt; \"Au [ppm]\",\n               \"Asppm\" =&gt; \"As [ppm]\",\n               \"Cuppm\" =&gt; \"Cu [ppm]\",\n               \"ISBD\" =&gt; \"ρ [Mg/m^3]\",\n               \"CODE\" =&gt; \"geo\",\n               \"OX\" =&gt; \"litho\") →\n        DropMissing() →\n        Unitify()\n\ngtb = gtb |&gt; clean\n\n\n19548×8 GeoTable over 19548 view(::PointSet, [1, 2, 3, 4, ..., 19615, 19616, 19617, 19618])\n\n\nAu\nAg\nCu\nAs\ngeo\nlitho\nρ\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nCategorical\nCategorical\nContinuous\nPoint\n\n\n[ppm]\n[ppm]\n[ppm]\n[ppm]\n[NoUnits]\n[NoUnits]\n[Mg m^-3]\n🖈 Cartesian{NoDatum}\n\n\n\n\n0.407 ppm\n2.335 ppm\n1311.0 ppm\n27.0 ppm\nC1\nTR1\n2.42 Mg m^-3\n(x: 243940.0 m, y: 1.00223e6 m, z: 1855.0 m)\n\n\n0.407 ppm\n2.335 ppm\n1311.0 ppm\n27.0 ppm\nC1\nTR1\n1.98 Mg m^-3\n(x: 243945.0 m, y: 1.00223e6 m, z: 1855.0 m)\n\n\n0.407 ppm\n2.335 ppm\n1311.0 ppm\n27.0 ppm\nC1\nTR1\n2.068 Mg m^-3\n(x: 243950.0 m, y: 1.00226e6 m, z: 1855.0 m)\n\n\n0.385 ppm\n2.1 ppm\n572.0 ppm\n0.0 ppm\nC1\nTR1\n2.222 Mg m^-3\n(x: 243965.0 m, y: 1.00226e6 m, z: 1855.0 m)\n\n\n0.385 ppm\n2.1 ppm\n572.0 ppm\n0.0 ppm\nC1\nTR1\n2.156 Mg m^-3\n(x: 243970.0 m, y: 1.00226e6 m, z: 1855.0 m)\n\n\n0.385 ppm\n2.1 ppm\n572.0 ppm\n0.0 ppm\nC1\nOX1\n2.08 Mg m^-3\n(x: 243960.0 m, y: 1.00227e6 m, z: 1855.0 m)\n\n\n0.385 ppm\n2.1 ppm\n572.0 ppm\n0.0 ppm\nC1\nOX1\n2.06 Mg m^-3\n(x: 243965.0 m, y: 1.00227e6 m, z: 1855.0 m)\n\n\n0.385 ppm\n2.1 ppm\n572.0 ppm\n0.0 ppm\nC1\nOX1\n1.9 Mg m^-3\n(x: 243970.0 m, y: 1.00227e6 m, z: 1855.0 m)\n\n\n0.42152 ppm\n1.422 ppm\n852.36 ppm\n22.85 ppm\nC1\nTR1\n2.024 Mg m^-3\n(x: 243930.0 m, y: 1.00222e6 m, z: 1860.0 m)\n\n\n0.41747 ppm\n1.429 ppm\n832.36 ppm\n21.87 ppm\nC1\nTR1\n2.112 Mg m^-3\n(x: 243935.0 m, y: 1.00222e6 m, z: 1860.0 m)\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe Unitify transform recognizes unit bracket notation in column names. It adds the units specified within brackets to the values of the columns, and removes the brackets from the column names.\n\n\nThat is a lot better! Let’s assume that we want to answer the following business question:\nWhat is the total mass of gold that will be mined from each geological unit?",
    "crumbs": [
      "Part III: Queries",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Split-apply-combine</span>"
    ]
  },
  {
    "objectID": "08-splitcombine.html#splitting-geotables",
    "href": "08-splitcombine.html#splitting-geotables",
    "title": "8  Split-apply-combine",
    "section": "8.3 Splitting geotables",
    "text": "8.3 Splitting geotables\nWe can split geotables into lazy geospatial partitions based on values stored in a column. In this case, we want to split the mineral deposit in geological units stored in the geo column:\n\ngroups = @groupby(gtb, \"geo\")\n\n2 Partition\n├─ 17153×8 SubGeoTable over 17153 view(::PointSet, [1, 2, 3, 4, ..., 17203, 17204, 17205, 17206])\n└─ 2395×8 SubGeoTable over 2395 view(::PointSet, [17207, 17208, 17209, 17210, ..., 19615, 19616, 19617, 19618])\nmetadata: rows, names\n\n\nThere are two geological units in this deposit, represented as SubGeoTable. We can access these units by indexing into the geospatial partition:\n\ngroups[1]\n\n\n17153×8 SubGeoTable over 17153 view(::PointSet, [1, 2, 3, 4, ..., 17203, 17204, 17205, 17206])\n\n\nAu\nAg\nCu\nAs\ngeo\nlitho\nρ\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nCategorical\nCategorical\nContinuous\nPoint\n\n\n[ppm]\n[ppm]\n[ppm]\n[ppm]\n[NoUnits]\n[NoUnits]\n[Mg m^-3]\n🖈 Cartesian{NoDatum}\n\n\n\n\n0.407 ppm\n2.335 ppm\n1311.0 ppm\n27.0 ppm\nC1\nTR1\n2.42 Mg m^-3\n(x: 243940.0 m, y: 1.00223e6 m, z: 1855.0 m)\n\n\n0.407 ppm\n2.335 ppm\n1311.0 ppm\n27.0 ppm\nC1\nTR1\n1.98 Mg m^-3\n(x: 243945.0 m, y: 1.00223e6 m, z: 1855.0 m)\n\n\n0.407 ppm\n2.335 ppm\n1311.0 ppm\n27.0 ppm\nC1\nTR1\n2.068 Mg m^-3\n(x: 243950.0 m, y: 1.00226e6 m, z: 1855.0 m)\n\n\n0.385 ppm\n2.1 ppm\n572.0 ppm\n0.0 ppm\nC1\nTR1\n2.222 Mg m^-3\n(x: 243965.0 m, y: 1.00226e6 m, z: 1855.0 m)\n\n\n0.385 ppm\n2.1 ppm\n572.0 ppm\n0.0 ppm\nC1\nTR1\n2.156 Mg m^-3\n(x: 243970.0 m, y: 1.00226e6 m, z: 1855.0 m)\n\n\n0.385 ppm\n2.1 ppm\n572.0 ppm\n0.0 ppm\nC1\nOX1\n2.08 Mg m^-3\n(x: 243960.0 m, y: 1.00227e6 m, z: 1855.0 m)\n\n\n0.385 ppm\n2.1 ppm\n572.0 ppm\n0.0 ppm\nC1\nOX1\n2.06 Mg m^-3\n(x: 243965.0 m, y: 1.00227e6 m, z: 1855.0 m)\n\n\n0.385 ppm\n2.1 ppm\n572.0 ppm\n0.0 ppm\nC1\nOX1\n1.9 Mg m^-3\n(x: 243970.0 m, y: 1.00227e6 m, z: 1855.0 m)\n\n\n0.42152 ppm\n1.422 ppm\n852.36 ppm\n22.85 ppm\nC1\nTR1\n2.024 Mg m^-3\n(x: 243930.0 m, y: 1.00222e6 m, z: 1860.0 m)\n\n\n0.41747 ppm\n1.429 ppm\n832.36 ppm\n21.87 ppm\nC1\nTR1\n2.112 Mg m^-3\n(x: 243935.0 m, y: 1.00222e6 m, z: 1860.0 m)\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\n\nviz(groups[1].geometry, color = \"teal\")\nviz!(groups[2].geometry, color = \"slategray3\")\nMke.current_figure()",
    "crumbs": [
      "Part III: Queries",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Split-apply-combine</span>"
    ]
  },
  {
    "objectID": "08-splitcombine.html#applying-expressions",
    "href": "08-splitcombine.html#applying-expressions",
    "title": "8  Split-apply-combine",
    "section": "8.4 Applying expressions",
    "text": "8.4 Applying expressions\nThe mass of gold in a mining block is a function of the gold grade (Au), the rock density (ρ), and the volume of the block:\n\\[\nm = Au \\times \\rho \\times V\n\\]\nLet’s use an auxiliary function to convert the Points in the geometry column into Boxes of sides 5x5x5. The function takes a centroid point as input and produces a box centered at the point with corners that are 2.5x2.5x2.5 units away in both directions:\n\nbox(point) = Box(point - Vec(2.5, 2.5, 2.5), point + Vec(2.5, 2.5, 2.5))\n\nbox (generic function with 1 method)\n\n\n\nbox.(gtb.geometry)\n\n19548-element Vector{Box{𝔼{3}, Cartesian3D{NoDatum, Quantity{Float64, 𝐋, Unitful.FreeUnits{(m,), 𝐋, nothing}}}}}:\n Box(min: (x: 2.43938e5 m, y: 1.00223e6 m, z: 1852.5 m), max: (x: 2.43942e5 m, y: 1.00223e6 m, z: 1857.5 m))\n Box(min: (x: 2.43942e5 m, y: 1.00223e6 m, z: 1852.5 m), max: (x: 2.43948e5 m, y: 1.00223e6 m, z: 1857.5 m))\n Box(min: (x: 2.43948e5 m, y: 1.00226e6 m, z: 1852.5 m), max: (x: 2.43952e5 m, y: 1.00226e6 m, z: 1857.5 m))\n Box(min: (x: 2.43962e5 m, y: 1.00226e6 m, z: 1852.5 m), max: (x: 2.43968e5 m, y: 1.00226e6 m, z: 1857.5 m))\n Box(min: (x: 2.43968e5 m, y: 1.00226e6 m, z: 1852.5 m), max: (x: 2.43972e5 m, y: 1.00226e6 m, z: 1857.5 m))\n Box(min: (x: 2.43958e5 m, y: 1.00227e6 m, z: 1852.5 m), max: (x: 2.43962e5 m, y: 1.00227e6 m, z: 1857.5 m))\n Box(min: (x: 2.43962e5 m, y: 1.00227e6 m, z: 1852.5 m), max: (x: 2.43968e5 m, y: 1.00227e6 m, z: 1857.5 m))\n Box(min: (x: 2.43968e5 m, y: 1.00227e6 m, z: 1852.5 m), max: (x: 2.43972e5 m, y: 1.00227e6 m, z: 1857.5 m))\n Box(min: (x: 2.43928e5 m, y: 1.00222e6 m, z: 1857.5 m), max: (x: 2.43932e5 m, y: 1.00222e6 m, z: 1862.5 m))\n Box(min: (x: 2.43932e5 m, y: 1.00222e6 m, z: 1857.5 m), max: (x: 2.43938e5 m, y: 1.00222e6 m, z: 1862.5 m))\n ⋮\n Box(min: (x: 2.43752e5 m, y: 1.00221e6 m, z: 2027.5 m), max: (x: 2.43758e5 m, y: 1.00221e6 m, z: 2032.5 m))\n Box(min: (x: 2.43758e5 m, y: 1.00221e6 m, z: 2027.5 m), max: (x: 2.43762e5 m, y: 1.00221e6 m, z: 2032.5 m))\n Box(min: (x: 2.43762e5 m, y: 1.00221e6 m, z: 2027.5 m), max: (x: 2.43768e5 m, y: 1.00221e6 m, z: 2032.5 m))\n Box(min: (x: 2.43768e5 m, y: 1.00221e6 m, z: 2027.5 m), max: (x: 2.43772e5 m, y: 1.00221e6 m, z: 2032.5 m))\n Box(min: (x: 2.43772e5 m, y: 1.00221e6 m, z: 2027.5 m), max: (x: 2.43778e5 m, y: 1.00221e6 m, z: 2032.5 m))\n Box(min: (x: 2.43778e5 m, y: 1.00221e6 m, z: 2027.5 m), max: (x: 2.43782e5 m, y: 1.00221e6 m, z: 2032.5 m))\n Box(min: (x: 2.43782e5 m, y: 1.00221e6 m, z: 2027.5 m), max: (x: 2.43788e5 m, y: 1.00221e6 m, z: 2032.5 m))\n Box(min: (x: 2.43788e5 m, y: 1.00221e6 m, z: 2027.5 m), max: (x: 2.43792e5 m, y: 1.00221e6 m, z: 2032.5 m))\n Box(min: (x: 2.43792e5 m, y: 1.00221e6 m, z: 2027.5 m), max: (x: 2.43798e5 m, y: 1.00221e6 m, z: 2032.5 m))\n\n\nThe @transform macro modifies or creates new columns in the geotable based on expressions with existing column names. In this case, we want to replace the geometry column by calling the auxiliary function above:\n\ngtb = @transform(gtb, :geometry = box(:geometry))\n\n\n19548×8 GeoTable over 19548 GeometrySet\n\n\nAu\nAg\nCu\nAs\ngeo\nlitho\nρ\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nCategorical\nCategorical\nContinuous\nBox\n\n\n[ppm]\n[ppm]\n[ppm]\n[ppm]\n[NoUnits]\n[NoUnits]\n[Mg m^-3]\n🖈 Cartesian{NoDatum}\n\n\n\n\n0.407 ppm\n2.335 ppm\n1311.0 ppm\n27.0 ppm\nC1\nTR1\n2.42 Mg m^-3\nBox(min: (x: 2.43938e5 m, y: 1.00223e6 m, z: 1852.5 m), max: (x: 2.43942e5 m, y: 1.00223e6 m, z: 1857.5 m))\n\n\n0.407 ppm\n2.335 ppm\n1311.0 ppm\n27.0 ppm\nC1\nTR1\n1.98 Mg m^-3\nBox(min: (x: 2.43942e5 m, y: 1.00223e6 m, z: 1852.5 m), max: (x: 2.43948e5 m, y: 1.00223e6 m, z: 1857.5 m))\n\n\n0.407 ppm\n2.335 ppm\n1311.0 ppm\n27.0 ppm\nC1\nTR1\n2.068 Mg m^-3\nBox(min: (x: 2.43948e5 m, y: 1.00226e6 m, z: 1852.5 m), max: (x: 2.43952e5 m, y: 1.00226e6 m, z: 1857.5 m))\n\n\n0.385 ppm\n2.1 ppm\n572.0 ppm\n0.0 ppm\nC1\nTR1\n2.222 Mg m^-3\nBox(min: (x: 2.43962e5 m, y: 1.00226e6 m, z: 1852.5 m), max: (x: 2.43968e5 m, y: 1.00226e6 m, z: 1857.5 m))\n\n\n0.385 ppm\n2.1 ppm\n572.0 ppm\n0.0 ppm\nC1\nTR1\n2.156 Mg m^-3\nBox(min: (x: 2.43968e5 m, y: 1.00226e6 m, z: 1852.5 m), max: (x: 2.43972e5 m, y: 1.00226e6 m, z: 1857.5 m))\n\n\n0.385 ppm\n2.1 ppm\n572.0 ppm\n0.0 ppm\nC1\nOX1\n2.08 Mg m^-3\nBox(min: (x: 2.43958e5 m, y: 1.00227e6 m, z: 1852.5 m), max: (x: 2.43962e5 m, y: 1.00227e6 m, z: 1857.5 m))\n\n\n0.385 ppm\n2.1 ppm\n572.0 ppm\n0.0 ppm\nC1\nOX1\n2.06 Mg m^-3\nBox(min: (x: 2.43962e5 m, y: 1.00227e6 m, z: 1852.5 m), max: (x: 2.43968e5 m, y: 1.00227e6 m, z: 1857.5 m))\n\n\n0.385 ppm\n2.1 ppm\n572.0 ppm\n0.0 ppm\nC1\nOX1\n1.9 Mg m^-3\nBox(min: (x: 2.43968e5 m, y: 1.00227e6 m, z: 1852.5 m), max: (x: 2.43972e5 m, y: 1.00227e6 m, z: 1857.5 m))\n\n\n0.42152 ppm\n1.422 ppm\n852.36 ppm\n22.85 ppm\nC1\nTR1\n2.024 Mg m^-3\nBox(min: (x: 2.43928e5 m, y: 1.00222e6 m, z: 1857.5 m), max: (x: 2.43932e5 m, y: 1.00222e6 m, z: 1862.5 m))\n\n\n0.41747 ppm\n1.429 ppm\n832.36 ppm\n21.87 ppm\nC1\nTR1\n2.112 Mg m^-3\nBox(min: (x: 2.43932e5 m, y: 1.00222e6 m, z: 1857.5 m), max: (x: 2.43938e5 m, y: 1.00222e6 m, z: 1862.5 m))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nThe macro will broadcast the expression to all rows of the geotable.\n\n\n\n\n\n\nNote\n\n\n\nWe used the :geometry symbol to refer to the geometry column instead of the usual \"geometry\" string. The @transform macro understands that strings can also appear as valid values in the right-hand-side of the expression, which are not columns in the geotable. To mark a string as a column name, we need to use curly braces:\n@transform(gtb, {\"geometry\"} = box({\"geometry\"}))\n\n\n\n\n\n\n\n\nTip for all users\n\n\n\nThe use of symbols to represent column names is preferred in macros.\n\n\nThe mass of gold on each mining block can be computed now that the geometries have volume:\n\n@transform(gtb, :m = :Au * :ρ * volume(:geometry))\n\n\n19548×9 GeoTable over 19548 GeometrySet\n\n\nAu\nAg\nCu\nAs\ngeo\nlitho\nρ\nm\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nCategorical\nCategorical\nContinuous\nContinuous\nBox\n\n\n[ppm]\n[ppm]\n[ppm]\n[ppm]\n[NoUnits]\n[NoUnits]\n[Mg m^-3]\n[Mg ppm]\n🖈 Cartesian{NoDatum}\n\n\n\n\n0.407 ppm\n2.335 ppm\n1311.0 ppm\n27.0 ppm\nC1\nTR1\n2.42 Mg m^-3\n123.117 Mg ppm\nBox(min: (x: 2.43938e5 m, y: 1.00223e6 m, z: 1852.5 m), max: (x: 2.43942e5 m, y: 1.00223e6 m, z: 1857.5 m))\n\n\n0.407 ppm\n2.335 ppm\n1311.0 ppm\n27.0 ppm\nC1\nTR1\n1.98 Mg m^-3\n100.732 Mg ppm\nBox(min: (x: 2.43942e5 m, y: 1.00223e6 m, z: 1852.5 m), max: (x: 2.43948e5 m, y: 1.00223e6 m, z: 1857.5 m))\n\n\n0.407 ppm\n2.335 ppm\n1311.0 ppm\n27.0 ppm\nC1\nTR1\n2.068 Mg m^-3\n105.209 Mg ppm\nBox(min: (x: 2.43948e5 m, y: 1.00226e6 m, z: 1852.5 m), max: (x: 2.43952e5 m, y: 1.00226e6 m, z: 1857.5 m))\n\n\n0.385 ppm\n2.1 ppm\n572.0 ppm\n0.0 ppm\nC1\nTR1\n2.222 Mg m^-3\n106.934 Mg ppm\nBox(min: (x: 2.43962e5 m, y: 1.00226e6 m, z: 1852.5 m), max: (x: 2.43968e5 m, y: 1.00226e6 m, z: 1857.5 m))\n\n\n0.385 ppm\n2.1 ppm\n572.0 ppm\n0.0 ppm\nC1\nTR1\n2.156 Mg m^-3\n103.758 Mg ppm\nBox(min: (x: 2.43968e5 m, y: 1.00226e6 m, z: 1852.5 m), max: (x: 2.43972e5 m, y: 1.00226e6 m, z: 1857.5 m))\n\n\n0.385 ppm\n2.1 ppm\n572.0 ppm\n0.0 ppm\nC1\nOX1\n2.08 Mg m^-3\n100.1 Mg ppm\nBox(min: (x: 2.43958e5 m, y: 1.00227e6 m, z: 1852.5 m), max: (x: 2.43962e5 m, y: 1.00227e6 m, z: 1857.5 m))\n\n\n0.385 ppm\n2.1 ppm\n572.0 ppm\n0.0 ppm\nC1\nOX1\n2.06 Mg m^-3\n99.1375 Mg ppm\nBox(min: (x: 2.43962e5 m, y: 1.00227e6 m, z: 1852.5 m), max: (x: 2.43968e5 m, y: 1.00227e6 m, z: 1857.5 m))\n\n\n0.385 ppm\n2.1 ppm\n572.0 ppm\n0.0 ppm\nC1\nOX1\n1.9 Mg m^-3\n91.4375 Mg ppm\nBox(min: (x: 2.43968e5 m, y: 1.00227e6 m, z: 1852.5 m), max: (x: 2.43972e5 m, y: 1.00227e6 m, z: 1857.5 m))\n\n\n0.42152 ppm\n1.422 ppm\n852.36 ppm\n22.85 ppm\nC1\nTR1\n2.024 Mg m^-3\n106.645 Mg ppm\nBox(min: (x: 2.43928e5 m, y: 1.00222e6 m, z: 1857.5 m), max: (x: 2.43932e5 m, y: 1.00222e6 m, z: 1862.5 m))\n\n\n0.41747 ppm\n1.429 ppm\n832.36 ppm\n21.87 ppm\nC1\nTR1\n2.112 Mg m^-3\n110.212 Mg ppm\nBox(min: (x: 2.43932e5 m, y: 1.00222e6 m, z: 1857.5 m), max: (x: 2.43938e5 m, y: 1.00222e6 m, z: 1862.5 m))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe @transform macro can be used with both geotables and geospatial partitions.",
    "crumbs": [
      "Part III: Queries",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Split-apply-combine</span>"
    ]
  },
  {
    "objectID": "08-splitcombine.html#combining-results",
    "href": "08-splitcombine.html#combining-results",
    "title": "8  Split-apply-combine",
    "section": "8.5 Combining results",
    "text": "8.5 Combining results\nWe can use the @combine macro to reduce columns of geotables in a geospatial partition obtained with the @groupby macro. The macro is similar to the @transform macro, but expects valid reduction functions such as sum, mean, std. Reduction functions take a vector of values as input and produce a single scalar as output:\n\ngroups = @groupby(gtb, :geo)\n\n@combine(groups, :μ = mean(:Au), :σ = std(:Au))\n\n\n2×4 GeoTable over 2 GeometrySet\n\n\ngeo\nμ\nσ\ngeometry\n\n\nCategorical\nContinuous\nContinuous\nMulti\n\n\n[NoUnits]\n[ppm]\n[ppm]\n🖈 Cartesian{NoDatum}\n\n\n\n\nC1\n0.581937 ppm\n0.136264 ppm\nMulti(17153×Box)\n\n\nC2\n0.484622 ppm\n0.095799 ppm\nMulti(2395×Box)\n\n\n\n\n\nNote that the macro reduces the geometry column and produces a new complex Multi geometry with all the Boxes that are inside each geological unit. This is a very advanced feature of the framework that cannot be represented with the simple features standard. It is also possible to use a custom reduction function for the geometry column:\n\ngroups = @groupby(gtb, :geo)\n\n@combine(groups, :μ = mean(:Au), :σ = std(:Au), :geometry = first(:geometry))\n\n\n2×4 GeoTable over 2 GeometrySet\n\n\ngeo\nμ\nσ\ngeometry\n\n\nCategorical\nContinuous\nContinuous\nBox\n\n\n[NoUnits]\n[ppm]\n[ppm]\n🖈 Cartesian{NoDatum}\n\n\n\n\nC1\n0.581937 ppm\n0.136264 ppm\nBox(min: (x: 2.43938e5 m, y: 1.00223e6 m, z: 1852.5 m), max: (x: 2.43942e5 m, y: 1.00223e6 m, z: 1857.5 m))\n\n\nC2\n0.484622 ppm\n0.095799 ppm\nBox(min: (x: 2.43792e5 m, y: 1.00214e6 m, z: 1872.5 m), max: (x: 2.43798e5 m, y: 1.00214e6 m, z: 1877.5 m))",
    "crumbs": [
      "Part III: Queries",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Split-apply-combine</span>"
    ]
  },
  {
    "objectID": "08-splitcombine.html#answering-questions",
    "href": "08-splitcombine.html#answering-questions",
    "title": "8  Split-apply-combine",
    "section": "8.6 Answering questions",
    "text": "8.6 Answering questions\nLet’s recall our original business question:\nWhat is the total mass of gold that will be mined from each geological unit?\nWe can now answer this question with three lines of code:\n\ngroups = @groupby(gtb, :geo)\n\nmass = @transform(groups, :m = :Au * :ρ * volume(:geometry))\n\nanswer = @combine(mass, :m = sum(:m))\n\n\n2×3 GeoTable over 2 GeometrySet\n\n\ngeo\nm\ngeometry\n\n\nCategorical\nContinuous\nMulti\n\n\n[NoUnits]\n[Mg ppm]\n🖈 Cartesian{NoDatum}\n\n\n\n\nC1\n2.53302e6 Mg ppm\nMulti(17153×Box)\n\n\nC2\n3.29241e5 Mg ppm\nMulti(2395×Box)\n\n\n\n\n\n\n\n\n\n\n\nTip for all users\n\n\n\nWe can simplify the code further using the @chain macro. It forwards the resulting geotable or geospatial partition to the next macro:\n\n@chain gtb begin\n  @groupby(:geo)\n  @transform(:m = :Au * :ρ * volume(:geometry))\n  @combine(:m = sum(:m))\nend\n\n\n2×3 GeoTable over 2 GeometrySet\n\n\ngeo\nm\ngeometry\n\n\nCategorical\nContinuous\nMulti\n\n\n[NoUnits]\n[Mg ppm]\n🖈 Cartesian{NoDatum}\n\n\n\n\nC1\n2.53302e6 Mg ppm\nMulti(17153×Box)\n\n\nC2\n3.29241e5 Mg ppm\nMulti(2395×Box)\n\n\n\n\n\n\n\n\n\n\n\nWickham, Hadley. 2011. “The Split-Apply-Combine Strategy for Data Analysis.” Journal of Statistical Software 40 (1): 1–29. https://doi.org/10.18637/jss.v040.i01.",
    "crumbs": [
      "Part III: Queries",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Split-apply-combine</span>"
    ]
  },
  {
    "objectID": "09-geojoins.html",
    "href": "09-geojoins.html",
    "title": "9  Geospatial joins",
    "section": "",
    "text": "9.1 Motivation\nAnother important tool in geospatial data science is the geospatial join. We will introduce the concept with a practical example, and will explain how it is related to the standard join of two tables.\nThe split-apply-combine pattern that we learned in the previous chapter requires a single geotable with all the relevant information in it. However, many questions in geospatial data science can only be answered with information that is spread across multiple geotables. Hence, the need to join these geotables before attempting to @groupby, @transform and @combine the information.\nLet’s consider a simple example where we are given two geotables, one containing people who shared their latitude and longitude coordinates:\ntable = (\n  NAME=[\"John\", \"Mary\", \"Paul\", \"Anne\", \"Kate\"],\n  AGE=[34.0, 12.0, 23.0, 39.0, 28.0]u\"yr\",\n  HEIGHT=[1.78, 1.56, 1.70, 1.80, 1.72]u\"m\",\n  LATITUDE=[-22.96710361241228, 37.42773662442142, -27.486220858775997, 39.90358408375064, -3.847311538763359],\n  LONGITUDE=[-43.17891118844475, -122.17007072663823, 153.04380578036657, 116.40764745941036, -32.411372812211226]\n)\n\npeople = georef(table, (:LONGITUDE, :LATITUDE)) |&gt; Proj(PlateCarree)\n\n\n5×4 GeoTable over 5 PointSet\n\n\nNAME\nAGE\nHEIGHT\ngeometry\n\n\nCategorical\nContinuous\nContinuous\nPoint\n\n\n[NoUnits]\n[yr]\n[m]\n🖈 PlateCarree{WGS84Latest}\n\n\n\n\nJohn\n34.0 yr\n1.78 m\n(x: -4.80665e6 m, y: -2.55669e6 m)\n\n\nMary\n12.0 yr\n1.56 m\n(x: -1.35999e7 m, y: 4.16644e6 m)\n\n\nPaul\n23.0 yr\n1.7 m\n(x: 1.70368e7 m, y: -3.05975e6 m)\n\n\nAnne\n39.0 yr\n1.8 m\n(x: 1.29584e7 m, y: 4.44205e6 m)\n\n\nKate\n28.0 yr\n1.72 m\n(x: -3.60802e6 m, y: -4.28281e5 m)\nAnd another containing countries in the world according to the Natural Earth project:\nusing GeoIO\n\ncountries = GeoIO.load(\"data/countries.geojson\", numbertype = Float64) |&gt; Proj(PlateCarree)\n\n\n177×3 GeoTable over 177 GeometrySet\n\n\nCOUNTRY\nREGION\ngeometry\n\n\nCategorical\nCategorical\nMultiPolygon\n\n\n[NoUnits]\n[NoUnits]\n🖈 PlateCarree{WGS84Latest}\n\n\n\n\nFiji\nMelanesia\nMulti(3×PolyArea)\n\n\nTanzania\nEastern Africa\nMulti(1×PolyArea)\n\n\nW. Sahara\nNorthern Africa\nMulti(1×PolyArea)\n\n\nCanada\nNorthern America\nMulti(30×PolyArea)\n\n\nUnited States of America\nNorthern America\nMulti(10×PolyArea)\n\n\nKazakhstan\nCentral Asia\nMulti(1×PolyArea)\n\n\nUzbekistan\nCentral Asia\nMulti(1×PolyArea)\n\n\nPapua New Guinea\nMelanesia\nMulti(4×PolyArea)\n\n\nIndonesia\nSouth-Eastern Asia\nMulti(13×PolyArea)\n\n\nArgentina\nSouth America\nMulti(2×PolyArea)\n\n\n⋮\n⋮\n⋮\nLet’s visualize the geometries of these two geotables:\nfig = Mke.Figure()\nax = Mke.Axis(fig[1,1], title = \"People and countries\",\n              xlabel = \"Easting [m]\", ylabel = \"Northing [m]\")\nviz!(countries.geometry)\nviz!(people.geometry, color = \"teal\", pointsize = 10)\nfig\nOur goal in this example is to attach the “COUNTRY” and “REGION” information to each individual based on their location, represented as a point. In other words, we want to find the countries that contain the location, and then copy the columns to the people.",
    "crumbs": [
      "Part III: Queries",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geospatial joins</span>"
    ]
  },
  {
    "objectID": "09-geojoins.html#motivation",
    "href": "09-geojoins.html#motivation",
    "title": "9  Geospatial joins",
    "section": "",
    "text": "Note\n\n\n\nThe georef function has a method that accepts the names of columns with geospatial coordinates. In this example, the table already has the LATITUDE and LONGITUDE coordinates, which we project to a PlateCarree CRS as discussed in the chapter Map projections.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe numbertype of the coordinates is specified to avoid the default floating point type used by the GeoJSON backend, which is Float32.",
    "crumbs": [
      "Part III: Queries",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geospatial joins</span>"
    ]
  },
  {
    "objectID": "09-geojoins.html#joining-geotables",
    "href": "09-geojoins.html#joining-geotables",
    "title": "9  Geospatial joins",
    "section": "9.2 Joining geotables",
    "text": "9.2 Joining geotables\nThe geojoin function can be used to join two geotables using a geometric predicate function:\n\ngeojoin(people, countries, pred = ∈)\n\n\n5×6 GeoTable over 5 PointSet\n\n\nNAME\nAGE\nHEIGHT\nCOUNTRY\nREGION\ngeometry\n\n\nCategorical\nContinuous\nContinuous\nCategorical\nCategorical\nPoint\n\n\n[NoUnits]\n[yr]\n[m]\n[NoUnits]\n[NoUnits]\n🖈 PlateCarree{WGS84Latest}\n\n\n\n\nJohn\n34.0 yr\n1.78 m\nBrazil\nSouth America\n(x: -4.80665e6 m, y: -2.55669e6 m)\n\n\nMary\n12.0 yr\n1.56 m\nUnited States of America\nNorthern America\n(x: -1.35999e7 m, y: 4.16644e6 m)\n\n\nPaul\n23.0 yr\n1.7 m\nAustralia\nAustralia and New Zealand\n(x: 1.70368e7 m, y: -3.05975e6 m)\n\n\nAnne\n39.0 yr\n1.8 m\nChina\nEastern Asia\n(x: 1.29584e7 m, y: 4.44205e6 m)\n\n\nKate\n28.0 yr\n1.72 m\nmissing\nmissing\n(x: -3.60802e6 m, y: -4.28281e5 m)\n\n\n\n\n\nIn the example above, we used the ∈ predicate to check if a Point in the people geotable is in a MultiPolygon in the countries geotable. The default predicate in geojoin is the intersects function that we covered in previous chapters.\nNotice that Kate’s “COUNTRY” and “REGION” are missing. That is because Kate lives in the Fernando de Noronha island, which is not present in the countries geotable. To retain just those people for which the geometric predicate evaluates true, we can use a different kind of geojoin known as :inner:\n\ngeojoin(people, countries, kind = :inner)\n\n\n4×6 GeoTable over 4 view(::PointSet, [1, 2, 3, 4])\n\n\nNAME\nAGE\nHEIGHT\nCOUNTRY\nREGION\ngeometry\n\n\nCategorical\nContinuous\nContinuous\nCategorical\nCategorical\nPoint\n\n\n[NoUnits]\n[yr]\n[m]\n[NoUnits]\n[NoUnits]\n🖈 PlateCarree{WGS84Latest}\n\n\n\n\nJohn\n34.0 yr\n1.78 m\nBrazil\nSouth America\n(x: -4.80665e6 m, y: -2.55669e6 m)\n\n\nMary\n12.0 yr\n1.56 m\nUnited States of America\nNorthern America\n(x: -1.35999e7 m, y: 4.16644e6 m)\n\n\nPaul\n23.0 yr\n1.7 m\nAustralia\nAustralia and New Zealand\n(x: 1.70368e7 m, y: -3.05975e6 m)\n\n\nAnne\n39.0 yr\n1.8 m\nChina\nEastern Asia\n(x: 1.29584e7 m, y: 4.44205e6 m)\n\n\n\n\n\nBy default, the :left kind is used. Like in standard join, the geojoin is not commutative. If we swap the order of the geotables, the result will be different:\n\ngeojoin(countries, people, kind = :inner)\n\n\n4×6 GeoTable over 4 view(::GeometrySet, [5, 30, 138, 140])\n\n\nCOUNTRY\nREGION\nNAME\nAGE\nHEIGHT\ngeometry\n\n\nCategorical\nCategorical\nCategorical\nContinuous\nContinuous\nMultiPolygon\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[yr]\n[m]\n🖈 PlateCarree{WGS84Latest}\n\n\n\n\nUnited States of America\nNorthern America\nMary\n12.0 yr\n1.56 m\nMulti(10×PolyArea)\n\n\nBrazil\nSouth America\nJohn\n34.0 yr\n1.78 m\nMulti(1×PolyArea)\n\n\nAustralia\nAustralia and New Zealand\nPaul\n23.0 yr\n1.7 m\nMulti(2×PolyArea)\n\n\nChina\nEastern Asia\nAnne\n39.0 yr\n1.8 m\nMulti(2×PolyArea)\n\n\n\n\n\nTo learn about the different kinds of join, check DataFrames.jl’s documentation on joins.\n\n\n\n\n\n\nNote\n\n\n\nIn database-style join, the predicate function isequal is applied to arbitrary columns of tables. In geojoin, geometric predicate functions are applied to the geometry column of geotables.\nThe tablejoin function can be used for database-style join between a geotable and a simple table (e.g., DataFrame). The result will be a new geotable over a subset of geometries from the first argument. Please check the documentation for more details.\n\n\n\n\n\n\n\n\nTip for all users\n\n\n\nBesides geojoin, the framework also provides vertical and horizontal concatenation of geotables. Vertical concatenation is achieved with vcat as follows:\n\ngt1 = georef((a=[1,2,3], b=[4,5,6]))\ngt2 = georef((b=[4,5,6], c=[7,8,9]))\n\nvcat(gt1, gt2)\n\n\n6×4 GeoTable over 6 GeometrySet\n\n\na\nb\nc\ngeometry\n\n\nCategorical\nCategorical\nCategorical\nSegment\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n1\n4\nmissing\nSegment((x: 0.0 m), (x: 1.0 m))\n\n\n2\n5\nmissing\nSegment((x: 1.0 m), (x: 2.0 m))\n\n\n3\n6\nmissing\nSegment((x: 2.0 m), (x: 3.0 m))\n\n\nmissing\n4\n7\nSegment((x: 0.0 m), (x: 1.0 m))\n\n\nmissing\n5\n8\nSegment((x: 1.0 m), (x: 2.0 m))\n\n\nmissing\n6\n9\nSegment((x: 2.0 m), (x: 3.0 m))\n\n\n\n\n\nAll columns are preserved by default, which corresponds to the option kind = :union. Absent columns are filled with missing values. The option kind = :intersect can be used to retain only the columns that are present in all geotables:\n\nvcat(gt1, gt2, kind = :intersect)\n\n\n6×2 GeoTable over 6 GeometrySet\n\n\nb\ngeometry\n\n\nCategorical\nSegment\n\n\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n4\nSegment((x: 0.0 m), (x: 1.0 m))\n\n\n5\nSegment((x: 1.0 m), (x: 2.0 m))\n\n\n6\nSegment((x: 2.0 m), (x: 3.0 m))\n\n\n4\nSegment((x: 0.0 m), (x: 1.0 m))\n\n\n5\nSegment((x: 1.0 m), (x: 2.0 m))\n\n\n6\nSegment((x: 2.0 m), (x: 3.0 m))\n\n\n\n\n\nHorizontal concatenation is achieved with hcat as follows:\n\nhcat(gt1, gt2)\n\n\n3×5 GeoTable over 3 CartesianGrid\n\n\na\nb\nb_\nc\ngeometry\n\n\nCategorical\nCategorical\nCategorical\nCategorical\nSegment\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n1\n4\n4\n7\nSegment((x: 0.0 m), (x: 1.0 m))\n\n\n2\n5\n5\n8\nSegment((x: 1.0 m), (x: 2.0 m))\n\n\n3\n6\n6\n9\nSegment((x: 2.0 m), (x: 3.0 m))\n\n\n\n\n\nUnique column names are produced with underscore suffixes whenever a column appears in multiple geotables. Julia provides convenient syntax for vcat and hcat:\n\n[gt1\n gt2]\n\n\n6×4 GeoTable over 6 GeometrySet\n\n\na\nb\nc\ngeometry\n\n\nCategorical\nCategorical\nCategorical\nSegment\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n1\n4\nmissing\nSegment((x: 0.0 m), (x: 1.0 m))\n\n\n2\n5\nmissing\nSegment((x: 1.0 m), (x: 2.0 m))\n\n\n3\n6\nmissing\nSegment((x: 2.0 m), (x: 3.0 m))\n\n\nmissing\n4\n7\nSegment((x: 0.0 m), (x: 1.0 m))\n\n\nmissing\n5\n8\nSegment((x: 1.0 m), (x: 2.0 m))\n\n\nmissing\n6\n9\nSegment((x: 2.0 m), (x: 3.0 m))\n\n\n\n\n\n\n[gt1 gt2]\n\n\n3×5 GeoTable over 3 CartesianGrid\n\n\na\nb\nb_\nc\ngeometry\n\n\nCategorical\nCategorical\nCategorical\nCategorical\nSegment\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n1\n4\n4\n7\nSegment((x: 0.0 m), (x: 1.0 m))\n\n\n2\n5\n5\n8\nSegment((x: 1.0 m), (x: 2.0 m))\n\n\n3\n6\n6\n9\nSegment((x: 2.0 m), (x: 3.0 m))",
    "crumbs": [
      "Part III: Queries",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geospatial joins</span>"
    ]
  },
  {
    "objectID": "09-geojoins.html#common-predicates",
    "href": "09-geojoins.html#common-predicates",
    "title": "9  Geospatial joins",
    "section": "9.3 Common predicates",
    "text": "9.3 Common predicates\nIn geospatial data science, the most common geometric predicates used in geojoin are ∈, ⊆, ==, ≈ and intersects as illustrated in Table 9.1. Specific applications may require custom predicates, which can be easily defined in pure Julia with the Meshes.jl module. For example, it is sometimes convenient to define geometric predicates in terms of a distance and a threshold:\n\npred(g1, g2) = evaluate(Euclidean(), centroid(g1), centroid(g2)) ≤ 1500u\"km\"\n\ngeojoin(people, countries, kind = :inner, pred = pred)\n\n\n1×6 GeoTable over 1 view(::PointSet, [4])\n\n\nNAME\nAGE\nHEIGHT\nCOUNTRY\nREGION\ngeometry\n\n\nCategorical\nContinuous\nContinuous\nCategorical\nCategorical\nPoint\n\n\n[NoUnits]\n[yr]\n[m]\n[NoUnits]\n[NoUnits]\n🖈 PlateCarree{WGS84Latest}\n\n\n\n\nAnne\n39.0 yr\n1.8 m\nNorth Korea\nEastern Asia\n(x: 1.29584e7 m, y: 4.44205e6 m)\n\n\n\n\n\n\n\n\nTable 9.1: Common geometric predicates in geospatial join\n\n\n\n\n\nPREDICATE\nEXAMPLE\n\n\n\n\n∈\n\n\n\n⊆\n\n\n\n==\n\n\n\n≈\n\n\n\nintersects",
    "crumbs": [
      "Part III: Queries",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geospatial joins</span>"
    ]
  },
  {
    "objectID": "09-geojoins.html#multiple-matches",
    "href": "09-geojoins.html#multiple-matches",
    "title": "9  Geospatial joins",
    "section": "9.4 Multiple matches",
    "text": "9.4 Multiple matches\nSometimes the predicate function will evaluate true for multiple rows of the geotables. In this case, we need to decide which value will be copied to the resulting geotable. The geojoin accepts reduction functions for each column. For example, suppose that Kate decided to move to the continent:\n\ntable = (\n  NAME=[\"John\", \"Mary\", \"Paul\", \"Anne\", \"Kate\"],\n  AGE=[34.0, 12.0, 23.0, 39.0, 28.0]u\"yr\",\n  HEIGHT=[1.78, 1.56, 1.70, 1.80, 1.72]u\"m\",\n  LATITUDE=[-22.96710361241228, 37.42773662442142, -27.486220858775997, 39.90358408375064, -9.66628224039543],\n  LONGITUDE=[-43.17891118844475, -122.17007072663823, 153.04380578036657, 116.40764745941036, -35.71261407423411]\n)\n\npeople = georef(table, (:LONGITUDE, :LATITUDE)) |&gt; Proj(PlateCarree)\n\n\n5×4 GeoTable over 5 PointSet\n\n\nNAME\nAGE\nHEIGHT\ngeometry\n\n\nCategorical\nContinuous\nContinuous\nPoint\n\n\n[NoUnits]\n[yr]\n[m]\n🖈 PlateCarree{WGS84Latest}\n\n\n\n\nJohn\n34.0 yr\n1.78 m\n(x: -4.80665e6 m, y: -2.55669e6 m)\n\n\nMary\n12.0 yr\n1.56 m\n(x: -1.35999e7 m, y: 4.16644e6 m)\n\n\nPaul\n23.0 yr\n1.7 m\n(x: 1.70368e7 m, y: -3.05975e6 m)\n\n\nAnne\n39.0 yr\n1.8 m\n(x: 1.29584e7 m, y: 4.44205e6 m)\n\n\nKate\n28.0 yr\n1.72 m\n(x: -3.97551e6 m, y: -1.07605e6 m)\n\n\n\n\n\nNow, both John and Kate live in Brazil according the countries geotable:\n\ngeojoin(people, countries)\n\n\n5×6 GeoTable over 5 PointSet\n\n\nNAME\nAGE\nHEIGHT\nCOUNTRY\nREGION\ngeometry\n\n\nCategorical\nContinuous\nContinuous\nCategorical\nCategorical\nPoint\n\n\n[NoUnits]\n[yr]\n[m]\n[NoUnits]\n[NoUnits]\n🖈 PlateCarree{WGS84Latest}\n\n\n\n\nJohn\n34.0 yr\n1.78 m\nBrazil\nSouth America\n(x: -4.80665e6 m, y: -2.55669e6 m)\n\n\nMary\n12.0 yr\n1.56 m\nUnited States of America\nNorthern America\n(x: -1.35999e7 m, y: 4.16644e6 m)\n\n\nPaul\n23.0 yr\n1.7 m\nAustralia\nAustralia and New Zealand\n(x: 1.70368e7 m, y: -3.05975e6 m)\n\n\nAnne\n39.0 yr\n1.8 m\nChina\nEastern Asia\n(x: 1.29584e7 m, y: 4.44205e6 m)\n\n\nKate\n28.0 yr\n1.72 m\nBrazil\nSouth America\n(x: -3.97551e6 m, y: -1.07605e6 m)\n\n\n\n\n\nIf we swap the order of the geotables in the geojoin, we need to decide how to reduce the multiple values of “NAME”, “AGE” and “HEIGHT” in the resulting geotable. By default, the mean function is used to reduce Continuous variables, and the first function is used otherwise:\n\ngeojoin(countries, people, kind = :inner)\n\n\n4×6 GeoTable over 4 view(::GeometrySet, [5, 30, 138, 140])\n\n\nCOUNTRY\nREGION\nNAME\nAGE\nHEIGHT\ngeometry\n\n\nCategorical\nCategorical\nCategorical\nContinuous\nContinuous\nMultiPolygon\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[yr]\n[m]\n🖈 PlateCarree{WGS84Latest}\n\n\n\n\nUnited States of America\nNorthern America\nMary\n12.0 yr\n1.56 m\nMulti(10×PolyArea)\n\n\nBrazil\nSouth America\nJohn\n31.0 yr\n1.75 m\nMulti(1×PolyArea)\n\n\nAustralia\nAustralia and New Zealand\nPaul\n23.0 yr\n1.7 m\nMulti(2×PolyArea)\n\n\nChina\nEastern Asia\nAnne\n39.0 yr\n1.8 m\nMulti(2×PolyArea)\n\n\n\n\n\nWe can specify custom reduction functions using the following syntax:\n\ngeojoin(countries, people, \"AGE\" =&gt; maximum, \"HEIGHT\" =&gt; mean, kind = :inner)\n\n\n4×6 GeoTable over 4 view(::GeometrySet, [5, 30, 138, 140])\n\n\nCOUNTRY\nREGION\nNAME\nAGE\nHEIGHT\ngeometry\n\n\nCategorical\nCategorical\nCategorical\nContinuous\nContinuous\nMultiPolygon\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[yr]\n[m]\n🖈 PlateCarree{WGS84Latest}\n\n\n\n\nUnited States of America\nNorthern America\nMary\n12.0 yr\n1.56 m\nMulti(10×PolyArea)\n\n\nBrazil\nSouth America\nJohn\n34.0 yr\n1.75 m\nMulti(1×PolyArea)\n\n\nAustralia\nAustralia and New Zealand\nPaul\n23.0 yr\n1.7 m\nMulti(2×PolyArea)\n\n\nChina\nEastern Asia\nAnne\n39.0 yr\n1.8 m\nMulti(2×PolyArea)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe keyword arguments kind and pred must appear at the end of the geojoin:\ngeojoin(gt1, gt2, var1 =&gt; red1, ..., varn =&gt; redn; kind = :left, pred = intersects)",
    "crumbs": [
      "Part III: Queries",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geospatial joins</span>"
    ]
  },
  {
    "objectID": "09-geojoins.html#congratulations",
    "href": "09-geojoins.html#congratulations",
    "title": "9  Geospatial joins",
    "section": "9.5 Congratulations!",
    "text": "9.5 Congratulations!\nCongratulations on finishing Part III of the book. Let’s quickly review what we learned so far:\n\nIn order to answer geoscientific questions with @groupby, @transform and @combine, we need a single geotable with all the relevant information. This single geotable is often the result of a geojoin with multiple geotables from different sources of information.\nThere are various kinds of geojoin such as inner and left, which match the behavior of standard join in databases. We recommend the DataFrames.jl documentation to learn more.\nThe geojoin produces matches with geometric predicate functions. The most common are illustrated in Table 9.1, but custom predicates can be easily defined in pure Julia using functions defined in the Meshes.jl module.\n\nIn the next part of the book, you will learn a final important tool that is missing in our toolkit for advanced geospatial data science. The concepts in the following chapters are extremely important.",
    "crumbs": [
      "Part III: Queries",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geospatial joins</span>"
    ]
  },
  {
    "objectID": "10-correlation.html",
    "href": "10-correlation.html",
    "title": "10  Geospatial correlation",
    "section": "",
    "text": "10.1 Variography\nIn Part II and Part III of the book, we learned two important tools for efficient geospatial data science. We learned how transform pipelines can be used to prepare geospatial data for investigation, and how geospatial queries can be used to answer geoscientific questions. Before we can learn our third tool, we need to review the important concept of geospatial correlation:\nLet’s consider the following synthetic image to illustrate the concept for different values of \\(h\\):\nThe hscatter plot can be used to visualize the scatter of pairs \\(\\{(x_1, y_1), (x_2, y_2), \\ldots, (x_n, y_n)\\}\\) at a given lag \\(h\\). We can choose a variable \\(X\\) for the horizontal axis, a (possibly different) variable \\(Y\\) for the vertical axis, and the value of the lag \\(h\\). In order to reduce the computational costs associated with the plot, we will sample a subset of measurements from the image:\nIf we plot the values of the variable Z in the horizontal axis and the values of the same variable measured at lag \\(h=0\\) on the vertical axis, we get points along the identity line (i.e. no scatter):\nBy increasing the value of the lag, we observe that the correlation is no longer equal to one, and that the linear fit through the points approaches the horizontal axis (i.e., zero correlation):\nThe Pearson correlation coefficient studied as a function of the lag \\(h\\) is known as the correlogram function. For example, consider the exponential correlogram function given by \\(cor(h) = \\exp(-h)\\):\nThe terms auto-correlogram (\\(X = Y\\)) and cross-correlogram (\\(X \\ne Y\\)) are also encountered in the literature to differentiate the various geospatial correlations in the multivariate case. Similarly, the terms auto-covariance and cross-covariance are encountered by replacing the correlation by the covariance (non-normalized correlation).\nEven though the correlogram function is widely used in other scientific fields, we will review an alternative statistic of association that is most useful in geospatial data science.\nThe value \\(\\gamma(h)\\) measures the “spread” of the hscatter plot. Usually, at \\(h=0\\) there is no spread, and hence \\(\\gamma(0) = 0\\). In most practical cases \\(\\gamma(h) \\to \\sigma^2\\) as \\(h \\to \\infty\\) where \\(\\sigma^2\\) is the maximum variance of the process. When this maximum variance exists, we can write the following relation:\n\\[\n\\gamma(h) = \\sigma^2 - cov(h)\n\\]\nwhere \\(cov(h)\\) is the covariance function, a version of the correlogram function that is scaled by the standard deviations of X and Y:\n\\[\ncor(h) = \\frac{cov(h)}{\\sigma_x \\sigma_y}\n\\]\nExplaining why the variogram is more general than the covariance is out of scope for this book, but it has to do with the fact that variograms operate on the “difference process” \\((x_i - x_j)\\) as opposed to the centered process \\((x_i - \\bar{x})\\). In particular, it does not require a finite maximum variance \\(\\sigma^2\\).\nOur main goal here is to gain intuition about the variogram function for interpolation purposes. It suffices to learn its four basic elements: range, sill, nugget and model.",
    "crumbs": [
      "Part IV: Interpolation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geospatial correlation</span>"
    ]
  },
  {
    "objectID": "10-correlation.html#variography",
    "href": "10-correlation.html#variography",
    "title": "10  Geospatial correlation",
    "section": "",
    "text": "Definition\n\n\n\nThe variogram function is a more general alternative to the correlogram and covariance functions that does not rely on the mean values \\(\\bar{x}\\) and \\(\\bar{y}\\). It is given by\n\\[\n\\gamma_x(h) \\approx \\frac{1}{2|N(h)|}\\sum_{N(h)}(x_i-x_j)^2\n\\]\nwhere \\(N(h) = \\Big\\{(i,j): i\\underbrace{\\longrightarrow}_{h \\text{ units}} j\\Big\\}\\) is the set of pairs of locations that are \\(h\\) units apart.\nIn the multivariate case, we can also define the cross-variogram:\n\\[\n\\gamma_{xy}(h) \\approx \\frac{1}{2|N(h)|}\\sum_{N(h)}(x_i-x_j)(y_i-y_j)\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe theory of intrinsic random functions of order k (IRF-k) is an advanced concept from geostatistical theory that explains the generality of the variogram function (Chilès and Delfiner 2012).\n\n\n\n\n\n10.1.1 range\nThe range (a.k.a. correlation length) of the variogram determines the average size of “blobs” in the image. Let’s consider two synthetic images with ranges 10 and 30, respectively:\n\n\n\n\n\nIn the first image, we can clearly visualize the average size of yellow and blue blobs around 10 pixels (i.e. quadrangles). In the second image, the blobs have an average size of 30 pixels, which is greater than one of the sides of the grid (100x25 pixels).\n\n\n10.1.2 sill\nTo understand the sill of the variogram, let’s consider a 1D grid as our domain, and let’s represent the values of the variable with height instead of color:\n\n\n\n\n\nThe sill determines the maximum variance of the process. If the sill is \\(\\sigma^2\\), then a process with mean \\(\\mu\\) will oscillate within \\(\\mu\\pm3\\sigma\\) with 99.7% probability. The vertical amplitude in the second plot is (3x) larger than that of the first plot. In both plots, we have \\(\\mu=0\\).\n\n\n10.1.3 nugget\nThe nugget can be used to insert additional variance at scales that are smaller than the scale of measurements (i.e. pixel). It is known in the image processing literature as salt-and-pepper noise:\n\n\n\n\n\nWe can visualize the nugget effect in our 2D grid with colors as before:\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe name “nugget” comes from gold nuggets in mining geostatistics. These are often much smaller than selective mining units (SMUs), and show as bright values in the 3D model of the mineral deposit.\n\n\n\n\n10.1.4 model\nFinally, the model of the variogram determines how the function increases near the origin. The GeoStats.jl framework provides dozens of such models of geospatial correlation. The most widely used are the GaussianVariogram, the SphericalVariogram and the ExponentialVariogram:\n\n\n\n\n\nThe faster is the increase of the function near the origin, the more “erratic” is the process:\n\n\n\n\n\nAll the four elements of the variogram function can be easily set at construction time:\n\nγ = GaussianVariogram(range=10.0, sill=2.0, nugget=0.1)\n\nGaussianVariogram\n├─ range: 10.0 m\n├─ sill: 2.0\n└─ nugget: 0.1\n\n\nAnd queried later with the corresponding functions:\n\nrange(γ), sill(γ), nugget(γ)\n\n(10.0 m, 2.0, 0.1)\n\n\nWe can evaluate the variogram at any given lag:\n\nγ(1.0)\n\n0.15615445670336806\n\n\nOr evaluate the variogram between any two points:\n\nγ(Point(0, 0), Point(1, 0))\n\n0.15615445670336806\n\n\nIn this case, the Euclidean metric is used by default to compute the lag. More generally, we can evaluate the variogram between any two geometries:\n\nγ(Point(0, 0), Triangle((0, 0), (1, 0), (1, 1)))\n\n0.13352136956222632\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe evaluation of the variogram function between two geometries is known as variogram regularization, and implemented in terms of numerical integration.\n\n\nRemind that the variogram value \\(\\gamma(h)\\) is a measure of spread in the hscatter plot. It tells how much variation is expected for a variable at a distance \\(h\\) from a reference point.",
    "crumbs": [
      "Part IV: Interpolation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geospatial correlation</span>"
    ]
  },
  {
    "objectID": "10-correlation.html#fitting-models",
    "href": "10-correlation.html#fitting-models",
    "title": "10  Geospatial correlation",
    "section": "10.2 Fitting models",
    "text": "10.2 Fitting models\nGiven geospatial data, how do we fit an appropriate variogram model for it? This practical question is traditionally answered in two steps as follows.\n\n10.2.1 Empirical estimate\nLet’s recap the synthetic image from the beginning of the chapter:\n\nimg |&gt; viewer\n\n\n\n\nWe can use the EmpiricalVariogram to estimate the function at specific lag values:\n\ng = EmpiricalVariogram(img, :Z, maxlag = 50.0)\n\nEmpiricalVariogram\n├─ abscissas: [1.77383 m, 3.97958 m, 6.34839 m, ..., 43.762 m, 46.2475 m, 48.7361 m]\n├─ ordinates: [0.0502087, 0.212007, 0.424966, ..., 0.874137, 0.880386, 0.886483]\n├─ distance: Euclidean(0.0)\n├─ estimator: MatheronEstimator()\n└─ npairs: 24138788\n\n\n\nvarioplot(g)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe numbers and bars in the empirical variogram plot represent the number of pairs used to estimate the value of the variogram at the corresponding bin. The larger the number, the more confident we can be in the estimate.\n\n\nThe DirectionalVariogram can be used to estimate the function along specific directions:\n\ngₕ = DirectionalVariogram((1.0, 0.0), img, :Z, maxlag = 50.0)\ngᵥ = DirectionalVariogram((0.0, 1.0), img, :Z, maxlag = 50.0)\n\nvarioplot(gₕ, showhist = false, color = \"maroon\")\nvarioplot!(gᵥ, showhist = false, color = \"slategray\")\nMke.current_figure()\n\n\n\n\nIn this example, we observe that the blobs are elongated with a horizontal range of 30 pixels and a vertical range of 10 pixels. This is known as geometric anisotropy.\nWe can also estimate the variogram in all directions on a plane with the EmpiricalVarioplane:\n\ngₚ = EmpiricalVarioplane(img, :Z, maxlag = 50.0)\n\nEmpiricalVarioplane\n  50 angles\n  └─0.00°\n  └─3.67°\n  └─7.35°\n  └─11.02°\n  └─14.69°\n  ⋮\n  └─165.31°\n  └─168.98°\n  └─172.65°\n  └─176.33°\n  └─180.00°\n\n\nThe varioplane is usually plotted on a polar axis to highlight the different ranges as a function of the polar angle:\n\nplaneplot(gₚ)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe book by Webster and Oliver (2007) and the article by Cressie and Hawkins (1980) are good resources to learn more about robust variogram estimation.\n\n\n\n\n10.2.2 Least-squares fit\nAfter empirical variogram estimation, the next step consists of fitting a theoretical model. This step is necessary for interpolation given that we need to be able to evaluate the variogram function at any lag \\(h\\), not just the specific lags of the empirical variogram.\n\n\n\n\n\n\nNote\n\n\n\nAnother reason to fit theoretical models is to ensure that variances of linear combinations of variables are always non-negative as discussed in Myers (1992).\n\n\nTo fit a specific theoretical model, we can use the fit function with the model as the first argument:\n\nGeoStatsFunctions.fit(SphericalVariogram, g)\n\nSphericalVariogram\n├─ range: 18.3506 m\n├─ sill: 0.886339\n└─ nugget: 2.6816e-10\n\n\nWe can also let the framework select the model with minimum weighted least-squares error by passing the generic Variogram model to the function:\n\nγ = GeoStatsFunctions.fit(Variogram, g)\n\nGaussianVariogram\n├─ range: 14.8885 m\n├─ sill: 0.886432\n└─ nugget: 0.0623571",
    "crumbs": [
      "Part IV: Interpolation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geospatial correlation</span>"
    ]
  },
  {
    "objectID": "10-correlation.html#remarks",
    "href": "10-correlation.html#remarks",
    "title": "10  Geospatial correlation",
    "section": "10.3 Remarks",
    "text": "10.3 Remarks\nThis chapter is definitely one of the most challenging ones for those with little background in geostatistics. Let’s make a few important remarks to summarize what we learned:\n\nGeospatial correlation can be represented with different functions, including the correlogram, the covariance and the variogram functions. Among these functions the variogram is the most general and easy to interpret as a measure of “spread” in the hscatter plot.\nThe variogram value \\(\\gamma(h)\\) represents the expected variation of a variable that is \\(h\\) units of distance from a reference point. It usually starts at \\(\\gamma(0) = 0\\), reaches a sill value \\(\\sigma^2\\) near the range and stays at this value as \\(h \\to \\infty\\).\nThe selection of an appropriate theoretical variogram model for interpolation of geospatial data is often based on a two-step procedure. First, we estimate the EmpiricalVariogram, and then we fit a theoretical model. The most widely used models are the GaussianVariogram, the SphericalVariogram and the ExponentialVariogram.\n\nIn the next chapter, we will learn how to perform geospatial interpolation with the selected theoretical variogram model.\n\n\n\n\nChilès, Jean-Paul, and Pierre Delfiner. 2012. Geostatistics. Wiley. https://doi.org/10.1002/9781118136188.\n\n\nCressie, Noel, and Douglas M. Hawkins. 1980. “Robust Estimation of the Variogram: i.” Journal of the International Association for Mathematical Geology 12 (2): 115–25. https://doi.org/10.1007/bf01035243.\n\n\nMyers, Donald E. 1992. “Kriging, Cokriging, Radial Basis Functions and the Role of Positive Definiteness.” Computers & Mathematics with Applications 24 (12): 139–48. https://doi.org/https://doi.org/10.1016/0898-1221(92)90176-I.\n\n\nWebster, Richard, and Margaret A. Oliver. 2007. Geostatistics for Environmental Scientists. Wiley. https://doi.org/10.1002/9780470517277.",
    "crumbs": [
      "Part IV: Interpolation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geospatial correlation</span>"
    ]
  },
  {
    "objectID": "11-interpolation.html",
    "href": "11-interpolation.html",
    "title": "11  Simple interpolation",
    "section": "",
    "text": "11.1 IDW\nA very common task in geospatial data science is geospatial interpolation, i.e., predicting variables on geometries that lie between two or more geometries that have measurements. In this chapter, we will exploit geospatial correlation to make good predictions of continuous variables over an entire domain based on sparse measurements, which are usually stored on a GeometrySet.\nThe basic idea behind most geostatistical interpolation methods is weighted combination of values from neighboring geometries. Given a geometry \\(u\\), we want to estimate the value of the variable at this geometry \\(z(u)\\) using weighted combinations of measurements from neighboring geometries \\(u_i,\\ i=1,2,\\ldots,n\\):\n\\[\nz(u) = \\lambda_1 z(u_1) + \\lambda_2 z(u_2) + \\cdots + \\lambda_n z(u_n)\n\\]\nThe methods differ in the way they compute the weights \\(\\lambda_i,\\ i=1,2,\\ldots,n\\), and we will cover two basic methods from classical literature: IDW and Kriging.\nIn Inverse Distance Weighting (IDW), the weights are computed in terms of distances \\(d(u, u_i)\\) to the neighboring geometries:\n\\[\n\\lambda_i = \\frac{1}{{d(u, u_i)}^\\beta}\n\\]\nThis basic idea was proposed by Shepard (1968), who also studied the effect of the exponent \\(\\beta\\) in the interpolation results. Here, we will visualize the results using synthetic data:\ndata = georef((z=[1.0, 0.0, 1.0],), [(25, 25), (50, 75), (75, 50)])\n\n\n3×2 GeoTable over 3 PointSet\n\n\nz\ngeometry\n\n\nContinuous\nPoint\n\n\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n1.0\n(x: 25.0 m, y: 25.0 m)\n\n\n0.0\n(x: 50.0 m, y: 75.0 m)\n\n\n1.0\n(x: 75.0 m, y: 50.0 m)\nviewer(data, pointsize = 10)\nFirst, we need to the define the domain of interpolation, i.e., the geometries where we want to estimate the variable z. In this case, we will perform interpolation on a 2D CartesianGrid:\ngrid = CartesianGrid(100, 100)\n\n100×100 CartesianGrid\n├─ minimum: Point(x: 0.0 m, y: 0.0 m)\n├─ maximum: Point(x: 100.0 m, y: 100.0 m)\n└─ spacing: (1.0 m, 1.0 m)\nWith the measurements of the variable z in the geotable, and the domain of interpolation, we can use the Interpolate transform with the IDW model:\ninterp = data |&gt; Interpolate(grid, model=IDW())\n\n\n10000×2 GeoTable over 100×100 CartesianGrid\n\n\nz\ngeometry\n\n\nContinuous\nQuadrangle\n\n\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n0.781732\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\n0.783631\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\n0.785528\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 1.0 m))\n\n\n0.787419\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 1.0 m))\n\n\n0.789298\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 1.0 m))\n\n\n0.79116\nQuadrangle((x: 5.0 m, y: 0.0 m), ..., (x: 5.0 m, y: 1.0 m))\n\n\n0.792998\nQuadrangle((x: 6.0 m, y: 0.0 m), ..., (x: 6.0 m, y: 1.0 m))\n\n\n0.794805\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 1.0 m))\n\n\n0.796573\nQuadrangle((x: 8.0 m, y: 0.0 m), ..., (x: 8.0 m, y: 1.0 m))\n\n\n0.798295\nQuadrangle((x: 9.0 m, y: 0.0 m), ..., (x: 9.0 m, y: 1.0 m))\n\n\n⋮\n⋮\ninterp |&gt; viewer\nTo visualize the effect of the exponent, let’s extract the interpolation results along the line segment between two of the measurements, and visualize it:\nseg = Segment((25, 25), (50, 75))\n\nSegment\n├─ Point(x: 25.0 m, y: 25.0 m)\n└─ Point(x: 50.0 m, y: 75.0 m)\nz = interp[seg, \"z\"]\n\n51-element Vector{Float64}:\n 0.9878058074478854\n 0.9876143292632583\n 0.972495221818037\n 0.9564199524248658\n 0.9361611041027588\n 0.9216832603980624\n 0.9021987666253538\n 0.8888032891965897\n 0.870354691640647\n 0.8577880405850806\n ⋮\n 0.32990370885751297\n 0.3057282754699494\n 0.26975994006108955\n 0.24282226179926458\n 0.20095741787691726\n 0.17114300512175212\n 0.1219443018616857\n 0.09029188985211117\n 0.03175705173700492\nMke.lines(z)\nWe observe that the exponent \\(\\beta=1\\) leads to a gradual transition from the value \\(z=1\\) to the value \\(z=0\\). Let’s repeat the process with increasing values of the exponent:\nfig = Mke.Figure()\nMke.Axis(fig[1,1])\nfor β in [1,2,3,4,5]\n  interp = data |&gt; Interpolate(grid, model=IDW(β))\n  Mke.lines!(interp[seg, \"z\"], label = \"β=$β\")\nend\nMke.axislegend(position = :lb)\nMke.current_figure()\nThe larger is the exponent, the more abrupt is the transition of values between the two locations. In addition, the IDW solution will converge to the nearest neighbor solution as \\(\\beta \\to \\infty\\):\ndata |&gt; Interpolate(grid, model=IDW(100)) |&gt; viewer\nCustom distances from Distances.jl may be used in place of the Euclidean distance to meet specific application requirements (e.g. Haversine distance on the sphere).",
    "crumbs": [
      "Part IV: Interpolation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Simple interpolation</span>"
    ]
  },
  {
    "objectID": "11-interpolation.html#kriging",
    "href": "11-interpolation.html#kriging",
    "title": "11  Simple interpolation",
    "section": "11.2 Kriging",
    "text": "11.2 Kriging\nIn Kriging (Matheron 1971), the weights are computed using geospatial correlation. More specifically, they are the solution to a linear system of equations produced with a theoretical variogram model \\(\\gamma\\):\n\\[\n\\begin{bmatrix}\n\\mathbf{G} & \\mathbf{1} \\\\\n\\mathbf{1}^\\top & 0\n\\end{bmatrix}\n\\begin{bmatrix}\n\\mathbf{\\lambda} \\\\\n\\nu\n\\end{bmatrix} =\n\\begin{bmatrix}\n\\mathbf{g} \\\\\n1\n\\end{bmatrix}\n\\]\nwhere \\(\\mathbf{G}_{ij} = \\gamma(u_i, u_j)\\) and \\(\\mathbf{g}_i = \\gamma(u, u_i)\\) and \\(\\nu\\) is the Lagrange multiplier associated with the constraint \\(\\mathbf{1}^\\top \\mathbf{\\lambda} = 1\\). The system of equations above is known as Ordinary Kriging, but many other variants are supported by the framework.\n\n\n\n\n\n\nNote\n\n\n\nThe book by Olea (1999) is a good resource to learn the different systems of of equations associated with Kriging interpolation. Names such as Simple Kriging Ordinary Kriging, Universal Kriging are quite popular.\n\n\nUnlike IDW, the Kriging solution is a function of pairwise evaluations of distances between geometries with measurements, represented in the matrix \\(\\mathbf{G}\\). The pairwise evaluations account for possible redundancy in the measurements, which leads to improvements in the estimates:\n\nγ = GaussianVariogram(range=30.0)\n\ndata |&gt; Interpolate(grid, model=Kriging(γ)) |&gt; viewer\n\n\n\n\nIn the previous chapter, we learned how the range of the variogram determines the average size of the “blobs” in the image. Let’s illustrate this concept again for increasing values of this parameter:\n\nfig = Mke.Figure()\nMke.Axis(fig[1,1])\nfor r in [10,20,30,40,50]\n  γ = GaussianVariogram(range=r)\n  interp = data |&gt; Interpolate(grid, model=Kriging(γ))\n  Mke.lines!(interp[seg, \"z\"], label = \"range=$r\")\nend\nMke.axislegend(position = :lb)\nMke.current_figure()\n\n\n\n\nThe larger is the range, the less abrupt is the transition of values between the two locations. Similar visualizations can be produced by varying the sill, the nugget and the model of the variogram.",
    "crumbs": [
      "Part IV: Interpolation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Simple interpolation</span>"
    ]
  },
  {
    "objectID": "11-interpolation.html#example",
    "href": "11-interpolation.html#example",
    "title": "11  Simple interpolation",
    "section": "11.3 Example",
    "text": "11.3 Example\nIn order to solidify the concepts learned so far, let’s look into an example. We will cover all the steps that a geospatial data scientist has to perform to extract geospatial correlation from samples and to use this information in geospatial interpolation.\nLet’s consider an image of the Walker Lake by Mariethoz and Caers (2014) as groundtruth. To avoid visualization of large images with CairoMakie.jl, we will consider a subdomain within a Box:\n\nusing GeoIO\n\nimg = GeoIO.load(\"data/walkerlake.gslib\")\n\nimg = img[Box((0, 0), (200, 200)), :]\n\n\n40401×2 GeoTable over 40401 view(::CartesianGrid, [1, 2, 3, 4, ..., 60198, 60199, 60200, 60201])\n\n\nZ\ngeometry\n\n\nContinuous\nQuadrangle\n\n\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n0.127143\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\n0.126681\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\n0.126143\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 1.0 m))\n\n\n0.125604\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 1.0 m))\n\n\n0.144938\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 1.0 m))\n\n\n0.169887\nQuadrangle((x: 5.0 m, y: 0.0 m), ..., (x: 5.0 m, y: 1.0 m))\n\n\n0.219131\nQuadrangle((x: 6.0 m, y: 0.0 m), ..., (x: 6.0 m, y: 1.0 m))\n\n\n0.302491\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 1.0 m))\n\n\n0.351556\nQuadrangle((x: 8.0 m, y: 0.0 m), ..., (x: 8.0 m, y: 1.0 m))\n\n\n0.365325\nQuadrangle((x: 9.0 m, y: 0.0 m), ..., (x: 9.0 m, y: 1.0 m))\n\n\n⋮\n⋮\n\n\n\n\n\n\nimg |&gt; viewer\n\n\n\n\nLet’s assume that we only have access to 10000 samples from the image:\n\nusing Random\n\nsamples = img |&gt; Sample(10000, replace=false, rng=MersenneTwister(123))\n\nsamples |&gt; viewer\n\n\n\n\nOur goal is to interpolate the variable Z over the original domain. Let’s start by estimating the EmpiricalVariogram from the samples. Because the distribution of values in the Walker Lake is skewed, the default :matheron estimator of the variogram shows a high nugget effect:\n\ng = EmpiricalVariogram(samples, \"Z\", maxlag = 100.0)\n\nEmpiricalVariogram\n├─ abscissas: [3.42807 m, 7.81911 m, 12.6844 m, ..., 87.5004 m, 92.4891 m, 97.4885 m]\n├─ ordinates: [0.0281692, 0.0417714, 0.053692, ..., 0.0911535, 0.0903101, 0.08894]\n├─ distance: Euclidean(0.0)\n├─ estimator: MatheronEstimator()\n└─ npairs: 23971781\n\n\n\nvarioplot(g)\n\n\n\n\nA better alternative in this case is to use the robust :cressie estimator:\n\ng = EmpiricalVariogram(samples, \"Z\", maxlag = 100.0, estimator = :cressie)\n\nEmpiricalVariogram\n├─ abscissas: [3.42807 m, 7.81911 m, 12.6844 m, ..., 87.5004 m, 92.4891 m, 97.4885 m]\n├─ ordinates: [0.013891, 0.0278463, 0.041494, ..., 0.0976509, 0.0974642, 0.0962541]\n├─ distance: Euclidean(0.0)\n├─ estimator: CressieEstimator()\n└─ npairs: 23971781\n\n\n\nvarioplot(g)\n\n\n\n\nAfter estimating the empirical variogram, the next step consists of fitting a theoretical model. The behavior near the origin resembles a SphericalVariogram:\n\nγ = GeoStatsFunctions.fit(SphericalVariogram, g)\n\nSphericalVariogram\n├─ range: 42.4939 m\n├─ sill: 0.0989522\n└─ nugget: 3.6195e-11\n\n\n\nvarioplot(γ, maxlag = 100.0)\n\n\n\n\nNow that we extracted the geospatial correlation from the samples, we can use this information in Kriging interpolation. Instead of fitting all the samples at once like it is done in the Interpolate transform, we will fit the Kriging model with a maximum number of neighbors with the InterpolateNeighbors transform:\n\ninterp = samples |&gt; InterpolateNeighbors(img.geometry, model=Kriging(γ))\n\n\n40401×2 GeoTable over 40401 view(::CartesianGrid, [1, 2, 3, 4, ..., 60198, 60199, 60200, 60201])\n\n\nZ\ngeometry\n\n\nContinuous\nQuadrangle\n\n\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n0.0973527\nQuadrangle((x: 0.0 m, y: 0.0 m), ..., (x: 0.0 m, y: 1.0 m))\n\n\n0.107266\nQuadrangle((x: 1.0 m, y: 0.0 m), ..., (x: 1.0 m, y: 1.0 m))\n\n\n0.120707\nQuadrangle((x: 2.0 m, y: 0.0 m), ..., (x: 2.0 m, y: 1.0 m))\n\n\n0.125604\nQuadrangle((x: 3.0 m, y: 0.0 m), ..., (x: 3.0 m, y: 1.0 m))\n\n\n0.218407\nQuadrangle((x: 4.0 m, y: 0.0 m), ..., (x: 4.0 m, y: 1.0 m))\n\n\n0.272989\nQuadrangle((x: 5.0 m, y: 0.0 m), ..., (x: 5.0 m, y: 1.0 m))\n\n\n0.306824\nQuadrangle((x: 6.0 m, y: 0.0 m), ..., (x: 6.0 m, y: 1.0 m))\n\n\n0.33139\nQuadrangle((x: 7.0 m, y: 0.0 m), ..., (x: 7.0 m, y: 1.0 m))\n\n\n0.351556\nQuadrangle((x: 8.0 m, y: 0.0 m), ..., (x: 8.0 m, y: 1.0 m))\n\n\n0.365325\nQuadrangle((x: 9.0 m, y: 0.0 m), ..., (x: 9.0 m, y: 1.0 m))\n\n\n⋮\n⋮\n\n\n\n\n\n\ninterp |&gt; viewer\n\n\n\n\n\n\n\n\n\n\nTip for all users\n\n\n\nThe InterpolateNeighbors is recommended in 3D applications with hundreds of thousands of measurements and very large grids.\n\n\n\n\n\n\n\n\nTip for all users\n\n\n\nThe InterpolateMissing transform can be used to interpolate missing values in a geotable using the same algorithm of InterpolateNeighbors. Likewise, the InterpolateNaN can be used to interpolate NaN values.",
    "crumbs": [
      "Part IV: Interpolation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Simple interpolation</span>"
    ]
  },
  {
    "objectID": "11-interpolation.html#congratulations",
    "href": "11-interpolation.html#congratulations",
    "title": "11  Simple interpolation",
    "section": "11.4 Congratulations!",
    "text": "11.4 Congratulations!\nCongratulations on finishing Part IV of the book. The interpolation models introduced here are simple, yet very useful. Before we start our journey with real-world applications of the framework, let’s review what we learned:\n\nGeospatial interpolation can be achieved with the Interpolate and InterpolateNeighbors transforms, and geostatistical models such as IDW and Kriging.\nModels such as Kriging exploit geospatial correlation to improve interpolation results. We can extract this information from samples using a two-step procedure:\n\nEstimate the EmpiricalVariogram from the available samples\nPerform fit of theoretical model with result from previous step\n\nInterpolate and InterpolateNeighbors are examples of geostatistical transforms. They can be easily inserted in more advanced pipelines as discussed in Part II.\n\nIn the next chapters, we will use the framework that we learned with real data to illustrate how advanced geospatial data science can be done with just a few lines of code. Once a solution is written in terms of the high-level tools covered in previous chapters, it is trivial to improve computational performance in pure Julia.\n\n\n\n\n\n\nNote\n\n\n\nFeature and performance requests are very welcome. We invite all users of the framework to submit issues and contribute with our open source software stack.\n\n\n\n\n\n\nMariethoz, Gregoire, and Jef Caers. 2014. Multiple-Point Geostatistics: Stochastic Modeling with Training Images. https://www.wiley.com/en-gb/Multiple+point+Geostatistics%3A+Stochastic+Modeling+with+Training+Images-p-9781118662755.\n\n\nMatheron, Georges François Paul Marie. 1971. The Theory of Regionalized Variables and Its Applications.\n\n\nOlea, Ricardo A. 1999. Geostatistics for Engineers and Earth Scientists. Springer US. https://doi.org/10.1007/978-1-4615-5001-3.\n\n\nShepard, Donald S. 1968. “A Two-Dimensional Interpolation Function for Irregularly-Spaced Data.” Proceedings of the 1968 23rd ACM National Conference. https://api.semanticscholar.org/CorpusID:42723195.",
    "crumbs": [
      "Part IV: Interpolation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Simple interpolation</span>"
    ]
  },
  {
    "objectID": "12-mining.html",
    "href": "12-mining.html",
    "title": "12  Mineral deposits",
    "section": "",
    "text": "12.1 Data\nIn the mining industry, resource estimation consists of interpolating measurements of metal and mineral grades from drill hole samples to 3D grids known as “block models”. Due to highly skewed distributions, several pre-processing steps need to be performed before the actual interpolation. In this chapter, we will cover simple steps for resource estimation and economic assessment of a real mineral deposit.\nTOOLS COVERED: @groupby, @transform, @combine, CLR, ProjectionPursuit, EmpiricalVariogram, Kriging, Interpolate, InterpolateNeighbors, Shadow, Map, Filter, boundingbox, convexhull, viewer\nMODULES:\nThe GeoMet dataset (Hoffimann et al. 2022a) consists of three geospatial tables stored as CSV files. In this chapter, we will only use the drillholes.csv table.\nDrill hole samples are always available in mining projects. They contain chemical information for each rock sample (a cylinder) along the drill hole trajectories. In this case, the data has been processed, and only the Cartesian “X”, “Y”, “Z” coordinates of the centroids of the cylinders were stored:\nurl = \"https://zenodo.org/record/7051975/files/drillholes.csv?download=1\"\n\ncsv = download(url, tempname()*\".csv\")\n\ndtable = GeoIO.load(csv, coords = (\"X\", \"Y\", \"Z\"))\n\ndtable |&gt; Select(\"Cu ppm\") |&gt; viewer\ndtable |&gt; describe\n\nTable with 6 columns and 19 rows:\n      variable  mean      minimum  median    maximum   nmissing\n    ┌──────────────────────────────────────────────────────────\n 1  │ HOLEID    nothing   1        nothing   119       0\n 2  │ Ag ppm    1.86199   0.01     1.14      15.38     0\n 3  │ Al ppm    52374.8   2400.0   56100.0   103300.0  0\n 4  │ Au ppm    0.470965  0.0      0.21      5.89      0\n 5  │ C ppm     1117.7    100.0    700.0     20700.0   0\n 6  │ Ca ppm    9900.6    100.0    6400.0    73700.0   0\n 7  │ Cl ppm    2303.75   5.48     1756.23   14273.8   0\n 8  │ Cu ppm    7540.4    0.0      5000.0    60200.0   0\n 9  │ F ppm     2528.58   20.89    1610.47   19786.3   0\n 10 │ Fe ppm    245452.0  9900.0   246000.0  500000.0  0\n 11 │ K ppm     13610.9   100.0    12450.0   45500.0   0\n 12 │ Mg ppm    17673.0   200.0    14000.0   88800.0   0\n 13 │ Mn ppm    4282.96   88.95    3685.35   24812.8   0\n 14 │ Na ppm    4404.8    100.0    1400.0    58900.0   0\n 15 │ P ppm     720.896   38.08    630.705   5576.14   0\n 16 │ Pb ppm    9.3938    0.8      6.005     247.83    0\n 17 │ S ppm     2712.95   100.0    1700.0    21500.0   0\n ⋮  │    ⋮         ⋮         ⋮        ⋮         ⋮         ⋮\nThere are 18 chemical elements in the table, all measured in parts per million (ppm). The table also stores an integer identifier for each hole trajectory in the “HOLEID” column. There are 119 such trajectories as shown in the “maximum” column of the describe output.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Mineral deposits</span>"
    ]
  },
  {
    "objectID": "12-mining.html#data",
    "href": "12-mining.html#data",
    "title": "12  Mineral deposits",
    "section": "",
    "text": "Note\n\n\n\nIn most mining projects, the drill hole samples are available as “SURVEY”, “COLLAR” and “INTERVAL” tables, which can be desurveyed and composited with DrillHoles.jl.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Mineral deposits</span>"
    ]
  },
  {
    "objectID": "12-mining.html#objectives",
    "href": "12-mining.html#objectives",
    "title": "12  Mineral deposits",
    "section": "12.2 Objectives",
    "text": "12.2 Objectives\nOur main objective is to estimate the economic value associated with each mining block in a 3D block model, i.e. a CartesianGrid with Hexahedron geometries (the blocks). This economic value in U$ dollars is estimated in terms of various other geospatial variables:\n\\[\nValue = \\underbrace{V \\times \\rho \\times Cu \\times f \\times P}_{\\text{revenue}} - \\underbrace{V \\times \\rho \\times (C_m + C_p)}_{\\text{cost}}\n\\]\nwhere\n\n\\(V\\) is the volume of the block in \\(m^3\\)\n\\(\\rho\\) is the rock density in \\(ton/m^3\\)\n\\(Cu\\) is the grade of copper in \\([0,1]\\)\n\\(f\\) is the recovery of copper in \\([0,1]\\)\n\\(P\\) is the selling price in \\(U\\$/ton\\)\n\\(C_m\\) is the mining cost in \\(U\\$/ton\\)\n\\(C_p\\) is the plant cost in \\(U\\$/ton\\)\n\nSecondary objectives include the localization (through 3D visualization) of blocks with high economic value, high grades of Au and Ag, and low grade of S.\nFor simplicity, we assume the following constants:\n\n\\(\\rho = 2.75\\ ton / m^3\\)\n\\(P = 4000\\ U\\$ / ton\\)\n\\(C_m = 4\\ U\\$ / ton\\)\n\\(C_p = 10\\ U\\$ / ton\\)",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Mineral deposits</span>"
    ]
  },
  {
    "objectID": "12-mining.html#methodology",
    "href": "12-mining.html#methodology",
    "title": "12  Mineral deposits",
    "section": "12.3 Methodology",
    "text": "12.3 Methodology\nIn order to estimate the economic value of each mining block, we need to interpolate the grade of Cu. Because we also want to localize the blocks with high grades of Au and Ag, and low grade of S, we will perform multivariate geostatistical interpolation of Cu, Au, Ag and S.\nThe proposed methodology has the following steps:\n\nPreliminary analysis and processing\nDefinition of interpolation domain\nMultivariate geostatistical interpolation\nEconomic assessment and visualizations\n\n\n12.3.1 Preliminary analysis\nWe recommend to start any application discarding all information that is not relevant for the stated objectives. In this case, the geotable contains measurements of various chemical elements that are not used in the economic assessment. We define a cleaning pipeline that selects and renames columns of interest, and adds units to the measurements:\n\nselectholeid = Select(\"HOLEID\")\n\nselectgrades = Select(\"Cu ppm\" =&gt; \"Cu\",\n                      \"Au ppm\" =&gt; \"Au\",\n                      \"Ag ppm\" =&gt; \"Ag\",\n                      \"S ppm\"  =&gt; \"S\") →\n               Functional(x -&gt; 1e-4*x*u\"percent\") # 1 ppm = 1e-4 percent\n\ndclean = selectholeid ⊔ selectgrades\n\nParallelTableTransform\n├─ Select(selector: [:HOLEID], newnames: nothing)\n└─ SequentialTransform\n   ├─ Select(selector: [Symbol(\"Cu ppm\"), Symbol(\"Au ppm\"), Symbol(\"Ag ppm\"), Symbol(\"S ppm\")], newnames: [:Cu, :Au, :Ag, :S])\n   └─ Functional(selector: all, fun: #1)\n\n\n\ndtable = dclean(dtable)\n\n\n2000×6 GeoTable over 2000 PointSet\n\n\nHOLEID\nCu\nAu\nAg\nS\ngeometry\n\n\nCategorical\nContinuous\nContinuous\nContinuous\nContinuous\nPoint\n\n\n[NoUnits]\n[%]\n[%]\n[%]\n[%]\n🖈 Cartesian{NoDatum}\n\n\n\n\n1\n0.72 %\n0.000104 %\n6.4e-5 %\n0.61 %\n(x: 559.725 m, y: -513.31 m, z: 252.82 m)\n\n\n1\n0.1 %\n6.0e-6 %\n2.0e-5 %\n0.06 %\n(x: 558.955 m, y: -515.23 m, z: 246.87 m)\n\n\n1\n2.18 %\n0.000202 %\n0.000344 %\n1.17 %\n(x: 557.225 m, y: -519.61 m, z: 233.37 m)\n\n\n1\n2.29 %\n0.000343 %\n0.000488 %\n1.1 %\n(x: 555.375 m, y: -524.3 m, z: 218.92 m)\n\n\n1\n0.59 %\n5.0e-5 %\n0.000125 %\n0.22 %\n(x: 553.825 m, y: -528.21 m, z: 206.94 m)\n\n\n1\n0.56 %\n9.0e-5 %\n9.0e-5 %\n0.28 %\n(x: 552.075 m, y: -532.56 m, z: 193.91 m)\n\n\n1\n2.0 %\n0.000356 %\n9.3e-5 %\n1.96 %\n(x: 550.305 m, y: -537.08 m, z: 180.8 m)\n\n\n1\n0.28 %\n2.1e-5 %\n7.6e-5 %\n0.14 %\n(x: 547.495 m, y: -544.31 m, z: 160.08 m)\n\n\n1\n0.61 %\n2.0e-5 %\n0.000112 %\n0.28 %\n(x: 544.335 m, y: -552.43 m, z: 137.08 m)\n\n\n1\n0.25 %\n1.6e-5 %\n7.7e-5 %\n0.09 %\n(x: 541.695 m, y: -559.19 m, z: 117.96 m)\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nIn order to better understand the multivariate distribution of chemical elements, we visualize the values of the drill hole samples with the pairplot:\n\ndtable |&gt; Select(\"Cu\", \"Au\", \"Ag\", \"S\") |&gt; values |&gt; pairplot\n\n\n\n\nWe can observe that the distribution is very skewed.\n\n\n12.3.2 Domain of interpolation\nBefore we can interpolate these variables, we need to define our domain of interpolation. In this application, we will define a 3D CartesianGrid in terms of the drill hole trajectories alone. Some of the Hexahedron geometries will be disabled whenever they are outside the convexhull of the points.\nFirst, let’s create our full CartesianGrid using the boundingbox of the trajectories:\n\n# compute bounding box\nbbox = boundingbox(dtable.geometry)\n\n# size of blocks in meters\nbsize = (25.0u\"m\", 25.0u\"m\", 12.5u\"m\")\n\n# define Cartesian grid\ngrid = CartesianGrid(extrema(bbox)..., bsize)\n\n85×66×66 CartesianGrid\n├─ minimum: Point(x: -1150.004825000069 m, y: -882.9003199972212 m, z: -399.92 m)\n├─ maximum: Point(x: 974.9951749999309 m, y: 767.0996800027788 m, z: 425.08 m)\n└─ spacing: (25.0 m, 25.0 m, 12.5 m)\n\n\n\nviz(dtable.geometry, color = \"black\")\nviz!(grid, alpha = 0.2)\nMke.current_figure()\n\n\n\n\nSecond, let’s compute the convexhull of the Shadow of all points on the xy plane:\n\nshadow(point) = point |&gt; Shadow(\"xy\")\n\npoints = shadow.(dtable.geometry)\n\nchull = convexhull(points)\n\nPolyArea\n  outer\n  └─ Ring((x: -1150.0 m, y: 641.23 m), ..., (x: -1120.56 m, y: 701.22 m))\n\n\n\nviz(chull)\nviz!(points, color = \"black\")\nMke.current_figure()\n\n\n\n\nWe can filter the grid to retain Hexahedrons for which the projected centroid is inside the convexhull:\n\nactive = findall(h -&gt; shadow(centroid(h)) ∈ chull, grid)\n\nblocks = view(grid, active)\n\n136422 view(::CartesianGrid, [76, 77, 78, 79, ..., 370102, 370103, 370104, 370186])\n├─ Hexahedron((x: 724.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 724.995 m, y: -857.9 m, z: -387.42 m))\n├─ Hexahedron((x: 749.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 749.995 m, y: -857.9 m, z: -387.42 m))\n├─ Hexahedron((x: 774.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 774.995 m, y: -857.9 m, z: -387.42 m))\n├─ Hexahedron((x: 799.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 799.995 m, y: -857.9 m, z: -387.42 m))\n├─ Hexahedron((x: 824.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 824.995 m, y: -857.9 m, z: -387.42 m))\n⋮\n├─ Hexahedron((x: -900.005 m, y: 717.1 m, z: 412.58 m), ..., (x: -900.005 m, y: 742.1 m, z: 425.08 m))\n├─ Hexahedron((x: -875.005 m, y: 717.1 m, z: 412.58 m), ..., (x: -875.005 m, y: 742.1 m, z: 425.08 m))\n├─ Hexahedron((x: -850.005 m, y: 717.1 m, z: 412.58 m), ..., (x: -850.005 m, y: 742.1 m, z: 425.08 m))\n├─ Hexahedron((x: -825.005 m, y: 717.1 m, z: 412.58 m), ..., (x: -825.005 m, y: 742.1 m, z: 425.08 m))\n└─ Hexahedron((x: -900.005 m, y: 742.1 m, z: 412.58 m), ..., (x: -900.005 m, y: 767.1 m, z: 425.08 m))\n\n\nWe would also like to filter Hexahedrons that are above the terrain. Let’s create a simple terrain elevation model by interpolating the vertical z coordinate of the first point of each trajectory:\n\nzcoord(point) = coords(point).z\n\nztable = @chain dtable begin\n  @groupby(:HOLEID)\n  @transform(:z = zcoord(:geometry), :geometry = shadow(:geometry))\n  @combine(:z = first(:z), :geometry = first(:geometry))\nend\n\n\n119×3 GeoTable over 119 PointSet\n\n\nHOLEID\nz\ngeometry\n\n\nCategorical\nContinuous\nPoint\n\n\n[NoUnits]\n[m]\n🖈 Cartesian{NoDatum}\n\n\n\n\n1\n252.82 m\n(x: 559.725 m, y: -513.31 m)\n\n\n2\n280.94 m\n(x: 745.345 m, y: -280.6 m)\n\n\n3\n281.09 m\n(x: -304.025 m, y: 318.13 m)\n\n\n4\n256.16 m\n(x: -416.575 m, y: 570.35 m)\n\n\n5\n324.65 m\n(x: 198.815 m, y: -524.78 m)\n\n\n6\n317.1 m\n(x: 493.605 m, y: -530.83 m)\n\n\n7\n245.13 m\n(x: -367.965 m, y: 394.78 m)\n\n\n8\n250.67 m\n(x: 17.6752 m, y: 33.4297 m)\n\n\n9\n254.49 m\n(x: -514.305 m, y: 594.68 m)\n\n\n10\n294.44 m\n(x: -674.415 m, y: 596.84 m)\n\n\n⋮\n⋮\n⋮\n\n\n\n\n\nWe perform the interpolation of the z coordinate on the projected centroids of the blocks:\n\ncentroids = unique(shadow.(centroid.(blocks)))\n\nztable = ztable |&gt; Select(\"z\") |&gt; Interpolate(centroids, model=IDW())\n\n\n2067×2 GeoTable over 2067 PointSet\n\n\nz\ngeometry\n\n\nContinuous\nPoint\n\n\n[m]\n🖈 Cartesian{NoDatum}\n\n\n\n\n315.273 m\n(x: 737.495 m, y: -870.4 m)\n\n\n318.783 m\n(x: 762.495 m, y: -870.4 m)\n\n\n321.816 m\n(x: 787.495 m, y: -870.4 m)\n\n\n324.655 m\n(x: 812.495 m, y: -870.4 m)\n\n\n327.816 m\n(x: 837.495 m, y: -870.4 m)\n\n\n309.922 m\n(x: 687.495 m, y: -845.4 m)\n\n\n314.0 m\n(x: 712.495 m, y: -845.4 m)\n\n\n318.755 m\n(x: 737.495 m, y: -845.4 m)\n\n\n323.911 m\n(x: 762.495 m, y: -845.4 m)\n\n\n327.361 m\n(x: 787.495 m, y: -845.4 m)\n\n\n⋮\n⋮\n\n\n\n\n\n\nztable |&gt; viewer\n\n\n\n\nFinally, we can filter the blocks for which the z coordinate is below the terrain:\n\np(h) = shadow(centroid(h))\nz(h) = zcoord(centroid(h))\n\nzdict = Dict(ztable.geometry .=&gt; ztable.z)\n\nactive = findall(h -&gt; z(h) &lt; zdict[p(h)], blocks)\n\nblocks = view(blocks, active)\n\n110854 view(::CartesianGrid, [76, 77, 78, 79, ..., 337107, 337109, 337193, 342719])\n├─ Hexahedron((x: 724.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 724.995 m, y: -857.9 m, z: -387.42 m))\n├─ Hexahedron((x: 749.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 749.995 m, y: -857.9 m, z: -387.42 m))\n├─ Hexahedron((x: 774.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 774.995 m, y: -857.9 m, z: -387.42 m))\n├─ Hexahedron((x: 799.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 799.995 m, y: -857.9 m, z: -387.42 m))\n├─ Hexahedron((x: 824.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 824.995 m, y: -857.9 m, z: -387.42 m))\n⋮\n├─ Hexahedron((x: 924.995 m, y: -682.9 m, z: 337.58 m), ..., (x: 924.995 m, y: -657.9 m, z: 350.08 m))\n├─ Hexahedron((x: 874.995 m, y: -757.9 m, z: 350.08 m), ..., (x: 874.995 m, y: -732.9 m, z: 362.58 m))\n├─ Hexahedron((x: 924.995 m, y: -757.9 m, z: 350.08 m), ..., (x: 924.995 m, y: -732.9 m, z: 362.58 m))\n├─ Hexahedron((x: 899.995 m, y: -732.9 m, z: 350.08 m), ..., (x: 899.995 m, y: -707.9 m, z: 362.58 m))\n└─ Hexahedron((x: 924.995 m, y: -757.9 m, z: 362.58 m), ..., (x: 924.995 m, y: -732.9 m, z: 375.08 m))\n\n\n\nviz(blocks)\n\n\n\n\nThe filtered blocks constitute our domain of interpolation.\n\n\n12.3.3 Interpolation of grades\nWe saw that the distribution of chemical elements in the drill hole samples is very skewed. This is always the case in the mining industry. Another issue is that metal and mineral grades are examples of compositional data (Aitchison 1982). The values in these variables are constrained to live in the interval \\([0,1]\\) and to sum up to 100% if all chemical elements are considered.\n\n12.3.3.1 Preprocessing\nIn order to remove compositional data constraints, we will perform the centered log-ratio transform (CLR) from the CoDa.jl module:\n\ngrades = dtable |&gt; Select(\"Cu\", \"Au\", \"Ag\", \"S\")\n\ngrades |&gt; CLR() |&gt; values |&gt; pairplot\n\n\n\n\nAfter the transform, the variables are free to vary in the unbounded interval \\([-\\infty,\\infty]\\). The theory behind this transform is beyond the scope of this book. Nevertheless, it is a simple mathematical expression in terms of logarithms of ratios (e.g., Cu/S).\nNext, we attempt to transform the multivariate distribution to a multivariate standard normal using the ProjectionPursuit transform:\n\ngrades |&gt; CLR() |&gt; ProjectionPursuit() |&gt; values |&gt; pairplot\n\n\n\n\nThe ProjectionPursuit is an advanced statistical transform that removes non-linear associations between variables using an iterative procedure (Friedman 1987). The result is a set of independent variables that can be interpolated separately.\nIn order to “undo” these transforms after the interpolation, we create a revertible pipeline:\n\npreproc = CLR() → ProjectionPursuit()\n\nsamples, cache = apply(preproc, grades)\n\nsamples\n\n\n2000×5 GeoTable over 2000 PointSet\n\n\nPP1\nPP2\nPP3\nPP4\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nPoint\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n-0.844802\n1.30343\n-1.27456\n1.10311\n(x: 559.725 m, y: -513.31 m, z: 252.82 m)\n\n\n-1.39571\n-0.321303\n-1.81311\n0.997374\n(x: 558.955 m, y: -515.23 m, z: 246.87 m)\n\n\n-0.376104\n1.02149\n0.293078\n1.42216\n(x: 557.225 m, y: -519.61 m, z: 233.37 m)\n\n\n-1.44524\n1.48274\n0.164087\n-0.394779\n(x: 555.375 m, y: -524.3 m, z: 218.92 m)\n\n\n-0.537837\n1.13512\n-0.422933\n-0.50318\n(x: 553.825 m, y: -528.21 m, z: 206.94 m)\n\n\n-1.00914\n1.79606\n-0.297047\n0.187243\n(x: 552.075 m, y: -532.56 m, z: 193.91 m)\n\n\n-0.268131\n1.68783\n-1.82083\n1.31376\n(x: 550.305 m, y: -537.08 m, z: 180.8 m)\n\n\n-1.94221\n0.393001\n-0.216252\n0.635433\n(x: 547.495 m, y: -544.31 m, z: 160.08 m)\n\n\n-0.0865092\n-1.39429\n-0.942279\n1.48856\n(x: 544.335 m, y: -552.43 m, z: 137.08 m)\n\n\n-1.46253\n-0.52865\n-0.203195\n-0.169176\n(x: 541.695 m, y: -559.19 m, z: 117.96 m)\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\n\n\n12.3.3.2 Geospatial correlation\nLet’s fit a theoretical variogram for all four (independent) variables up to a given maximum lag:\n\nmaxlag = 300.0u\"m\"\n\nvs = setdiff(names(samples), [\"geometry\"])\n\ngs = [EmpiricalVariogram(samples, v, maxlag = maxlag) for v in vs]\n\nγs = [GeoStatsFunctions.fit(Variogram, g, h -&gt; 1 / h^2) for g in gs]\n\n4-element Vector{Variogram}:\n MaternVariogram(range: 176.833 m, sill: 0.880135, nugget: 0.44146, order: 1.0)\n GaussianVariogram(range: 93.1168 m, sill: 0.938068, nugget: 0.640292)\n MaternVariogram(range: 155.907 m, sill: 0.899557, nugget: 0.54671, order: 1.0)\n MaternVariogram(range: 233.645 m, sill: 0.885176, nugget: 0.495555, order: 1.0)\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe performed the fit of the variogram model using the weighting function h -&gt; 1 / h^2 that penalizes the lag distance h with the inverse of its square.\n\n\n\nfunction gammaplot(n, g, γ)\n  varioplot(g, axis = (; title = n))\n  varioplot!(γ, maxlag = maxlag, color = \"teal\")\n  Mke.current_figure()\nend\n\ngammaplot(vs[1], gs[1], γs[1])\n\n\n\n\n\ngammaplot(vs[2], gs[2], γs[2])\n\n\n\n\n\ngammaplot(vs[3], gs[3], γs[3])\n\n\n\n\n\ngammaplot(vs[4], gs[4], γs[4])\n\n\n\n\nAssuming that the variogram models are adequate, we can proceed to interpolation.\n\n\n12.3.3.3 Geostatistical interpolation\nGiven the domain of interpolation, the samples and the variogram models, we can perform interpolation with InterpolateNeighbors:\n\ninterps = map(vs, γs) do v, γ\n  samples |&gt; Select(v) |&gt; InterpolateNeighbors(blocks, model=Kriging(γ))\nend\n\ninterp = reduce(hcat, interps)\n\n\n110854×5 GeoTable over 110854 view(::CartesianGrid, [76, 77, 78, 79, ..., 337107, 337109, 337193, 342719])\n\n\nPP1\nPP2\nPP3\nPP4\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nHexahedron\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n-0.276408\n-0.26237\n0.249033\n0.464472\nHexahedron((x: 724.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 724.995 m, y: -857.9 m, z: -387.42 m))\n\n\n0.117886\n-0.171133\n0.646586\n0.728788\nHexahedron((x: 749.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 749.995 m, y: -857.9 m, z: -387.42 m))\n\n\n0.117873\n-0.171133\n0.646595\n0.728613\nHexahedron((x: 774.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 774.995 m, y: -857.9 m, z: -387.42 m))\n\n\n0.117865\n-0.171133\n0.6466\n0.72849\nHexahedron((x: 799.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 799.995 m, y: -857.9 m, z: -387.42 m))\n\n\n0.0659519\n-0.113773\n0.131502\n-0.243844\nHexahedron((x: 824.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 824.995 m, y: -857.9 m, z: -387.42 m))\n\n\n-0.309495\n-0.0224843\n0.380854\n0.461341\nHexahedron((x: 674.995 m, y: -857.9 m, z: -399.92 m), ..., (x: 674.995 m, y: -832.9 m, z: -387.42 m))\n\n\n-0.276412\n-0.26237\n0.249037\n0.464695\nHexahedron((x: 699.995 m, y: -857.9 m, z: -399.92 m), ..., (x: 699.995 m, y: -832.9 m, z: -387.42 m))\n\n\n-0.276396\n-0.26237\n0.249064\n0.464544\nHexahedron((x: 724.995 m, y: -857.9 m, z: -399.92 m), ..., (x: 724.995 m, y: -832.9 m, z: -387.42 m))\n\n\n0.117858\n-0.171133\n0.646604\n0.72864\nHexahedron((x: 749.995 m, y: -857.9 m, z: -399.92 m), ..., (x: 749.995 m, y: -832.9 m, z: -387.42 m))\n\n\n0.117843\n-0.171133\n0.646614\n0.728429\nHexahedron((x: 774.995 m, y: -857.9 m, z: -399.92 m), ..., (x: 774.995 m, y: -832.9 m, z: -387.42 m))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nLet’s confirm that the interpolated values follow the same standard normal distribution:\n\ninterp |&gt; Sample(10000) |&gt; values |&gt; pairplot\n\n\n\n\n\n\n12.3.3.4 Postprocessing\nIn order to get the interpolated values in the original compositional space, we need to revert the preprocessing pipeline:\n\nestim = revert(preproc, interp, cache)\n\n\n110854×5 GeoTable over 110854 view(::CartesianGrid, [76, 77, 78, 79, ..., 337107, 337109, 337193, 342719])\n\n\nCu\nAu\nAg\nS\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nHexahedron\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n0.740864\n3.16536e-5\n0.000198069\n0.258906\nHexahedron((x: 724.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 724.995 m, y: -857.9 m, z: -387.42 m))\n\n\n0.745084\n2.18173e-5\n0.000207436\n0.254687\nHexahedron((x: 749.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 749.995 m, y: -857.9 m, z: -387.42 m))\n\n\n0.745107\n2.18107e-5\n0.000207404\n0.254664\nHexahedron((x: 774.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 774.995 m, y: -857.9 m, z: -387.42 m))\n\n\n0.745078\n2.18228e-5\n0.000207451\n0.254692\nHexahedron((x: 799.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 799.995 m, y: -857.9 m, z: -387.42 m))\n\n\n0.75471\n3.36616e-5\n0.000199094\n0.245057\nHexahedron((x: 824.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 824.995 m, y: -857.9 m, z: -387.42 m))\n\n\n0.740053\n3.25046e-5\n0.000201914\n0.259713\nHexahedron((x: 674.995 m, y: -857.9 m, z: -399.92 m), ..., (x: 674.995 m, y: -832.9 m, z: -387.42 m))\n\n\n0.740716\n3.17948e-5\n0.000197862\n0.259055\nHexahedron((x: 699.995 m, y: -857.9 m, z: -399.92 m), ..., (x: 699.995 m, y: -832.9 m, z: -387.42 m))\n\n\n0.740807\n3.17266e-5\n0.000197892\n0.258963\nHexahedron((x: 724.995 m, y: -857.9 m, z: -399.92 m), ..., (x: 724.995 m, y: -832.9 m, z: -387.42 m))\n\n\n0.745111\n2.17933e-5\n0.000207471\n0.25466\nHexahedron((x: 749.995 m, y: -857.9 m, z: -399.92 m), ..., (x: 749.995 m, y: -832.9 m, z: -387.42 m))\n\n\n0.745077\n2.18182e-5\n0.00020744\n0.254693\nHexahedron((x: 774.995 m, y: -857.9 m, z: -399.92 m), ..., (x: 774.995 m, y: -832.9 m, z: -387.42 m))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\n\nestim |&gt; Select(\"Cu\") |&gt; viewer\n\n\n\n\n\n\n\n12.3.4 Model of recovery\nWe introduce a simplistic model of metallurgical recovery using the grade of copper estimated at the mining blocks. We assume that the logistic function represents an ideal behavior for the recovery as the grade of copper increases:\n\nμ = mean(estim.Cu) - 0.1\nσ = std(estim.Cu)\n\nf(Cu) = 1 / (1 + exp(-(Cu - μ) / σ))\n\nf (generic function with 1 method)\n\n\n\nestim = estim |&gt; Map(\"Cu\" =&gt; f =&gt; \"f\")\n\n\n110854×6 GeoTable over 110854 view(::CartesianGrid, [76, 77, 78, 79, ..., 337107, 337109, 337193, 342719])\n\n\nCu\nAu\nAg\nS\nf\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nHexahedron\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n0.740864\n3.16536e-5\n0.000198069\n0.258906\n0.979391\nHexahedron((x: 724.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 724.995 m, y: -857.9 m, z: -387.42 m))\n\n\n0.745084\n2.18173e-5\n0.000207436\n0.254687\n0.982492\nHexahedron((x: 749.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 749.995 m, y: -857.9 m, z: -387.42 m))\n\n\n0.745107\n2.18107e-5\n0.000207404\n0.254664\n0.982507\nHexahedron((x: 774.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 774.995 m, y: -857.9 m, z: -387.42 m))\n\n\n0.745078\n2.18228e-5\n0.000207451\n0.254692\n0.982488\nHexahedron((x: 799.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 799.995 m, y: -857.9 m, z: -387.42 m))\n\n\n0.75471\n3.36616e-5\n0.000199094\n0.245057\n0.987951\nHexahedron((x: 824.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 824.995 m, y: -857.9 m, z: -387.42 m))\n\n\n0.740053\n3.25046e-5\n0.000201914\n0.259713\n0.978736\nHexahedron((x: 674.995 m, y: -857.9 m, z: -399.92 m), ..., (x: 674.995 m, y: -832.9 m, z: -387.42 m))\n\n\n0.740716\n3.17948e-5\n0.000197862\n0.259055\n0.979272\nHexahedron((x: 699.995 m, y: -857.9 m, z: -399.92 m), ..., (x: 699.995 m, y: -832.9 m, z: -387.42 m))\n\n\n0.740807\n3.17266e-5\n0.000197892\n0.258963\n0.979345\nHexahedron((x: 724.995 m, y: -857.9 m, z: -399.92 m), ..., (x: 724.995 m, y: -832.9 m, z: -387.42 m))\n\n\n0.745111\n2.17933e-5\n0.000207471\n0.25466\n0.98251\nHexahedron((x: 749.995 m, y: -857.9 m, z: -399.92 m), ..., (x: 749.995 m, y: -832.9 m, z: -387.42 m))\n\n\n0.745077\n2.18182e-5\n0.00020744\n0.254693\n0.982487\nHexahedron((x: 774.995 m, y: -857.9 m, z: -399.92 m), ..., (x: 774.995 m, y: -832.9 m, z: -387.42 m))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nPlease check the paper by Hoffimann et al. (2022b) for a more elaborate model of metallurgical recovery in the locked-cycle-test.\n\n\n12.3.5 Economic assessment\nGiven the block model with the grade of copper and metallurgical recovery, we can proceed and apply the formula of economic value stated in our objectives:\n\nton = 1000u\"kg\"\n\nρ = 2.75 * ton / 1u\"m^3\"\nP = 4000 / ton\nCₘ = 4 / ton\nCₚ = 10 / ton\n\nestim = @transform(estim,\n  :value = volume(:geometry) * ρ * ((:Cu / 100) * :f * P - (Cₘ + Cₚ))\n)\n\n\n110854×7 GeoTable over 110854 view(::CartesianGrid, [76, 77, 78, 79, ..., 337107, 337109, 337193, 342719])\n\n\nCu\nAu\nAg\nS\nf\nvalue\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nHexahedron\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n0.740864\n3.16536e-5\n0.000198069\n0.258906\n0.979391\n3.22778e5\nHexahedron((x: 724.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 724.995 m, y: -857.9 m, z: -387.42 m))\n\n\n0.745084\n2.18173e-5\n0.000207436\n0.254687\n0.982492\n3.28314e5\nHexahedron((x: 749.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 749.995 m, y: -857.9 m, z: -387.42 m))\n\n\n0.745107\n2.18107e-5\n0.000207404\n0.254664\n0.982507\n3.28344e5\nHexahedron((x: 774.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 774.995 m, y: -857.9 m, z: -387.42 m))\n\n\n0.745078\n2.18228e-5\n0.000207451\n0.254692\n0.982488\n3.28307e5\nHexahedron((x: 799.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 799.995 m, y: -857.9 m, z: -387.42 m))\n\n\n0.75471\n3.36616e-5\n0.000199094\n0.245057\n0.987951\n3.39983e5\nHexahedron((x: 824.995 m, y: -882.9 m, z: -399.92 m), ..., (x: 824.995 m, y: -857.9 m, z: -387.42 m))\n\n\n0.740053\n3.25046e-5\n0.000201914\n0.259713\n0.978736\n3.21678e5\nHexahedron((x: 674.995 m, y: -857.9 m, z: -399.92 m), ..., (x: 674.995 m, y: -832.9 m, z: -387.42 m))\n\n\n0.740716\n3.17948e-5\n0.000197862\n0.259055\n0.979272\n3.22577e5\nHexahedron((x: 699.995 m, y: -857.9 m, z: -399.92 m), ..., (x: 699.995 m, y: -832.9 m, z: -387.42 m))\n\n\n0.740807\n3.17266e-5\n0.000197892\n0.258963\n0.979345\n3.227e5\nHexahedron((x: 724.995 m, y: -857.9 m, z: -399.92 m), ..., (x: 724.995 m, y: -832.9 m, z: -387.42 m))\n\n\n0.745111\n2.17933e-5\n0.000207471\n0.25466\n0.98251\n3.28349e5\nHexahedron((x: 749.995 m, y: -857.9 m, z: -399.92 m), ..., (x: 749.995 m, y: -832.9 m, z: -387.42 m))\n\n\n0.745077\n2.18182e-5\n0.00020744\n0.254693\n0.982487\n3.28306e5\nHexahedron((x: 774.995 m, y: -857.9 m, z: -399.92 m), ..., (x: 774.995 m, y: -832.9 m, z: -387.42 m))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nWe can then visualize all blocks with a positive economic value:\n\nestim |&gt; Filter(x -&gt; x.value &gt; 0) |&gt; Select(\"value\") |&gt; viewer\n\n\n\n\nOr any criterion of interest such as positive economic value and small fraction of contaminants:\n\nestim |&gt; Filter(x -&gt; x.value &gt; 0 && x.S &lt; 0.25) |&gt; Select(\"value\") |&gt; viewer",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Mineral deposits</span>"
    ]
  },
  {
    "objectID": "12-mining.html#summary",
    "href": "12-mining.html#summary",
    "title": "12  Mineral deposits",
    "section": "12.4 Summary",
    "text": "12.4 Summary\nIn this chapter, we illustrated an application of the framework in the mining industry. Among other things, we learned how to\n\nPerform simple economic assessment based on grades and metallurgical recoveries estimated at mining blocks using simple interpolation of transformed variables from drill hole samples.\nUse the tools covered in previous chapters to localize regions of interest in the mineral deposit.\n\nAlthough the mathematical model presented here is simple, it is what most mining companies do. There is opportunity to improve these types of estimates with more sophisticated geospatial data science pipelines.\n\n\n\n\nAitchison, J. 1982. “The Statistical Analysis of Compositional Data.” Journal of the Royal Statistical Society. Series B (Methodological) 44 (2): 139–77. http://www.jstor.org/stable/2345821.\n\n\nFriedman, Jerome H. 1987. “Exploratory Projection Pursuit.” Journal of the American Statistical Association 82 (397): 249–66. http://www.jstor.org/stable/2289161.\n\n\nHoffimann, Júlio, José Augusto, Lucas Resende, Marlon Mathias, Douglas Mazzinghy, Matheus Bianchetti, Mônica Mendes, et al. 2022a. “GeoMet Dataset.” Zenodo. https://doi.org/10.5281/zenodo.7051975.\n\n\nHoffimann, Júlio, José Augusto, Lucas Resende, Marlon Mathias, Douglas Mazzinghy, Matheus Bianchetti, Mônica Mendes, et al. 2022b. “Modeling Geospatial Uncertainty of Geometallurgical Variables with Bayesian Models and Hilbertkriging.” Mathematical Geosciences 54 (7): 1227–53. https://doi.org/10.1007/s11004-022-10013-1.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Mineral deposits</span>"
    ]
  },
  {
    "objectID": "13-agriculture.html",
    "href": "13-agriculture.html",
    "title": "13  Agricultural fields 🚧",
    "section": "",
    "text": "13.1 Coming soon…",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Agricultural fields 🚧</span>"
    ]
  },
  {
    "objectID": "14-energy.html",
    "href": "14-energy.html",
    "title": "14  Petroleum reservoirs",
    "section": "",
    "text": "14.1 Data\nPetroleum reservoirs present various modeling challenges related to their complex geometry and distribution of rock and fluid properties. Some of these challenges are still open in industry due the lack of software for advanced geospatial data science with unstructured meshes. In this chapter, we will illustrate how an important “oil-in-place” calculation in reservoir management can be automated with the framework.\nTOOLS COVERED: @groupby, @transform, @combine, Unitify, Unit, GHC, volume, viewer\nMODULES:\nWe will use reservoir simulation results of the Norne benchmark case, a real oil field from the Norwegian Sea. For more information, please check the OPM project. These results were simulated with the JutulDarcy.jl reservoir simulator by Møyner (2024).\nIn particular, we will consider only two time steps of the simulation, named norne1.vtu and norne2.vtu. The data are stored in the open VTK format with .vtu extension, indicating that it is georeferenced over an unstructured mesh:\nnorne₁ = GeoIO.load(\"data/norne1.vtu\")\nnorne₂ = GeoIO.load(\"data/norne2.vtu\")\n\nnorne₁ |&gt; viewer",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Petroleum reservoirs</span>"
    ]
  },
  {
    "objectID": "14-energy.html#data",
    "href": "14-energy.html#data",
    "title": "14  Petroleum reservoirs",
    "section": "",
    "text": "Note\n\n\n\nThe vtk.org website provides official documentation for the various VTK file formats, including formats for image data (.vti), rectilinear grids (.vtr), structured grids (.vts), unstructured meshes (.vtu), etc.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Petroleum reservoirs</span>"
    ]
  },
  {
    "objectID": "14-energy.html#objectives",
    "href": "14-energy.html#objectives",
    "title": "14  Petroleum reservoirs",
    "section": "14.2 Objectives",
    "text": "14.2 Objectives\nThe Volume of Oil In Place (\\(VOIP\\)) is a global estimate of the volume of oil trapped in the subsurface. It is defined as an integral over the volume \\(V\\) of the reservoir:\n\\[\nVOIP = \\int_V S_o \\phi\\ dV\n\\]\nwhere \\(\\phi\\) is the rock porosity and \\(S_o\\) is the oil saturation. The integrand can be converted into Mass of Oil in Place (\\(MOIP\\)) using the oil density \\(\\rho_o\\):\n\\[\nMOIP = \\int_V \\rho_o S_o \\phi\\ dV\n\\]\nLikewise, the Mass of Water In Place (\\(MWIP\\)) and Mass of Gas in Place (\\(MGIP\\)) are defined using the respective fluid saturations and densities.\nOur main objective is to estimate these masses of fluids in place over a reservoir model with non-trivial geometry, for different time steps within a physical reservoir simulation. This can be useful to understand rates of depletion and guide reservoir management.\nSecondary objectives include the localization (through 3D visualization) of zones with high mass of hydrocarbons (oil + gas), and the calculation of zonal depletion, i.e., the change of hydrocarbon mass per zone, from a time step \\(t_1\\) to a time step \\(t_2\\):\n\\[\nDepletion = \\left\\{MOIP + MGIP\\right\\}_{t_1} - \\left\\{MOIP + MGIP\\right\\}_{t_2}\n\\]",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Petroleum reservoirs</span>"
    ]
  },
  {
    "objectID": "14-energy.html#methodology",
    "href": "14-energy.html#methodology",
    "title": "14  Petroleum reservoirs",
    "section": "14.3 Methodology",
    "text": "14.3 Methodology\nIn order to identify zones of the reservoir with high mass of hydrocarbons, we need to compute the fluids in place for each element of the mesh, and group the elements based on their calculated masses. Given the zones, we can compute the zonal depletion.\nThe proposed methodology has the following steps:\n\nAnalysis of oil, gas and water in place\nLocalization of hydrocarbon zones\nCalculation of zonal depletion\n\n\n14.3.1 Fluid analysis\nBefore we start our calculations, we need to rename the variables in the dataset to match our concise notation. We also need to correct the units of the variables to make sure that our final report has values that are easy to read.\nThe following pipeline performs the desired cleaning steps by exploiting bracket notation (e.g., [kg/m^3]) for units. The Unitify transform takes a geotable with bracket notation as input and converts the values of columns to unitful values:\n\nclean = Select(\n  \"porosity\" =&gt; \"ϕ\",\n  \"saturation_oil\" =&gt; \"So\",\n  \"saturation_gas\" =&gt; \"Sg\",\n  \"saturation_water\" =&gt; \"Sw\",\n  \"density_oil\" =&gt; \"ρo [kg/m^3]\",\n  \"density_gas\" =&gt; \"ρg [kg/m^3]\",\n  \"density_water\" =&gt; \"ρw [kg/m^3]\"\n) → Unitify()\n\nSequentialTransform\n├─ Select(selector: [:porosity, :saturation_oil, :saturation_gas, :saturation_water, :density_oil, :density_gas, :density_water], newnames: [:ϕ, :So, :Sg, :Sw, Symbol(\"ρo [kg/m^3]\"), Symbol(\"ρg [kg/m^3]\"), Symbol(\"ρw [kg/m^3]\")])\n└─ Unitify()\n\n\nThe resulting geotable has variables with concise names and correct units:\n\nreservoir₁ = clean(norne₁)\nreservoir₂ = clean(norne₂)\n\n\n44431×8 GeoTable over 44431 SimpleMesh\n\n\nϕ\nSo\nSg\nSw\nρo\nρg\nρw\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nHexahedron\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[kg m^-3]\n[kg m^-3]\n[kg m^-3]\n🖈 Cartesian{NoDatum}\n\n\n\n\n0.30081\n0.894952\n0.0\n0.105049\n718.387 kg m^-3\n189.051 kg m^-3\n994.545 kg m^-3\nHexahedron((x: 455586.0 m, y: 7.32115e6 m, z: 2586.74 m), ..., (x: 455636.0 m, y: 7.32122e6 m, z: 2605.72 m))\n\n\n0.299529\n0.000697226\n0.894094\n0.105209\n716.681 kg m^-3\n188.769 kg m^-3\n994.486 kg m^-3\nHexahedron((x: 455608.0 m, y: 7.32107e6 m, z: 2568.85 m), ..., (x: 455659.0 m, y: 7.32114e6 m, z: 2585.64 m))\n\n\n0.29655\n0.00040746\n0.894254\n0.105339\n716.723 kg m^-3\n188.685 kg m^-3\n994.457 kg m^-3\nHexahedron((x: 455625.0 m, y: 7.32099e6 m, z: 2563.06 m), ..., (x: 455678.0 m, y: 7.32106e6 m, z: 2573.92 m))\n\n\n0.29324\n0.000401796\n0.894189\n0.10541\n716.745 kg m^-3\n188.64 kg m^-3\n994.442 kg m^-3\nHexahedron((x: 455650.0 m, y: 7.32092e6 m, z: 2559.15 m), ..., (x: 455706.0 m, y: 7.32099e6 m, z: 2569.36 m))\n\n\n0.289647\n0.00040205\n0.894385\n0.105212\n716.765 kg m^-3\n188.6 kg m^-3\n994.427 kg m^-3\nHexahedron((x: 455677.0 m, y: 7.32085e6 m, z: 2555.98 m), ..., (x: 455731.0 m, y: 7.32091e6 m, z: 2567.17 m))\n\n\n0.28579\n0.000402928\n0.894402\n0.105195\n716.783 kg m^-3\n188.565 kg m^-3\n994.415 kg m^-3\nHexahedron((x: 455700.0 m, y: 7.32078e6 m, z: 2553.79 m), ..., (x: 455756.0 m, y: 7.32084e6 m, z: 2562.11 m))\n\n\n0.280003\n0.000401767\n0.894401\n0.105197\n716.788 kg m^-3\n188.554 kg m^-3\n994.411 kg m^-3\nHexahedron((x: 455724.0 m, y: 7.3207e6 m, z: 2552.27 m), ..., (x: 455781.0 m, y: 7.32076e6 m, z: 2560.06 m))\n\n\n0.274279\n0.000383991\n0.859452\n0.140164\n716.793 kg m^-3\n188.546 kg m^-3\n994.408 kg m^-3\nHexahedron((x: 455751.0 m, y: 7.32063e6 m, z: 2551.07 m), ..., (x: 455804.0 m, y: 7.32068e6 m, z: 2561.31 m))\n\n\n0.270403\n0.000385463\n0.859456\n0.140159\n716.805 kg m^-3\n188.521 kg m^-3\n994.399 kg m^-3\nHexahedron((x: 455785.0 m, y: 7.32057e6 m, z: 2549.52 m), ..., (x: 455831.0 m, y: 7.32061e6 m, z: 2559.75 m))\n\n\n0.266089\n0.000382203\n0.854474\n0.145144\n716.818 kg m^-3\n188.494 kg m^-3\n994.389 kg m^-3\nHexahedron((x: 455823.0 m, y: 7.3205e6 m, z: 2547.65 m), ..., (x: 455866.0 m, y: 7.32054e6 m, z: 2556.82 m))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nWe @transform the reservoir and compute masses of fluids for each element of the mesh using the formulae in the beginning of the chapter:\n\nmass(reservoir) = @transform(reservoir,\n  :MOIP = :ρo * :So * :ϕ * volume(:geometry),\n  :MGIP = :ρg * :Sg * :ϕ * volume(:geometry),\n  :MWIP = :ρw * :Sw * :ϕ * volume(:geometry)\n)\n\nmass₁ = mass(reservoir₁)\nmass₂ = mass(reservoir₂)\n\nmass₁ |&gt; Select(\"MWIP\") |&gt; viewer\n\n\n\n\n\n\n14.3.2 Hydrocarbon zones\nWe compute the mass of hydrocarbon in place \\(MHIP\\) as the sum of oil and gas in the first time step, and cluster it with geostatistical hierarchical clustering (GHC) (Fouedjio 2016). The method requires an approximate number of clusters that we set to \\(k=3\\) (low, medium and high values) and a maximum range of geospatial association that we set to \\(\\lambda = 500m\\).\nAdditionally, we set an upper bound nmax=1000 on the number of elements used in the dissimilarity matrix computation and the option as=\"zone\" to name the column with clustering results.\n\nzones = @transform(mass₁, :MHIP = :MOIP + :MGIP) |&gt;\n        Select(\"MHIP\") |&gt; GHC(3, 500u\"m\", nmax=1000, as=\"zone\")\n\nzones |&gt; viewer\n\n\n\n\n\n\n14.3.3 Zonal depletion\nWe concatenate all variables of interest in a single geotable to be able to use the geospatial split-apply-combine pattern, and compute the final summary table with statistics per zone:\n\ncarbon₁ = mass₁ |&gt; Select(\"MOIP\" =&gt; \"MOIP₁\", \"MGIP\" =&gt; \"MGIP₁\")\ncarbon₂ = mass₂ |&gt; Select(\"MOIP\" =&gt; \"MOIP₂\", \"MGIP\" =&gt; \"MGIP₂\")\n\ndata = [carbon₁ carbon₂ zones]\n\n\n44431×6 GeoTable over 44431 SimpleMesh\n\n\nMOIP₁\nMGIP₁\nMOIP₂\nMGIP₂\nzone\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nCategorical\nHexahedron\n\n\n[kg]\n[kg]\n[kg]\n[kg]\n[NoUnits]\n🖈 Cartesian{NoDatum}\n\n\n\n\n7.57425e6 kg\n0.0 kg\n7.56895e6 kg\n0.0 kg\n2\nHexahedron((x: 455586.0 m, y: 7.32115e6 m, z: 2586.74 m), ..., (x: 455636.0 m, y: 7.32122e6 m, z: 2605.72 m))\n\n\n0.0 kg\n2.43976e6 kg\n7141.61 kg\n2.41219e6 kg\n2\nHexahedron((x: 455608.0 m, y: 7.32107e6 m, z: 2568.85 m), ..., (x: 455659.0 m, y: 7.32114e6 m, z: 2585.64 m))\n\n\n0.0 kg\n2.24126e6 kg\n3835.96 kg\n2.21634e6 kg\n2\nHexahedron((x: 455625.0 m, y: 7.32099e6 m, z: 2563.06 m), ..., (x: 455678.0 m, y: 7.32106e6 m, z: 2573.92 m))\n\n\n0.0 kg\n2.16366e6 kg\n3652.63 kg\n2.13943e6 kg\n2\nHexahedron((x: 455650.0 m, y: 7.32092e6 m, z: 2559.15 m), ..., (x: 455706.0 m, y: 7.32099e6 m, z: 2569.36 m))\n\n\n0.0 kg\n2.21737e6 kg\n3746.6 kg\n2.19304e6 kg\n2\nHexahedron((x: 455677.0 m, y: 7.32085e6 m, z: 2555.98 m), ..., (x: 455731.0 m, y: 7.32091e6 m, z: 2567.17 m))\n\n\n0.0 kg\n2.25638e6 kg\n3821.64 kg\n2.23166e6 kg\n2\nHexahedron((x: 455700.0 m, y: 7.32078e6 m, z: 2553.79 m), ..., (x: 455756.0 m, y: 7.32084e6 m, z: 2562.11 m))\n\n\n0.0 kg\n1.91029e6 kg\n3226.36 kg\n1.88936e6 kg\n2\nHexahedron((x: 455724.0 m, y: 7.3207e6 m, z: 2552.27 m), ..., (x: 455781.0 m, y: 7.32076e6 m, z: 2560.06 m))\n\n\n0.0 kg\n1.78157e6 kg\n2993.03 kg\n1.76212e6 kg\n2\nHexahedron((x: 455751.0 m, y: 7.32063e6 m, z: 2551.07 m), ..., (x: 455804.0 m, y: 7.32068e6 m, z: 2561.31 m))\n\n\n0.0 kg\n1.70066e6 kg\n2868.5 kg\n1.68211e6 kg\n2\nHexahedron((x: 455785.0 m, y: 7.32057e6 m, z: 2549.52 m), ..., (x: 455831.0 m, y: 7.32061e6 m, z: 2559.75 m))\n\n\n0.0 kg\n1.57036e6 kg\n2642.13 kg\n1.55327e6 kg\n2\nHexahedron((x: 455823.0 m, y: 7.3205e6 m, z: 2547.65 m), ..., (x: 455866.0 m, y: 7.32054e6 m, z: 2556.82 m))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nThe depletion per zone can be computed with\n\nsummary = @chain data begin\n  @groupby(:zone)\n  @transform(:delta = :MOIP₁ + :MGIP₁ - :MOIP₂ - :MGIP₂)\n  @combine(:depletion = sum(:delta))\nend\n\n\n3×3 GeoTable over 3 GeometrySet\n\n\nzone\ndepletion\ngeometry\n\n\nCategorical\nContinuous\nMultiPolyhedron\n\n\n[NoUnits]\n[kg]\n🖈 Cartesian{NoDatum}\n\n\n\n\n2\n4.53802e10 kg\nMulti(22342×Hexahedron)\n\n\n3\n1.54539e10 kg\nMulti(4694×Hexahedron)\n\n\n1\n2.17843e9 kg\nMulti(17395×Hexahedron)\n\n\n\n\n\nor in \\(Mg\\) (ton) after a change of Unit:\n\nsummary |&gt; Unit(\"depletion\" =&gt; u\"Mg\")\n\n\n3×3 GeoTable over 3 GeometrySet\n\n\nzone\ndepletion\ngeometry\n\n\nCategorical\nContinuous\nMultiPolyhedron\n\n\n[NoUnits]\n[Mg]\n🖈 Cartesian{NoDatum}\n\n\n\n\n2\n4.53802e7 Mg\nMulti(22342×Hexahedron)\n\n\n3\n1.54539e7 Mg\nMulti(4694×Hexahedron)\n\n\n1\n2.17843e6 Mg\nMulti(17395×Hexahedron)",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Petroleum reservoirs</span>"
    ]
  },
  {
    "objectID": "14-energy.html#summary",
    "href": "14-energy.html#summary",
    "title": "14  Petroleum reservoirs",
    "section": "14.4 Summary",
    "text": "14.4 Summary\nIn this chapter, we illustrated the application of the framework in the petroleum industry. Among other things, we learned how to\n\nPerform simple calculations involving fluids in place and unstructured meshes.\nIdentify zones of a petroleum reservoir using clustering methods and visualizations.\n\nThis open source technology can be used to create advanced dashboards for reservoir management without advanced programming skills. It addresses real issues raised by geospatial data scientists in industry who feel unproductive using rigid geomodeling software.\n\n\n\n\nFouedjio, Francky. 2016. “A Hierarchical Clustering Method for Multivariate Geostatistical Data.” Spatial Statistics 18: 333–51. https://doi.org/https://doi.org/10.1016/j.spasta.2016.07.003.\n\n\nMøyner, O. 2024. “JutulDarcy.jl - a Fully Differentiable High-Performance Reservoir Simulator Based on Automatic Differentiation” 2024 (1): 1–9. https://doi.org/https://doi.org/10.3997/2214-4609.202437111.",
    "crumbs": [
      "Part V: Applications",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Petroleum reservoirs</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Aitchison, J. 1982. “The Statistical Analysis of Compositional\nData.” Journal of the Royal Statistical Society. Series B\n(Methodological) 44 (2): 139–77. http://www.jstor.org/stable/2345821.\n\n\nBezanson, Jeff, Alan Edelman, Stefan Karpinski, and Viral B Shah. 2017.\n“Julia: A Fresh Approach to Numerical Computing.” SIAM\nReview 59 (1): 65–98. https://doi.org/10.1137/141000671.\n\n\nBouchet-Valat, Milan, and Bogumił Kamiński. 2023. “DataFrames.jl:\nFlexible and Fast Tabular Data in Julia.” Journal of\nStatistical Software 107 (4): 1–32. https://doi.org/10.18637/jss.v107.i04.\n\n\nBreloff, Tom. 2023. “Plots.jl.” Zenodo. https://doi.org/10.5281/zenodo.8183938.\n\n\nCheng, Siu-Wing, Tamal K. Dey, and Jonathan Shewchuk. 2012. Delaunay\nMesh Generation. Chapman; Hall/CRC. https://people.eecs.berkeley.edu/~jrs/meshbook.html.\n\n\nChilès, Jean-Paul, and Pierre Delfiner. 2012. Geostatistics.\nWiley. https://doi.org/10.1002/9781118136188.\n\n\nCorreia, M.., J.. Hohendorff, A. T. Gaspar, and D.. Schiozer. 2015.\nUNISIM-II-D: Benchmark Case Proposal Based on a\nCarbonate Reservoir. Vol. Day 3 Fri, November 20, 2015. SPE\nLatin America and Caribbean Petroleum Engineering Conference. https://doi.org/10.2118/177140-MS.\n\n\nCressie, Noel, and Douglas M. Hawkins. 1980. “Robust Estimation of\nthe Variogram: i.” Journal of the International Association\nfor Mathematical Geology 12 (2): 115–25. https://doi.org/10.1007/bf01035243.\n\n\nDanisch, Simon, and Julius Krumbiegel. 2021. “Makie.jl: Flexible\nHigh-Performance Data Visualization for Julia.” Journal of\nOpen Source Software 6 (65): 3349. https://doi.org/10.21105/joss.03349.\n\n\nDevadoss, Satyan L, and Joseph O’Rourke. 2011. Discrete and\nComputational Geometry. Princeton, NJ: Princeton University Press.\n\n\nFloriani, L. De, and A. Hui. 2007. “Shape\nRepresentations Based on Simplicial and Cell Complexes.”\nIn Eurographics 2007 - State of the Art Reports, edited by\nDieter Schmalstieg and Jiri Bittner. The Eurographics Association. https://doi.org/10.2312/egst.20071055.\n\n\nFouedjio, Francky. 2016. “A Hierarchical Clustering Method for\nMultivariate Geostatistical Data.” Spatial Statistics\n18: 333–51. https://doi.org/https://doi.org/10.1016/j.spasta.2016.07.003.\n\n\nFriedman, Jerome H. 1987. “Exploratory Projection Pursuit.”\nJournal of the American Statistical Association 82 (397):\n249–66. http://www.jstor.org/stable/2289161.\n\n\nHeld, M. 2001. “FIST: Fast Industrial-Strength\nTriangulation of Polygons.” Algorithmica 30 (4): 563–96.\nhttps://doi.org/10.1007/s00453-001-0028-4.\n\n\nHoffimann, Júlio, José Augusto, Lucas Resende, Marlon Mathias, Douglas\nMazzinghy, Matheus Bianchetti, Mônica Mendes, et al. 2022a.\n“GeoMet Dataset.” Zenodo. https://doi.org/10.5281/zenodo.7051975.\n\n\nHoffimann, Júlio, José Augusto, Lucas Resende, Marlon Mathias, Douglas\nMazzinghy, Matheus Bianchetti, Mônica Mendes, et al. 2022b.\n“Modeling Geospatial Uncertainty of Geometallurgical Variables\nwith Bayesian Models and Hilbertkriging.”\nMathematical Geosciences 54 (7): 1227–53. https://doi.org/10.1007/s11004-022-10013-1.\n\n\nHoffimann, Júlio, and Bianca Zadrozny. 2019. “Efficient\nVariography with Partition Variograms.” Computers &\nGeosciences 131: 52–59. https://doi.org/https://doi.org/10.1016/j.cageo.2019.06.013.\n\n\nHoffimann, Júlio, Maciel Zortea, Breno de Carvalho, and Bianca Zadrozny.\n2021. “Geostatistical Learning: Challenges and\nOpportunities.” Frontiers in Applied Mathematics and\nStatistics 7. https://doi.org/10.3389/fams.2021.689393.\n\n\nKoolen, Twan, Yuto Horikawa, Andy Ferris, Claire Foster, awbsmith,\nryanelandt, Jan Weidner, et al. 2023. “JuliaGeometry/Rotations.jl:\nV1.6.0.” Zenodo. https://doi.org/10.5281/zenodo.8366010.\n\n\nLauwens, Ben, and Allen Downey. 2018. Think Julia: How to Think Like\na Computer Scientist. https://benlauwens.github.io/ThinkJulia.jl/latest/book.html.\n\n\nLin, Dahua, David Widmann, Simon Byrne, John Myles White, Andreas Noack,\nMathieu Besançon, Douglas Bates, et al. 2023.\n“JuliaStats/Distributions.jl: V0.25.100.” Zenodo. https://doi.org/10.5281/zenodo.8224988.\n\n\nMariethoz, Gregoire, and Jef Caers. 2014. Multiple-Point\nGeostatistics: Stochastic Modeling with Training Images. https://www.wiley.com/en-gb/Multiple+point+Geostatistics%3A+Stochastic+Modeling+with+Training+Images-p-9781118662755.\n\n\nMatheron, Georges François Paul Marie. 1971. The Theory of\nRegionalized Variables and Its Applications.\n\n\nMøyner, O. 2024. “JutulDarcy.jl - a Fully Differentiable\nHigh-Performance Reservoir Simulator Based on Automatic\nDifferentiation” 2024 (1): 1–9. https://doi.org/https://doi.org/10.3997/2214-4609.202437111.\n\n\nMyers, Donald E. 1992. “Kriging, Cokriging, Radial Basis Functions\nand the Role of Positive Definiteness.” Computers &\nMathematics with Applications 24 (12): 139–48. https://doi.org/https://doi.org/10.1016/0898-1221(92)90176-I.\n\n\nOlea, Ricardo A. 1999. Geostatistics for Engineers and Earth\nScientists. Springer US. https://doi.org/10.1007/978-1-4615-5001-3.\n\n\nQuinn, Jacob, Bogumił Kamiński, David Anthoff, Milan Bouchet-Valat,\nTamas K. Papp, Takafumi Arakaki, Rafael Schouten, et al. 2023.\n“JuliaData/Tables.jl: V1.10.1.” Zenodo. https://doi.org/10.5281/zenodo.7730968.\n\n\nShepard, Donald S. 1968. “A Two-Dimensional Interpolation Function\nfor Irregularly-Spaced Data.” Proceedings of the 1968 23rd\nACM National Conference. https://api.semanticscholar.org/CorpusID:42723195.\n\n\nThompson, William. 2023. “PairPlots.jl\nBeautiful and Flexible Visualizations of High Dimensional Data.”\nhttps://sefffal.github.io/PairPlots.jl/dev.\n\n\nWebster, Richard, and Margaret A. Oliver. 2007. Geostatistics for\nEnvironmental Scientists. Wiley. https://doi.org/10.1002/9780470517277.\n\n\nWickham, Hadley. 2011. “The Split-Apply-Combine Strategy for Data\nAnalysis.” Journal of Statistical Software 40 (1): 1–29.\nhttps://doi.org/10.18637/jss.v040.i01.",
    "crumbs": [
      "References"
    ]
  }
]